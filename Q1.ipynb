{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1b46fe41",
      "metadata": {
        "id": "1b46fe41"
      },
      "source": [
        "<h1 align=\"center\">Introduction to Machine Learning - Course Code: 25737</h1>\n",
        "<h4 align=\"center\">Instructor: Dr. Amiri</h4>\n",
        "<h4 align=\"center\">Sharif University of Technology, Spring 2024</h4>\n",
        "<h4 align=\"center\">Computer Assignment 3</h4>\n",
        "<h4 align=\"center\">\n",
        "\n",
        "Question 1\n",
        "\n",
        "</h4>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24a0fc13",
      "metadata": {
        "id": "24a0fc13"
      },
      "source": [
        "# Personal Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "44babb65",
      "metadata": {
        "id": "44babb65"
      },
      "outputs": [],
      "source": [
        "# Set your student number\n",
        "student_number = 400101283\n",
        "Name = 'Kimia'\n",
        "Last_Name = 'Ramezan'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca4a337a",
      "metadata": {
        "id": "ca4a337a"
      },
      "source": [
        "# Rules\n",
        "- You are not allowed to add or remove cells. You **must use the provided space to write your code**. If you don't follow this rule, **your Practical Assignment won't be graded**.  \n",
        "\n",
        "- Collaboration and using the internet is allowed, but your code **must be written by yourself**. **Copying code** from each other or from available resources will result in a **zero score for the assignment**.\n",
        "\n",
        "- You are not allowed to use `torch.nn`, `torch.optim` and any activation function and loss function implemented in torch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "12b76789",
      "metadata": {
        "id": "12b76789",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5db0a56e-6fb7-42ba-816f-022d324fa0eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: torch==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.3.0+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.0->torchvision)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.0->torchvision)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.0->torchvision)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.0->torchvision)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.0->torchvision)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.0->torchvision)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.0->torchvision)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.0->torchvision)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.0->torchvision)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.0->torchvision)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.0->torchvision)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0->torchvision)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.3.0->torchvision) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.3.0->torchvision) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy\n",
        "!pip install matplotlib\n",
        "!pip install torchvision\n",
        "!pip install torch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "886188c7",
      "metadata": {
        "id": "886188c7"
      },
      "source": [
        "## Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "55a0adcc",
      "metadata": {
        "id": "55a0adcc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision.datasets import FashionMNIST\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from typing import Dict"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18510868",
      "metadata": {
        "id": "18510868"
      },
      "source": [
        "## Datasets and Dataloaders\n",
        "\n",
        "Here, we download and load the train and test `FashionMNIST` dataset with the desired transforms. Then, we define the dataloaders for `train` and `test`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "dc8759e2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc8759e2",
        "outputId": "da504044-06e2-4dd7-e991-92caecac9fab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 16572900.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./FashionMNIST/raw/train-images-idx3-ubyte.gz to ./FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 298947.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 5468192.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 12226657.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train_set = FashionMNIST(root='.', train=True, download=True, transform=transforms.ToTensor())\n",
        "test_set = FashionMNIST(root='.', train=False, download=True, transform=transforms.ToTensor())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5df47fcb",
      "metadata": {
        "id": "5df47fcb"
      },
      "source": [
        "\n",
        "Here you have to calculate the number of classes amd input dimention of the first layer (how many pixels does each image have?)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each image in the dataset is 28 pixels wide and 28 pixels high, and since they are grayscale, each pixel is represented by a single value (not RGB). Thus, the input dimension for each image, when considering it as an input to a neural network layer, is typically the total number of pixels in the image. Therefore, the input dimension is 28 x 28 = 784 pixels."
      ],
      "metadata": {
        "id": "_j4Io08VoNDJ"
      },
      "id": "_j4Io08VoNDJ"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8f6763e6",
      "metadata": {
        "id": "8f6763e6"
      },
      "outputs": [],
      "source": [
        "## FILL HERE\n",
        "# input_dim = .....\n",
        "num_classes = 10\n",
        "input_dim = 784  # 28 x 28 pixels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c695ff60",
      "metadata": {
        "id": "c695ff60"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_set, 64, shuffle=True)\n",
        "test_loader = DataLoader(test_set, 64, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9dac6c2",
      "metadata": {
        "id": "f9dac6c2"
      },
      "source": [
        "## Visualization\n",
        "\n",
        "Visualize 1 random image from each class by using `plt.subplots`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "e3d6b0c1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        },
        "id": "e3d6b0c1",
        "outputId": "fd60bc1a-c10a-414f-8a04-4ddedc360118"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x400 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "class_names = {\n",
        "    0: \"T-shirt/top\",\n",
        "    1: \"Trouser\",\n",
        "    2: \"Pullover\",\n",
        "    3: \"Dress\",\n",
        "    4: \"Coat\",\n",
        "    5: \"Sandal\",\n",
        "    6: \"Shirt\",\n",
        "    7: \"Sneaker\",\n",
        "    8: \"Bag\",\n",
        "    9: \"Ankle boot\"\n",
        "}\n",
        "class_images = [None] * 10\n",
        "\n",
        "# check if all classes have images\n",
        "def all_classes_filled(images_list):\n",
        "    return all(image is not None for image in images_list)\n",
        "\n",
        "# find one image for each class\n",
        "for images, labels in train_loader:\n",
        "    for image, label in zip(images, labels):\n",
        "        label = label.item()\n",
        "        if class_images[label] is None:\n",
        "            class_images[label] = image\n",
        "        if all_classes_filled(class_images):\n",
        "            break\n",
        "    if all_classes_filled(class_images):\n",
        "        break\n",
        "\n",
        "fig, axes = plt.subplots(1, 10, figsize=(20, 4))\n",
        "for idx, image in enumerate(class_images):\n",
        "    ax = axes[idx]\n",
        "    ax.imshow(image.squeeze(), cmap='gray')\n",
        "    ax.set_title(class_names[idx])\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a94c5aba",
      "metadata": {
        "id": "a94c5aba"
      },
      "source": [
        "## Initializing model's parameters\n",
        "\n",
        "In this part, we create the model and initialize its parameters and store the values of these parameters in the variable `parameters` which is a dictionary including the weigths and biases of each layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "e6d40952",
      "metadata": {
        "id": "e6d40952"
      },
      "outputs": [],
      "source": [
        "def add_linear_layer(parameters: dict, shape, device, i=None):\n",
        "    \"\"\"\n",
        "    This function adds parameters of a linear unit of shape `shape` to the `parameters` dictionary.\n",
        "    \"\"\"\n",
        "    n_in, n_out = shape\n",
        "    with torch.no_grad():\n",
        "        w = torch.zeros(*shape, device=device)\n",
        "        # kaiming initialization for ReLU activations:\n",
        "        bound = 1 / np.sqrt(n_in).item()\n",
        "        w.uniform_(-bound, bound)\n",
        "        b = torch.zeros(n_out, device=device)  # no need to (1, n_out). it will broadcast itself.\n",
        "    w.requires_grad = True\n",
        "    b.requires_grad = True\n",
        "    # `i` is used to give numbers to parameter names\n",
        "    parameters.update({f'w{i}': w, f'b{i}': b})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce914706",
      "metadata": {
        "id": "ce914706"
      },
      "source": [
        "Now we define our neural network with the given layers and add the weights and biases to the dictionary `parameters`. **You are allowed to modify the values of the layers**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "8f3867d7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f3867d7",
        "outputId": "9fc4d88c-5497-4347-dc1b-ac8c49dfa379"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['w0', 'b0', 'w1', 'b1', 'w2', 'b2', 'w3', 'b3', 'w4', 'b4'])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# input_dim : input dimention of the first layer, which you have calculated before.\n",
        "layers = [\n",
        "    (input_dim, 512),\n",
        "    (512, 256),\n",
        "    (256, 128),\n",
        "    (128, 64),\n",
        "    (64, num_classes)\n",
        "]\n",
        "num_layers = len(layers)\n",
        "parameters = {}\n",
        "\n",
        "# setting the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# adding the parameters to the dictionary\n",
        "for i, shape in enumerate(layers):\n",
        "    add_linear_layer(parameters, shape, device, i)\n",
        "\n",
        "parameters.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bfd2c8e",
      "metadata": {
        "id": "8bfd2c8e"
      },
      "source": [
        "## Defining the required functions\n",
        "\n",
        "In this section, we should define the required functions. For each of these functions, the inputs and the desired outputs are given and you should write all or part of the function. **You are not allowed to use the activation functions and the loss functions implemented in torch**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3b413d8",
      "metadata": {
        "id": "f3b413d8"
      },
      "source": [
        "Computing affine and relu outputs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "bebeeb0e",
      "metadata": {
        "id": "bebeeb0e"
      },
      "outputs": [],
      "source": [
        "def affine_forward(x, w, b):\n",
        "    ## FILL HERE\n",
        "  y = x @ w + b\n",
        "  return y\n",
        "\n",
        "\n",
        "def relu(x):\n",
        "    ## FILL HERE\n",
        "    return torch.maximum(x, torch.tensor(0.0, device=x.device))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d9baa5e",
      "metadata": {
        "id": "5d9baa5e"
      },
      "source": [
        "Function `model` returns output of the whole model for the input `x` using the parameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "d2562962",
      "metadata": {
        "id": "d2562962"
      },
      "outputs": [],
      "source": [
        "def model(x: torch.Tensor, parameters, num_layers=num_layers):\n",
        "    # number of batches\n",
        "    B = x.shape[0]\n",
        "    x = x.view(B, -1)\n",
        "\n",
        "    ## FILL HERE\n",
        "    for i in range(num_layers):\n",
        "        w = parameters[f'w{i}']\n",
        "        b = parameters[f'b{i}']\n",
        "        x = affine_forward(x, w, b)\n",
        "        if i < num_layers - 1:\n",
        "            x = relu(x)\n",
        "    output = x\n",
        "    return output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d17a9b4c",
      "metadata": {
        "id": "d17a9b4c"
      },
      "source": [
        "Implementing cross entropy loss:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "6959621c",
      "metadata": {
        "id": "6959621c"
      },
      "outputs": [],
      "source": [
        "def cross_entropy_loss(scores, y):\n",
        "    n = len(y)\n",
        "    ## FILL HERE\n",
        "    exp_scores = torch.exp(scores)\n",
        "    probabilities = exp_scores / torch.sum(exp_scores, axis=1, keepdim=True)\n",
        "    correct_log_probs = -torch.log(probabilities[range(n), y])\n",
        "    loss = torch.sum(correct_log_probs) / n\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15a589af",
      "metadata": {
        "id": "15a589af"
      },
      "source": [
        "Implementing a function for optimizing paramters and a function to zeroing out their gradients:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "3121c147",
      "metadata": {
        "id": "3121c147"
      },
      "outputs": [],
      "source": [
        "def sgd_optimizer(parameters: Dict[str, torch.Tensor], learning_rate=0.001):\n",
        "    '''This function gets the parameters and a learning rate. Then updates the parameters using their\n",
        "    gradient. Finally, you should zero the gradients of the parameters after updating\n",
        "    the parameter value.'''\n",
        "    ## FILL HERE\n",
        "    for param in parameters.values():\n",
        "        if param.grad is not None:\n",
        "            param.data -= learning_rate * param.grad.data\n",
        "            param.grad.zero_()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e17b4cf8",
      "metadata": {
        "id": "e17b4cf8"
      },
      "source": [
        "Training functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "76c0f03b",
      "metadata": {
        "id": "76c0f03b"
      },
      "outputs": [],
      "source": [
        "def accuracy(y_pred: np.ndarray, y_true: np.ndarray):\n",
        "    ## FILL HERE\n",
        "    correct_predictions = np.sum(y_pred == y_true)\n",
        "    total_predictions = len(y_true)\n",
        "    acc = correct_predictions / total_predictions\n",
        "    return acc\n",
        "\n",
        "def train(train_loader, learning_rate=0.001, epoch=None):\n",
        "    '''This function implements the training loop for a single epoch. For each batch you should do the following:\n",
        "        1- Calculate the output of the model to the given input batch\n",
        "        2- Calculate the loss based on the model output\n",
        "        3- Update the gradients using backward method\n",
        "        4- Optimize the model parameters using the sgd_optimizer function defined previously\n",
        "        5- Print the train loss (Show the epoch and batch as well)\n",
        "        '''\n",
        "    train_loss = 0\n",
        "    N_train = len(train_loader.dataset)\n",
        "\n",
        "    # Creating empty lists Y and Y_pred to store the labels and predictions of each batch\n",
        "    # for calculateing the accuracy later\n",
        "    Y = []\n",
        "    Y_pred = []\n",
        "\n",
        "\n",
        "    for i, (x, y) in enumerate(train_loader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        p = model(x, parameters)\n",
        "\n",
        "        ## FILL HERE\n",
        "        loss = cross_entropy_loss(p, y)\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        sgd_optimizer(parameters, learning_rate)\n",
        "\n",
        "        y_pred = p.argmax(dim=-1)\n",
        "        Y.append(y.cpu().numpy())\n",
        "        Y_pred.append(y_pred.cpu().numpy())\n",
        "\n",
        "    Y = np.concatenate(Y)\n",
        "    Y_pred = np.concatenate(Y_pred)\n",
        "    acc = accuracy(Y_pred, Y)\n",
        "    print(f'Accuracy of train set: {acc}')\n",
        "    return train_loss / N_train, acc\n",
        "\n",
        "\n",
        "def validate(loader, epoch=None, set_name=None):\n",
        "    '''This function validates the model on the test dataloader. The function goes through each batch and does\n",
        "    the following on each batch:\n",
        "        1- Calculate the model output\n",
        "        2- Calculate the loss using the model output\n",
        "        3- Print the loss for each batch and epoch\n",
        "\n",
        "    Finally the function calculates the model accuracy.'''\n",
        "    total_loss = 0\n",
        "    N = len(loader.dataset)\n",
        "\n",
        "    Y = []\n",
        "    Y_pred = []\n",
        "    for i, (x, y) in enumerate(loader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        p = model(x, parameters)\n",
        "\n",
        "        loss = cross_entropy_loss(p, y)\n",
        "        total_loss += loss.item()\n",
        "        y_pred = p.argmax(dim=-1)\n",
        "\n",
        "        Y.append(y.cpu().numpy())\n",
        "        Y_pred.append(y_pred.cpu().numpy())\n",
        "        print(f'Epoch {epoch}, Batch {i}, {set_name} Loss: {loss.item()}')\n",
        "\n",
        "    Y = np.concatenate(Y)\n",
        "    Y_pred = np.concatenate(Y_pred)\n",
        "    acc = accuracy(Y_pred, Y)\n",
        "    print(f'Epoch {epoch}, Accuracy of {set_name} set: {acc}')\n",
        "\n",
        "    return total_loss / N, acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "87ebb4b6",
      "metadata": {
        "id": "87ebb4b6"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "test_losses = []\n",
        "train_accuracies = []\n",
        "test_accuracies = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "28d4eb0b",
      "metadata": {
        "id": "28d4eb0b"
      },
      "outputs": [],
      "source": [
        "def train_model(dataloaders, num_epochs, learning_rate=0.001, model_name='pytorch_model'):\n",
        "    '''This function trains the model for the number of epochs given and stores, calculates and prints the train\n",
        "    and test losses and accuracies. Finally, it plots the accuracy and loss history for training and test sets'''\n",
        "    train_loader, test_loader = dataloaders\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        ## FILL HERE\n",
        "        ## You should calculate the train and test loss and accuracies for each epoch and add them to\n",
        "        ## the lists `train_losses`, `test_losses`, `train_accuracies` and `test_accuracies`\n",
        "        train_loss, train_acc = train(train_loader, learning_rate, epoch)\n",
        "        test_loss, test_acc = validate(test_loader, epoch, set_name='test')\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        test_losses.append(test_loss)\n",
        "        train_accuracies.append(train_acc)\n",
        "        test_accuracies.append(test_acc)\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}:')\n",
        "        print(f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.2f}')\n",
        "        print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.2f}')\n",
        "\n",
        "    ## plot the loss history of training and test sets\n",
        "    ## FILL HERE\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(train_losses, label='Train Loss')\n",
        "    plt.plot(test_losses, label='Test Loss')\n",
        "    plt.title('Loss History')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    ## plot the accuracy history of training and test sets\n",
        "    ## FILL HERE\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(train_accuracies, label='Train Accuracy')\n",
        "    plt.plot(test_accuracies, label='Test Accuracy')\n",
        "    plt.title('Accuracy History')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "2ec4bdd2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2ec4bdd2",
        "outputId": "67e7f17d-2c27-4840-861c-56dc9729bab5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of train set: 0.3377833333333333\n",
            "Epoch 0, Batch 0, test Loss: 2.2748303413391113\n",
            "Epoch 0, Batch 1, test Loss: 2.272495746612549\n",
            "Epoch 0, Batch 2, test Loss: 2.266124725341797\n",
            "Epoch 0, Batch 3, test Loss: 2.267388105392456\n",
            "Epoch 0, Batch 4, test Loss: 2.26432204246521\n",
            "Epoch 0, Batch 5, test Loss: 2.2687063217163086\n",
            "Epoch 0, Batch 6, test Loss: 2.273946762084961\n",
            "Epoch 0, Batch 7, test Loss: 2.2724456787109375\n",
            "Epoch 0, Batch 8, test Loss: 2.2716903686523438\n",
            "Epoch 0, Batch 9, test Loss: 2.270747423171997\n",
            "Epoch 0, Batch 10, test Loss: 2.271632671356201\n",
            "Epoch 0, Batch 11, test Loss: 2.2751870155334473\n",
            "Epoch 0, Batch 12, test Loss: 2.2650716304779053\n",
            "Epoch 0, Batch 13, test Loss: 2.2639825344085693\n",
            "Epoch 0, Batch 14, test Loss: 2.264436960220337\n",
            "Epoch 0, Batch 15, test Loss: 2.27082896232605\n",
            "Epoch 0, Batch 16, test Loss: 2.2724509239196777\n",
            "Epoch 0, Batch 17, test Loss: 2.2710254192352295\n",
            "Epoch 0, Batch 18, test Loss: 2.2694268226623535\n",
            "Epoch 0, Batch 19, test Loss: 2.271134614944458\n",
            "Epoch 0, Batch 20, test Loss: 2.267587900161743\n",
            "Epoch 0, Batch 21, test Loss: 2.272482395172119\n",
            "Epoch 0, Batch 22, test Loss: 2.2687134742736816\n",
            "Epoch 0, Batch 23, test Loss: 2.271306037902832\n",
            "Epoch 0, Batch 24, test Loss: 2.273542642593384\n",
            "Epoch 0, Batch 25, test Loss: 2.27275013923645\n",
            "Epoch 0, Batch 26, test Loss: 2.270890235900879\n",
            "Epoch 0, Batch 27, test Loss: 2.2735559940338135\n",
            "Epoch 0, Batch 28, test Loss: 2.2708630561828613\n",
            "Epoch 0, Batch 29, test Loss: 2.270331859588623\n",
            "Epoch 0, Batch 30, test Loss: 2.2709524631500244\n",
            "Epoch 0, Batch 31, test Loss: 2.274651288986206\n",
            "Epoch 0, Batch 32, test Loss: 2.2749085426330566\n",
            "Epoch 0, Batch 33, test Loss: 2.267674446105957\n",
            "Epoch 0, Batch 34, test Loss: 2.274244546890259\n",
            "Epoch 0, Batch 35, test Loss: 2.270038604736328\n",
            "Epoch 0, Batch 36, test Loss: 2.2699222564697266\n",
            "Epoch 0, Batch 37, test Loss: 2.2659125328063965\n",
            "Epoch 0, Batch 38, test Loss: 2.2661335468292236\n",
            "Epoch 0, Batch 39, test Loss: 2.2679810523986816\n",
            "Epoch 0, Batch 40, test Loss: 2.2720117568969727\n",
            "Epoch 0, Batch 41, test Loss: 2.26421856880188\n",
            "Epoch 0, Batch 42, test Loss: 2.2680160999298096\n",
            "Epoch 0, Batch 43, test Loss: 2.2742245197296143\n",
            "Epoch 0, Batch 44, test Loss: 2.2743749618530273\n",
            "Epoch 0, Batch 45, test Loss: 2.2716221809387207\n",
            "Epoch 0, Batch 46, test Loss: 2.2626428604125977\n",
            "Epoch 0, Batch 47, test Loss: 2.2733678817749023\n",
            "Epoch 0, Batch 48, test Loss: 2.2755494117736816\n",
            "Epoch 0, Batch 49, test Loss: 2.2723536491394043\n",
            "Epoch 0, Batch 50, test Loss: 2.257645606994629\n",
            "Epoch 0, Batch 51, test Loss: 2.2774245738983154\n",
            "Epoch 0, Batch 52, test Loss: 2.2700679302215576\n",
            "Epoch 0, Batch 53, test Loss: 2.270930528640747\n",
            "Epoch 0, Batch 54, test Loss: 2.2629196643829346\n",
            "Epoch 0, Batch 55, test Loss: 2.269094944000244\n",
            "Epoch 0, Batch 56, test Loss: 2.2768969535827637\n",
            "Epoch 0, Batch 57, test Loss: 2.2706801891326904\n",
            "Epoch 0, Batch 58, test Loss: 2.260554552078247\n",
            "Epoch 0, Batch 59, test Loss: 2.2670278549194336\n",
            "Epoch 0, Batch 60, test Loss: 2.2691893577575684\n",
            "Epoch 0, Batch 61, test Loss: 2.27364444732666\n",
            "Epoch 0, Batch 62, test Loss: 2.265923023223877\n",
            "Epoch 0, Batch 63, test Loss: 2.269643783569336\n",
            "Epoch 0, Batch 64, test Loss: 2.2705931663513184\n",
            "Epoch 0, Batch 65, test Loss: 2.2596335411071777\n",
            "Epoch 0, Batch 66, test Loss: 2.2659714221954346\n",
            "Epoch 0, Batch 67, test Loss: 2.264066696166992\n",
            "Epoch 0, Batch 68, test Loss: 2.2699100971221924\n",
            "Epoch 0, Batch 69, test Loss: 2.259859800338745\n",
            "Epoch 0, Batch 70, test Loss: 2.272902250289917\n",
            "Epoch 0, Batch 71, test Loss: 2.2734642028808594\n",
            "Epoch 0, Batch 72, test Loss: 2.271812915802002\n",
            "Epoch 0, Batch 73, test Loss: 2.2700648307800293\n",
            "Epoch 0, Batch 74, test Loss: 2.2720956802368164\n",
            "Epoch 0, Batch 75, test Loss: 2.2619094848632812\n",
            "Epoch 0, Batch 76, test Loss: 2.275815486907959\n",
            "Epoch 0, Batch 77, test Loss: 2.2687034606933594\n",
            "Epoch 0, Batch 78, test Loss: 2.271904230117798\n",
            "Epoch 0, Batch 79, test Loss: 2.268021821975708\n",
            "Epoch 0, Batch 80, test Loss: 2.2721807956695557\n",
            "Epoch 0, Batch 81, test Loss: 2.2682104110717773\n",
            "Epoch 0, Batch 82, test Loss: 2.2680063247680664\n",
            "Epoch 0, Batch 83, test Loss: 2.2686572074890137\n",
            "Epoch 0, Batch 84, test Loss: 2.2642312049865723\n",
            "Epoch 0, Batch 85, test Loss: 2.2668864727020264\n",
            "Epoch 0, Batch 86, test Loss: 2.266126871109009\n",
            "Epoch 0, Batch 87, test Loss: 2.279467821121216\n",
            "Epoch 0, Batch 88, test Loss: 2.2669484615325928\n",
            "Epoch 0, Batch 89, test Loss: 2.2689523696899414\n",
            "Epoch 0, Batch 90, test Loss: 2.2645819187164307\n",
            "Epoch 0, Batch 91, test Loss: 2.2698476314544678\n",
            "Epoch 0, Batch 92, test Loss: 2.2633450031280518\n",
            "Epoch 0, Batch 93, test Loss: 2.268242597579956\n",
            "Epoch 0, Batch 94, test Loss: 2.2693557739257812\n",
            "Epoch 0, Batch 95, test Loss: 2.2651174068450928\n",
            "Epoch 0, Batch 96, test Loss: 2.266524314880371\n",
            "Epoch 0, Batch 97, test Loss: 2.277855157852173\n",
            "Epoch 0, Batch 98, test Loss: 2.269507646560669\n",
            "Epoch 0, Batch 99, test Loss: 2.2701902389526367\n",
            "Epoch 0, Batch 100, test Loss: 2.2698476314544678\n",
            "Epoch 0, Batch 101, test Loss: 2.2703452110290527\n",
            "Epoch 0, Batch 102, test Loss: 2.2735276222229004\n",
            "Epoch 0, Batch 103, test Loss: 2.2686169147491455\n",
            "Epoch 0, Batch 104, test Loss: 2.276456832885742\n",
            "Epoch 0, Batch 105, test Loss: 2.275263547897339\n",
            "Epoch 0, Batch 106, test Loss: 2.274031639099121\n",
            "Epoch 0, Batch 107, test Loss: 2.2650327682495117\n",
            "Epoch 0, Batch 108, test Loss: 2.2663445472717285\n",
            "Epoch 0, Batch 109, test Loss: 2.2728588581085205\n",
            "Epoch 0, Batch 110, test Loss: 2.2705752849578857\n",
            "Epoch 0, Batch 111, test Loss: 2.267045259475708\n",
            "Epoch 0, Batch 112, test Loss: 2.2732205390930176\n",
            "Epoch 0, Batch 113, test Loss: 2.2724642753601074\n",
            "Epoch 0, Batch 114, test Loss: 2.2748587131500244\n",
            "Epoch 0, Batch 115, test Loss: 2.2634875774383545\n",
            "Epoch 0, Batch 116, test Loss: 2.2717158794403076\n",
            "Epoch 0, Batch 117, test Loss: 2.2650251388549805\n",
            "Epoch 0, Batch 118, test Loss: 2.2688708305358887\n",
            "Epoch 0, Batch 119, test Loss: 2.274837017059326\n",
            "Epoch 0, Batch 120, test Loss: 2.2640442848205566\n",
            "Epoch 0, Batch 121, test Loss: 2.2686102390289307\n",
            "Epoch 0, Batch 122, test Loss: 2.2737650871276855\n",
            "Epoch 0, Batch 123, test Loss: 2.2665414810180664\n",
            "Epoch 0, Batch 124, test Loss: 2.271540641784668\n",
            "Epoch 0, Batch 125, test Loss: 2.2679476737976074\n",
            "Epoch 0, Batch 126, test Loss: 2.2790262699127197\n",
            "Epoch 0, Batch 127, test Loss: 2.265867233276367\n",
            "Epoch 0, Batch 128, test Loss: 2.277116298675537\n",
            "Epoch 0, Batch 129, test Loss: 2.2760744094848633\n",
            "Epoch 0, Batch 130, test Loss: 2.2697062492370605\n",
            "Epoch 0, Batch 131, test Loss: 2.265437364578247\n",
            "Epoch 0, Batch 132, test Loss: 2.261862277984619\n",
            "Epoch 0, Batch 133, test Loss: 2.2690112590789795\n",
            "Epoch 0, Batch 134, test Loss: 2.269718647003174\n",
            "Epoch 0, Batch 135, test Loss: 2.27116322517395\n",
            "Epoch 0, Batch 136, test Loss: 2.272804021835327\n",
            "Epoch 0, Batch 137, test Loss: 2.2670910358428955\n",
            "Epoch 0, Batch 138, test Loss: 2.267740249633789\n",
            "Epoch 0, Batch 139, test Loss: 2.2690181732177734\n",
            "Epoch 0, Batch 140, test Loss: 2.2723004817962646\n",
            "Epoch 0, Batch 141, test Loss: 2.26772403717041\n",
            "Epoch 0, Batch 142, test Loss: 2.272958517074585\n",
            "Epoch 0, Batch 143, test Loss: 2.268531560897827\n",
            "Epoch 0, Batch 144, test Loss: 2.275108814239502\n",
            "Epoch 0, Batch 145, test Loss: 2.2661845684051514\n",
            "Epoch 0, Batch 146, test Loss: 2.2693190574645996\n",
            "Epoch 0, Batch 147, test Loss: 2.2646262645721436\n",
            "Epoch 0, Batch 148, test Loss: 2.2727839946746826\n",
            "Epoch 0, Batch 149, test Loss: 2.2687511444091797\n",
            "Epoch 0, Batch 150, test Loss: 2.2731969356536865\n",
            "Epoch 0, Batch 151, test Loss: 2.270587682723999\n",
            "Epoch 0, Batch 152, test Loss: 2.268916606903076\n",
            "Epoch 0, Batch 153, test Loss: 2.272151231765747\n",
            "Epoch 0, Batch 154, test Loss: 2.271064043045044\n",
            "Epoch 0, Batch 155, test Loss: 2.2562122344970703\n",
            "Epoch 0, Batch 156, test Loss: 2.267242431640625\n",
            "Epoch 0, Accuracy of test set: 0.4207\n",
            "Epoch 1/25:\n",
            "Train Loss: 0.0358, Train Accuracy: 0.34\n",
            "Test Loss: 0.0356, Test Accuracy: 0.42\n",
            "Accuracy of train set: 0.33405\n",
            "Epoch 1, Batch 0, test Loss: 1.7028366327285767\n",
            "Epoch 1, Batch 1, test Loss: 1.7267290353775024\n",
            "Epoch 1, Batch 2, test Loss: 1.7173796892166138\n",
            "Epoch 1, Batch 3, test Loss: 1.677403450012207\n",
            "Epoch 1, Batch 4, test Loss: 1.6750651597976685\n",
            "Epoch 1, Batch 5, test Loss: 1.700313925743103\n",
            "Epoch 1, Batch 6, test Loss: 1.7892407178878784\n",
            "Epoch 1, Batch 7, test Loss: 1.6769609451293945\n",
            "Epoch 1, Batch 8, test Loss: 1.5899230241775513\n",
            "Epoch 1, Batch 9, test Loss: 1.7945042848587036\n",
            "Epoch 1, Batch 10, test Loss: 1.6934932470321655\n",
            "Epoch 1, Batch 11, test Loss: 1.72533118724823\n",
            "Epoch 1, Batch 12, test Loss: 1.7173885107040405\n",
            "Epoch 1, Batch 13, test Loss: 1.8093409538269043\n",
            "Epoch 1, Batch 14, test Loss: 1.7415058612823486\n",
            "Epoch 1, Batch 15, test Loss: 1.664741039276123\n",
            "Epoch 1, Batch 16, test Loss: 1.6973466873168945\n",
            "Epoch 1, Batch 17, test Loss: 1.7212626934051514\n",
            "Epoch 1, Batch 18, test Loss: 1.6599386930465698\n",
            "Epoch 1, Batch 19, test Loss: 1.7652368545532227\n",
            "Epoch 1, Batch 20, test Loss: 1.6364777088165283\n",
            "Epoch 1, Batch 21, test Loss: 1.7082881927490234\n",
            "Epoch 1, Batch 22, test Loss: 1.6899853944778442\n",
            "Epoch 1, Batch 23, test Loss: 1.7331715822219849\n",
            "Epoch 1, Batch 24, test Loss: 1.7782888412475586\n",
            "Epoch 1, Batch 25, test Loss: 1.7184396982192993\n",
            "Epoch 1, Batch 26, test Loss: 1.6541285514831543\n",
            "Epoch 1, Batch 27, test Loss: 1.6536707878112793\n",
            "Epoch 1, Batch 28, test Loss: 1.7757211923599243\n",
            "Epoch 1, Batch 29, test Loss: 1.6061018705368042\n",
            "Epoch 1, Batch 30, test Loss: 1.771153211593628\n",
            "Epoch 1, Batch 31, test Loss: 1.7634403705596924\n",
            "Epoch 1, Batch 32, test Loss: 1.7523411512374878\n",
            "Epoch 1, Batch 33, test Loss: 1.5783565044403076\n",
            "Epoch 1, Batch 34, test Loss: 1.7669692039489746\n",
            "Epoch 1, Batch 35, test Loss: 1.6914129257202148\n",
            "Epoch 1, Batch 36, test Loss: 1.6925746202468872\n",
            "Epoch 1, Batch 37, test Loss: 1.6350723505020142\n",
            "Epoch 1, Batch 38, test Loss: 1.7081900835037231\n",
            "Epoch 1, Batch 39, test Loss: 1.6956068277359009\n",
            "Epoch 1, Batch 40, test Loss: 1.6712026596069336\n",
            "Epoch 1, Batch 41, test Loss: 1.616161584854126\n",
            "Epoch 1, Batch 42, test Loss: 1.6044776439666748\n",
            "Epoch 1, Batch 43, test Loss: 1.7517821788787842\n",
            "Epoch 1, Batch 44, test Loss: 1.7082384824752808\n",
            "Epoch 1, Batch 45, test Loss: 1.676584243774414\n",
            "Epoch 1, Batch 46, test Loss: 1.6670124530792236\n",
            "Epoch 1, Batch 47, test Loss: 1.686531662940979\n",
            "Epoch 1, Batch 48, test Loss: 1.7283248901367188\n",
            "Epoch 1, Batch 49, test Loss: 1.717043399810791\n",
            "Epoch 1, Batch 50, test Loss: 1.6013306379318237\n",
            "Epoch 1, Batch 51, test Loss: 1.7403467893600464\n",
            "Epoch 1, Batch 52, test Loss: 1.7562282085418701\n",
            "Epoch 1, Batch 53, test Loss: 1.7300167083740234\n",
            "Epoch 1, Batch 54, test Loss: 1.6981866359710693\n",
            "Epoch 1, Batch 55, test Loss: 1.7365230321884155\n",
            "Epoch 1, Batch 56, test Loss: 1.7603862285614014\n",
            "Epoch 1, Batch 57, test Loss: 1.6917409896850586\n",
            "Epoch 1, Batch 58, test Loss: 1.7199351787567139\n",
            "Epoch 1, Batch 59, test Loss: 1.6837961673736572\n",
            "Epoch 1, Batch 60, test Loss: 1.7061606645584106\n",
            "Epoch 1, Batch 61, test Loss: 1.6648119688034058\n",
            "Epoch 1, Batch 62, test Loss: 1.6315537691116333\n",
            "Epoch 1, Batch 63, test Loss: 1.6735923290252686\n",
            "Epoch 1, Batch 64, test Loss: 1.6593645811080933\n",
            "Epoch 1, Batch 65, test Loss: 1.7342957258224487\n",
            "Epoch 1, Batch 66, test Loss: 1.7156556844711304\n",
            "Epoch 1, Batch 67, test Loss: 1.7120747566223145\n",
            "Epoch 1, Batch 68, test Loss: 1.7596427202224731\n",
            "Epoch 1, Batch 69, test Loss: 1.7429953813552856\n",
            "Epoch 1, Batch 70, test Loss: 1.7663023471832275\n",
            "Epoch 1, Batch 71, test Loss: 1.7055697441101074\n",
            "Epoch 1, Batch 72, test Loss: 1.6811988353729248\n",
            "Epoch 1, Batch 73, test Loss: 1.6988202333450317\n",
            "Epoch 1, Batch 74, test Loss: 1.7953068017959595\n",
            "Epoch 1, Batch 75, test Loss: 1.6683228015899658\n",
            "Epoch 1, Batch 76, test Loss: 1.7340871095657349\n",
            "Epoch 1, Batch 77, test Loss: 1.7174949645996094\n",
            "Epoch 1, Batch 78, test Loss: 1.7222663164138794\n",
            "Epoch 1, Batch 79, test Loss: 1.7070010900497437\n",
            "Epoch 1, Batch 80, test Loss: 1.6212852001190186\n",
            "Epoch 1, Batch 81, test Loss: 1.7258150577545166\n",
            "Epoch 1, Batch 82, test Loss: 1.7516640424728394\n",
            "Epoch 1, Batch 83, test Loss: 1.7523162364959717\n",
            "Epoch 1, Batch 84, test Loss: 1.7258687019348145\n",
            "Epoch 1, Batch 85, test Loss: 1.7248694896697998\n",
            "Epoch 1, Batch 86, test Loss: 1.70603609085083\n",
            "Epoch 1, Batch 87, test Loss: 1.7052099704742432\n",
            "Epoch 1, Batch 88, test Loss: 1.7003345489501953\n",
            "Epoch 1, Batch 89, test Loss: 1.7058579921722412\n",
            "Epoch 1, Batch 90, test Loss: 1.734161615371704\n",
            "Epoch 1, Batch 91, test Loss: 1.8156135082244873\n",
            "Epoch 1, Batch 92, test Loss: 1.686776876449585\n",
            "Epoch 1, Batch 93, test Loss: 1.6861376762390137\n",
            "Epoch 1, Batch 94, test Loss: 1.6494648456573486\n",
            "Epoch 1, Batch 95, test Loss: 1.7107943296432495\n",
            "Epoch 1, Batch 96, test Loss: 1.5851359367370605\n",
            "Epoch 1, Batch 97, test Loss: 1.7164922952651978\n",
            "Epoch 1, Batch 98, test Loss: 1.6872509717941284\n",
            "Epoch 1, Batch 99, test Loss: 1.7160375118255615\n",
            "Epoch 1, Batch 100, test Loss: 1.7662309408187866\n",
            "Epoch 1, Batch 101, test Loss: 1.7435237169265747\n",
            "Epoch 1, Batch 102, test Loss: 1.580949068069458\n",
            "Epoch 1, Batch 103, test Loss: 1.7128890752792358\n",
            "Epoch 1, Batch 104, test Loss: 1.7556681632995605\n",
            "Epoch 1, Batch 105, test Loss: 1.7263611555099487\n",
            "Epoch 1, Batch 106, test Loss: 1.6047391891479492\n",
            "Epoch 1, Batch 107, test Loss: 1.747866153717041\n",
            "Epoch 1, Batch 108, test Loss: 1.7366925477981567\n",
            "Epoch 1, Batch 109, test Loss: 1.7115085124969482\n",
            "Epoch 1, Batch 110, test Loss: 1.6601271629333496\n",
            "Epoch 1, Batch 111, test Loss: 1.6797081232070923\n",
            "Epoch 1, Batch 112, test Loss: 1.6811378002166748\n",
            "Epoch 1, Batch 113, test Loss: 1.7871198654174805\n",
            "Epoch 1, Batch 114, test Loss: 1.7015907764434814\n",
            "Epoch 1, Batch 115, test Loss: 1.655213475227356\n",
            "Epoch 1, Batch 116, test Loss: 1.745072841644287\n",
            "Epoch 1, Batch 117, test Loss: 1.7591252326965332\n",
            "Epoch 1, Batch 118, test Loss: 1.6470673084259033\n",
            "Epoch 1, Batch 119, test Loss: 1.742561936378479\n",
            "Epoch 1, Batch 120, test Loss: 1.7555913925170898\n",
            "Epoch 1, Batch 121, test Loss: 1.7095270156860352\n",
            "Epoch 1, Batch 122, test Loss: 1.635966181755066\n",
            "Epoch 1, Batch 123, test Loss: 1.7118103504180908\n",
            "Epoch 1, Batch 124, test Loss: 1.6323968172073364\n",
            "Epoch 1, Batch 125, test Loss: 1.7209457159042358\n",
            "Epoch 1, Batch 126, test Loss: 1.635992407798767\n",
            "Epoch 1, Batch 127, test Loss: 1.6990033388137817\n",
            "Epoch 1, Batch 128, test Loss: 1.646090030670166\n",
            "Epoch 1, Batch 129, test Loss: 1.715602159500122\n",
            "Epoch 1, Batch 130, test Loss: 1.6914058923721313\n",
            "Epoch 1, Batch 131, test Loss: 1.7092732191085815\n",
            "Epoch 1, Batch 132, test Loss: 1.7655107975006104\n",
            "Epoch 1, Batch 133, test Loss: 1.7515816688537598\n",
            "Epoch 1, Batch 134, test Loss: 1.634275197982788\n",
            "Epoch 1, Batch 135, test Loss: 1.7604937553405762\n",
            "Epoch 1, Batch 136, test Loss: 1.855422854423523\n",
            "Epoch 1, Batch 137, test Loss: 1.7362534999847412\n",
            "Epoch 1, Batch 138, test Loss: 1.720372200012207\n",
            "Epoch 1, Batch 139, test Loss: 1.694754958152771\n",
            "Epoch 1, Batch 140, test Loss: 1.7543625831604004\n",
            "Epoch 1, Batch 141, test Loss: 1.7381937503814697\n",
            "Epoch 1, Batch 142, test Loss: 1.829893708229065\n",
            "Epoch 1, Batch 143, test Loss: 1.7894032001495361\n",
            "Epoch 1, Batch 144, test Loss: 1.6937038898468018\n",
            "Epoch 1, Batch 145, test Loss: 1.7172073125839233\n",
            "Epoch 1, Batch 146, test Loss: 1.6507608890533447\n",
            "Epoch 1, Batch 147, test Loss: 1.7374193668365479\n",
            "Epoch 1, Batch 148, test Loss: 1.7824320793151855\n",
            "Epoch 1, Batch 149, test Loss: 1.7224249839782715\n",
            "Epoch 1, Batch 150, test Loss: 1.6320327520370483\n",
            "Epoch 1, Batch 151, test Loss: 1.6649647951126099\n",
            "Epoch 1, Batch 152, test Loss: 1.7653248310089111\n",
            "Epoch 1, Batch 153, test Loss: 1.8038736581802368\n",
            "Epoch 1, Batch 154, test Loss: 1.6124942302703857\n",
            "Epoch 1, Batch 155, test Loss: 1.7627804279327393\n",
            "Epoch 1, Batch 156, test Loss: 1.7050126791000366\n",
            "Epoch 1, Accuracy of test set: 0.367\n",
            "Epoch 2/25:\n",
            "Train Loss: 0.0331, Train Accuracy: 0.33\n",
            "Test Loss: 0.0268, Test Accuracy: 0.37\n",
            "Accuracy of train set: 0.5507666666666666\n",
            "Epoch 2, Batch 0, test Loss: 0.8899823427200317\n",
            "Epoch 2, Batch 1, test Loss: 1.1509568691253662\n",
            "Epoch 2, Batch 2, test Loss: 0.9291101694107056\n",
            "Epoch 2, Batch 3, test Loss: 0.919823169708252\n",
            "Epoch 2, Batch 4, test Loss: 0.7612239122390747\n",
            "Epoch 2, Batch 5, test Loss: 0.8640998005867004\n",
            "Epoch 2, Batch 6, test Loss: 1.0752676725387573\n",
            "Epoch 2, Batch 7, test Loss: 0.9515029191970825\n",
            "Epoch 2, Batch 8, test Loss: 0.9463901519775391\n",
            "Epoch 2, Batch 9, test Loss: 0.9718618392944336\n",
            "Epoch 2, Batch 10, test Loss: 0.9850544333457947\n",
            "Epoch 2, Batch 11, test Loss: 0.9248872995376587\n",
            "Epoch 2, Batch 12, test Loss: 0.9918807744979858\n",
            "Epoch 2, Batch 13, test Loss: 1.0269814729690552\n",
            "Epoch 2, Batch 14, test Loss: 1.031976342201233\n",
            "Epoch 2, Batch 15, test Loss: 1.208505630493164\n",
            "Epoch 2, Batch 16, test Loss: 0.8882490396499634\n",
            "Epoch 2, Batch 17, test Loss: 1.012010097503662\n",
            "Epoch 2, Batch 18, test Loss: 1.026558756828308\n",
            "Epoch 2, Batch 19, test Loss: 0.9629529714584351\n",
            "Epoch 2, Batch 20, test Loss: 0.9296023845672607\n",
            "Epoch 2, Batch 21, test Loss: 0.9129589796066284\n",
            "Epoch 2, Batch 22, test Loss: 0.9408620595932007\n",
            "Epoch 2, Batch 23, test Loss: 1.014510154724121\n",
            "Epoch 2, Batch 24, test Loss: 0.9392858743667603\n",
            "Epoch 2, Batch 25, test Loss: 1.0351227521896362\n",
            "Epoch 2, Batch 26, test Loss: 1.0634005069732666\n",
            "Epoch 2, Batch 27, test Loss: 1.1799126863479614\n",
            "Epoch 2, Batch 28, test Loss: 0.9669299721717834\n",
            "Epoch 2, Batch 29, test Loss: 0.8310115337371826\n",
            "Epoch 2, Batch 30, test Loss: 0.9219680428504944\n",
            "Epoch 2, Batch 31, test Loss: 0.9182642698287964\n",
            "Epoch 2, Batch 32, test Loss: 1.0162458419799805\n",
            "Epoch 2, Batch 33, test Loss: 0.9147181510925293\n",
            "Epoch 2, Batch 34, test Loss: 0.9624290466308594\n",
            "Epoch 2, Batch 35, test Loss: 0.993749737739563\n",
            "Epoch 2, Batch 36, test Loss: 0.9361681938171387\n",
            "Epoch 2, Batch 37, test Loss: 0.8484553694725037\n",
            "Epoch 2, Batch 38, test Loss: 1.0489169359207153\n",
            "Epoch 2, Batch 39, test Loss: 1.013641595840454\n",
            "Epoch 2, Batch 40, test Loss: 0.9047617316246033\n",
            "Epoch 2, Batch 41, test Loss: 1.0518276691436768\n",
            "Epoch 2, Batch 42, test Loss: 0.8954041600227356\n",
            "Epoch 2, Batch 43, test Loss: 1.0902060270309448\n",
            "Epoch 2, Batch 44, test Loss: 0.9548299908638\n",
            "Epoch 2, Batch 45, test Loss: 1.0778850317001343\n",
            "Epoch 2, Batch 46, test Loss: 1.0240278244018555\n",
            "Epoch 2, Batch 47, test Loss: 1.0866599082946777\n",
            "Epoch 2, Batch 48, test Loss: 1.0687276124954224\n",
            "Epoch 2, Batch 49, test Loss: 1.0255250930786133\n",
            "Epoch 2, Batch 50, test Loss: 0.8639090061187744\n",
            "Epoch 2, Batch 51, test Loss: 0.9897555708885193\n",
            "Epoch 2, Batch 52, test Loss: 1.09510338306427\n",
            "Epoch 2, Batch 53, test Loss: 0.8562833070755005\n",
            "Epoch 2, Batch 54, test Loss: 1.0941773653030396\n",
            "Epoch 2, Batch 55, test Loss: 1.1016361713409424\n",
            "Epoch 2, Batch 56, test Loss: 0.9435195326805115\n",
            "Epoch 2, Batch 57, test Loss: 0.8683552742004395\n",
            "Epoch 2, Batch 58, test Loss: 1.0838849544525146\n",
            "Epoch 2, Batch 59, test Loss: 0.9607537984848022\n",
            "Epoch 2, Batch 60, test Loss: 0.9908525347709656\n",
            "Epoch 2, Batch 61, test Loss: 0.9733273983001709\n",
            "Epoch 2, Batch 62, test Loss: 0.9933558702468872\n",
            "Epoch 2, Batch 63, test Loss: 0.9124734401702881\n",
            "Epoch 2, Batch 64, test Loss: 0.961447536945343\n",
            "Epoch 2, Batch 65, test Loss: 1.0589724779129028\n",
            "Epoch 2, Batch 66, test Loss: 0.8912405371665955\n",
            "Epoch 2, Batch 67, test Loss: 0.9935142993927002\n",
            "Epoch 2, Batch 68, test Loss: 0.8757708668708801\n",
            "Epoch 2, Batch 69, test Loss: 0.9231404066085815\n",
            "Epoch 2, Batch 70, test Loss: 1.0198535919189453\n",
            "Epoch 2, Batch 71, test Loss: 0.8995528221130371\n",
            "Epoch 2, Batch 72, test Loss: 1.021284818649292\n",
            "Epoch 2, Batch 73, test Loss: 0.9694067239761353\n",
            "Epoch 2, Batch 74, test Loss: 1.1173224449157715\n",
            "Epoch 2, Batch 75, test Loss: 0.8821868896484375\n",
            "Epoch 2, Batch 76, test Loss: 0.9271911978721619\n",
            "Epoch 2, Batch 77, test Loss: 0.8940175771713257\n",
            "Epoch 2, Batch 78, test Loss: 0.8146786093711853\n",
            "Epoch 2, Batch 79, test Loss: 1.011491060256958\n",
            "Epoch 2, Batch 80, test Loss: 0.8337641358375549\n",
            "Epoch 2, Batch 81, test Loss: 1.2250508069992065\n",
            "Epoch 2, Batch 82, test Loss: 0.8939751982688904\n",
            "Epoch 2, Batch 83, test Loss: 1.036173701286316\n",
            "Epoch 2, Batch 84, test Loss: 1.0369893312454224\n",
            "Epoch 2, Batch 85, test Loss: 1.1701301336288452\n",
            "Epoch 2, Batch 86, test Loss: 0.9269170761108398\n",
            "Epoch 2, Batch 87, test Loss: 1.0083320140838623\n",
            "Epoch 2, Batch 88, test Loss: 0.9439080357551575\n",
            "Epoch 2, Batch 89, test Loss: 1.0506306886672974\n",
            "Epoch 2, Batch 90, test Loss: 1.1280202865600586\n",
            "Epoch 2, Batch 91, test Loss: 1.015895128250122\n",
            "Epoch 2, Batch 92, test Loss: 1.0373377799987793\n",
            "Epoch 2, Batch 93, test Loss: 0.9903717041015625\n",
            "Epoch 2, Batch 94, test Loss: 1.067749261856079\n",
            "Epoch 2, Batch 95, test Loss: 0.9780669808387756\n",
            "Epoch 2, Batch 96, test Loss: 0.8531100749969482\n",
            "Epoch 2, Batch 97, test Loss: 0.8000771403312683\n",
            "Epoch 2, Batch 98, test Loss: 0.96296226978302\n",
            "Epoch 2, Batch 99, test Loss: 0.9859057664871216\n",
            "Epoch 2, Batch 100, test Loss: 0.9073030948638916\n",
            "Epoch 2, Batch 101, test Loss: 0.8978450298309326\n",
            "Epoch 2, Batch 102, test Loss: 1.0601493120193481\n",
            "Epoch 2, Batch 103, test Loss: 0.9320067763328552\n",
            "Epoch 2, Batch 104, test Loss: 0.971524715423584\n",
            "Epoch 2, Batch 105, test Loss: 0.9524112939834595\n",
            "Epoch 2, Batch 106, test Loss: 0.9532890915870667\n",
            "Epoch 2, Batch 107, test Loss: 0.8505541086196899\n",
            "Epoch 2, Batch 108, test Loss: 1.0399792194366455\n",
            "Epoch 2, Batch 109, test Loss: 0.9835019707679749\n",
            "Epoch 2, Batch 110, test Loss: 0.960982620716095\n",
            "Epoch 2, Batch 111, test Loss: 0.9568503499031067\n",
            "Epoch 2, Batch 112, test Loss: 0.9997734427452087\n",
            "Epoch 2, Batch 113, test Loss: 1.175215244293213\n",
            "Epoch 2, Batch 114, test Loss: 0.8925597667694092\n",
            "Epoch 2, Batch 115, test Loss: 1.0446759462356567\n",
            "Epoch 2, Batch 116, test Loss: 0.9063628911972046\n",
            "Epoch 2, Batch 117, test Loss: 0.9285712838172913\n",
            "Epoch 2, Batch 118, test Loss: 0.8439480662345886\n",
            "Epoch 2, Batch 119, test Loss: 0.9975831508636475\n",
            "Epoch 2, Batch 120, test Loss: 0.9710309505462646\n",
            "Epoch 2, Batch 121, test Loss: 1.0620625019073486\n",
            "Epoch 2, Batch 122, test Loss: 1.0074162483215332\n",
            "Epoch 2, Batch 123, test Loss: 0.9008291959762573\n",
            "Epoch 2, Batch 124, test Loss: 1.0843498706817627\n",
            "Epoch 2, Batch 125, test Loss: 0.9562731385231018\n",
            "Epoch 2, Batch 126, test Loss: 1.0907710790634155\n",
            "Epoch 2, Batch 127, test Loss: 1.2658330202102661\n",
            "Epoch 2, Batch 128, test Loss: 1.0230978727340698\n",
            "Epoch 2, Batch 129, test Loss: 0.9671419858932495\n",
            "Epoch 2, Batch 130, test Loss: 0.9640624523162842\n",
            "Epoch 2, Batch 131, test Loss: 0.9264886975288391\n",
            "Epoch 2, Batch 132, test Loss: 0.8914492130279541\n",
            "Epoch 2, Batch 133, test Loss: 1.0224742889404297\n",
            "Epoch 2, Batch 134, test Loss: 0.8593824505805969\n",
            "Epoch 2, Batch 135, test Loss: 0.8614873886108398\n",
            "Epoch 2, Batch 136, test Loss: 0.8876820206642151\n",
            "Epoch 2, Batch 137, test Loss: 1.1202950477600098\n",
            "Epoch 2, Batch 138, test Loss: 0.8996628522872925\n",
            "Epoch 2, Batch 139, test Loss: 0.9389691948890686\n",
            "Epoch 2, Batch 140, test Loss: 0.9313589334487915\n",
            "Epoch 2, Batch 141, test Loss: 0.8481128811836243\n",
            "Epoch 2, Batch 142, test Loss: 1.076663613319397\n",
            "Epoch 2, Batch 143, test Loss: 1.1357113122940063\n",
            "Epoch 2, Batch 144, test Loss: 1.1574368476867676\n",
            "Epoch 2, Batch 145, test Loss: 0.9371846914291382\n",
            "Epoch 2, Batch 146, test Loss: 0.9937047958374023\n",
            "Epoch 2, Batch 147, test Loss: 1.189817190170288\n",
            "Epoch 2, Batch 148, test Loss: 0.8734037280082703\n",
            "Epoch 2, Batch 149, test Loss: 0.9210293292999268\n",
            "Epoch 2, Batch 150, test Loss: 0.9614704251289368\n",
            "Epoch 2, Batch 151, test Loss: 0.9767035841941833\n",
            "Epoch 2, Batch 152, test Loss: 0.8283365964889526\n",
            "Epoch 2, Batch 153, test Loss: 1.0539566278457642\n",
            "Epoch 2, Batch 154, test Loss: 0.8698228597640991\n",
            "Epoch 2, Batch 155, test Loss: 1.1091288328170776\n",
            "Epoch 2, Batch 156, test Loss: 1.2632901668548584\n",
            "Epoch 2, Accuracy of test set: 0.615\n",
            "Epoch 3/25:\n",
            "Train Loss: 0.0194, Train Accuracy: 0.55\n",
            "Test Loss: 0.0154, Test Accuracy: 0.61\n",
            "Accuracy of train set: 0.6587333333333333\n",
            "Epoch 3, Batch 0, test Loss: 1.200100302696228\n",
            "Epoch 3, Batch 1, test Loss: 0.8342198133468628\n",
            "Epoch 3, Batch 2, test Loss: 1.127910852432251\n",
            "Epoch 3, Batch 3, test Loss: 1.0650092363357544\n",
            "Epoch 3, Batch 4, test Loss: 1.0444202423095703\n",
            "Epoch 3, Batch 5, test Loss: 0.8724730014801025\n",
            "Epoch 3, Batch 6, test Loss: 0.914043128490448\n",
            "Epoch 3, Batch 7, test Loss: 0.8864464163780212\n",
            "Epoch 3, Batch 8, test Loss: 1.0006458759307861\n",
            "Epoch 3, Batch 9, test Loss: 1.130927562713623\n",
            "Epoch 3, Batch 10, test Loss: 1.0780476331710815\n",
            "Epoch 3, Batch 11, test Loss: 0.7995190024375916\n",
            "Epoch 3, Batch 12, test Loss: 1.0228508710861206\n",
            "Epoch 3, Batch 13, test Loss: 1.3344537019729614\n",
            "Epoch 3, Batch 14, test Loss: 0.690723180770874\n",
            "Epoch 3, Batch 15, test Loss: 0.9195221662521362\n",
            "Epoch 3, Batch 16, test Loss: 0.8311867713928223\n",
            "Epoch 3, Batch 17, test Loss: 0.7915300130844116\n",
            "Epoch 3, Batch 18, test Loss: 0.9476869702339172\n",
            "Epoch 3, Batch 19, test Loss: 0.8930968046188354\n",
            "Epoch 3, Batch 20, test Loss: 0.9775400161743164\n",
            "Epoch 3, Batch 21, test Loss: 0.9430267810821533\n",
            "Epoch 3, Batch 22, test Loss: 0.806347668170929\n",
            "Epoch 3, Batch 23, test Loss: 0.9207882285118103\n",
            "Epoch 3, Batch 24, test Loss: 0.8841518759727478\n",
            "Epoch 3, Batch 25, test Loss: 0.9860762357711792\n",
            "Epoch 3, Batch 26, test Loss: 0.8096669912338257\n",
            "Epoch 3, Batch 27, test Loss: 1.027712345123291\n",
            "Epoch 3, Batch 28, test Loss: 1.218145489692688\n",
            "Epoch 3, Batch 29, test Loss: 1.0002973079681396\n",
            "Epoch 3, Batch 30, test Loss: 0.9289056658744812\n",
            "Epoch 3, Batch 31, test Loss: 0.9783430099487305\n",
            "Epoch 3, Batch 32, test Loss: 1.1131733655929565\n",
            "Epoch 3, Batch 33, test Loss: 1.1260700225830078\n",
            "Epoch 3, Batch 34, test Loss: 0.8961796760559082\n",
            "Epoch 3, Batch 35, test Loss: 0.8150983452796936\n",
            "Epoch 3, Batch 36, test Loss: 1.2292910814285278\n",
            "Epoch 3, Batch 37, test Loss: 0.8684178590774536\n",
            "Epoch 3, Batch 38, test Loss: 1.403123140335083\n",
            "Epoch 3, Batch 39, test Loss: 1.0435210466384888\n",
            "Epoch 3, Batch 40, test Loss: 0.7821134328842163\n",
            "Epoch 3, Batch 41, test Loss: 1.3019007444381714\n",
            "Epoch 3, Batch 42, test Loss: 1.0288714170455933\n",
            "Epoch 3, Batch 43, test Loss: 0.8335510492324829\n",
            "Epoch 3, Batch 44, test Loss: 1.2494009733200073\n",
            "Epoch 3, Batch 45, test Loss: 0.8167227506637573\n",
            "Epoch 3, Batch 46, test Loss: 0.8937082886695862\n",
            "Epoch 3, Batch 47, test Loss: 1.0172309875488281\n",
            "Epoch 3, Batch 48, test Loss: 1.0750212669372559\n",
            "Epoch 3, Batch 49, test Loss: 1.0341064929962158\n",
            "Epoch 3, Batch 50, test Loss: 1.0097908973693848\n",
            "Epoch 3, Batch 51, test Loss: 0.9435406923294067\n",
            "Epoch 3, Batch 52, test Loss: 0.7911511063575745\n",
            "Epoch 3, Batch 53, test Loss: 1.019479513168335\n",
            "Epoch 3, Batch 54, test Loss: 0.9753822684288025\n",
            "Epoch 3, Batch 55, test Loss: 1.2404515743255615\n",
            "Epoch 3, Batch 56, test Loss: 0.9908173084259033\n",
            "Epoch 3, Batch 57, test Loss: 1.2025794982910156\n",
            "Epoch 3, Batch 58, test Loss: 0.8972257375717163\n",
            "Epoch 3, Batch 59, test Loss: 1.049174189567566\n",
            "Epoch 3, Batch 60, test Loss: 1.2562178373336792\n",
            "Epoch 3, Batch 61, test Loss: 1.0389498472213745\n",
            "Epoch 3, Batch 62, test Loss: 1.3911700248718262\n",
            "Epoch 3, Batch 63, test Loss: 0.9552448391914368\n",
            "Epoch 3, Batch 64, test Loss: 1.04719877243042\n",
            "Epoch 3, Batch 65, test Loss: 1.0582466125488281\n",
            "Epoch 3, Batch 66, test Loss: 1.0537580251693726\n",
            "Epoch 3, Batch 67, test Loss: 0.9720306992530823\n",
            "Epoch 3, Batch 68, test Loss: 1.3344790935516357\n",
            "Epoch 3, Batch 69, test Loss: 1.2261950969696045\n",
            "Epoch 3, Batch 70, test Loss: 1.1662448644638062\n",
            "Epoch 3, Batch 71, test Loss: 0.890579879283905\n",
            "Epoch 3, Batch 72, test Loss: 0.7664121389389038\n",
            "Epoch 3, Batch 73, test Loss: 0.8261648416519165\n",
            "Epoch 3, Batch 74, test Loss: 0.9059722423553467\n",
            "Epoch 3, Batch 75, test Loss: 0.9661633968353271\n",
            "Epoch 3, Batch 76, test Loss: 0.9562044739723206\n",
            "Epoch 3, Batch 77, test Loss: 0.9996508359909058\n",
            "Epoch 3, Batch 78, test Loss: 1.1381388902664185\n",
            "Epoch 3, Batch 79, test Loss: 1.1084988117218018\n",
            "Epoch 3, Batch 80, test Loss: 1.085132360458374\n",
            "Epoch 3, Batch 81, test Loss: 0.978965163230896\n",
            "Epoch 3, Batch 82, test Loss: 0.8769248723983765\n",
            "Epoch 3, Batch 83, test Loss: 0.8997676372528076\n",
            "Epoch 3, Batch 84, test Loss: 0.9342438578605652\n",
            "Epoch 3, Batch 85, test Loss: 0.9641236066818237\n",
            "Epoch 3, Batch 86, test Loss: 0.8890584707260132\n",
            "Epoch 3, Batch 87, test Loss: 0.9539948105812073\n",
            "Epoch 3, Batch 88, test Loss: 1.0332504510879517\n",
            "Epoch 3, Batch 89, test Loss: 1.0187393426895142\n",
            "Epoch 3, Batch 90, test Loss: 1.1226855516433716\n",
            "Epoch 3, Batch 91, test Loss: 0.9892728924751282\n",
            "Epoch 3, Batch 92, test Loss: 1.1873198747634888\n",
            "Epoch 3, Batch 93, test Loss: 1.3093528747558594\n",
            "Epoch 3, Batch 94, test Loss: 0.8382364511489868\n",
            "Epoch 3, Batch 95, test Loss: 0.9492135047912598\n",
            "Epoch 3, Batch 96, test Loss: 1.070465087890625\n",
            "Epoch 3, Batch 97, test Loss: 1.0453554391860962\n",
            "Epoch 3, Batch 98, test Loss: 1.2325968742370605\n",
            "Epoch 3, Batch 99, test Loss: 1.2838094234466553\n",
            "Epoch 3, Batch 100, test Loss: 1.2338874340057373\n",
            "Epoch 3, Batch 101, test Loss: 0.8587756156921387\n",
            "Epoch 3, Batch 102, test Loss: 1.2044869661331177\n",
            "Epoch 3, Batch 103, test Loss: 0.9563073515892029\n",
            "Epoch 3, Batch 104, test Loss: 0.9519902467727661\n",
            "Epoch 3, Batch 105, test Loss: 1.0021164417266846\n",
            "Epoch 3, Batch 106, test Loss: 1.132497787475586\n",
            "Epoch 3, Batch 107, test Loss: 0.937438428401947\n",
            "Epoch 3, Batch 108, test Loss: 1.1782079935073853\n",
            "Epoch 3, Batch 109, test Loss: 1.1008967161178589\n",
            "Epoch 3, Batch 110, test Loss: 0.9892520904541016\n",
            "Epoch 3, Batch 111, test Loss: 1.0197337865829468\n",
            "Epoch 3, Batch 112, test Loss: 0.9256879091262817\n",
            "Epoch 3, Batch 113, test Loss: 0.7932955026626587\n",
            "Epoch 3, Batch 114, test Loss: 0.818388819694519\n",
            "Epoch 3, Batch 115, test Loss: 1.0610477924346924\n",
            "Epoch 3, Batch 116, test Loss: 0.8594123721122742\n",
            "Epoch 3, Batch 117, test Loss: 1.03783118724823\n",
            "Epoch 3, Batch 118, test Loss: 0.9896076917648315\n",
            "Epoch 3, Batch 119, test Loss: 1.007659912109375\n",
            "Epoch 3, Batch 120, test Loss: 1.1142463684082031\n",
            "Epoch 3, Batch 121, test Loss: 0.9854426980018616\n",
            "Epoch 3, Batch 122, test Loss: 1.0173813104629517\n",
            "Epoch 3, Batch 123, test Loss: 0.8331939578056335\n",
            "Epoch 3, Batch 124, test Loss: 1.0053104162216187\n",
            "Epoch 3, Batch 125, test Loss: 0.9053139686584473\n",
            "Epoch 3, Batch 126, test Loss: 1.1425118446350098\n",
            "Epoch 3, Batch 127, test Loss: 0.9600635766983032\n",
            "Epoch 3, Batch 128, test Loss: 0.9156897068023682\n",
            "Epoch 3, Batch 129, test Loss: 0.8132730722427368\n",
            "Epoch 3, Batch 130, test Loss: 0.90933758020401\n",
            "Epoch 3, Batch 131, test Loss: 1.3891491889953613\n",
            "Epoch 3, Batch 132, test Loss: 0.9730890393257141\n",
            "Epoch 3, Batch 133, test Loss: 0.9040274024009705\n",
            "Epoch 3, Batch 134, test Loss: 0.9395477175712585\n",
            "Epoch 3, Batch 135, test Loss: 1.064067006111145\n",
            "Epoch 3, Batch 136, test Loss: 1.2197803258895874\n",
            "Epoch 3, Batch 137, test Loss: 0.8171678781509399\n",
            "Epoch 3, Batch 138, test Loss: 0.8889861106872559\n",
            "Epoch 3, Batch 139, test Loss: 0.8372877836227417\n",
            "Epoch 3, Batch 140, test Loss: 0.9856929183006287\n",
            "Epoch 3, Batch 141, test Loss: 0.8890644311904907\n",
            "Epoch 3, Batch 142, test Loss: 1.0671100616455078\n",
            "Epoch 3, Batch 143, test Loss: 0.9535903930664062\n",
            "Epoch 3, Batch 144, test Loss: 1.0968149900436401\n",
            "Epoch 3, Batch 145, test Loss: 0.7910664081573486\n",
            "Epoch 3, Batch 146, test Loss: 1.0296456813812256\n",
            "Epoch 3, Batch 147, test Loss: 1.098724603652954\n",
            "Epoch 3, Batch 148, test Loss: 0.6591391563415527\n",
            "Epoch 3, Batch 149, test Loss: 0.9394628405570984\n",
            "Epoch 3, Batch 150, test Loss: 0.9347410202026367\n",
            "Epoch 3, Batch 151, test Loss: 0.8515799045562744\n",
            "Epoch 3, Batch 152, test Loss: 1.055631399154663\n",
            "Epoch 3, Batch 153, test Loss: 1.1077744960784912\n",
            "Epoch 3, Batch 154, test Loss: 1.1211614608764648\n",
            "Epoch 3, Batch 155, test Loss: 0.9103072881698608\n",
            "Epoch 3, Batch 156, test Loss: 1.211693286895752\n",
            "Epoch 3, Accuracy of test set: 0.6087\n",
            "Epoch 4/25:\n",
            "Train Loss: 0.0139, Train Accuracy: 0.66\n",
            "Test Loss: 0.0158, Test Accuracy: 0.61\n",
            "Accuracy of train set: 0.7066833333333333\n",
            "Epoch 4, Batch 0, test Loss: 0.6163321137428284\n",
            "Epoch 4, Batch 1, test Loss: 0.6078405380249023\n",
            "Epoch 4, Batch 2, test Loss: 0.8893170952796936\n",
            "Epoch 4, Batch 3, test Loss: 0.5853471159934998\n",
            "Epoch 4, Batch 4, test Loss: 0.7931073904037476\n",
            "Epoch 4, Batch 5, test Loss: 1.0162415504455566\n",
            "Epoch 4, Batch 6, test Loss: 0.6807758212089539\n",
            "Epoch 4, Batch 7, test Loss: 1.0257536172866821\n",
            "Epoch 4, Batch 8, test Loss: 0.7903514504432678\n",
            "Epoch 4, Batch 9, test Loss: 0.6807152628898621\n",
            "Epoch 4, Batch 10, test Loss: 0.7843772768974304\n",
            "Epoch 4, Batch 11, test Loss: 0.855037271976471\n",
            "Epoch 4, Batch 12, test Loss: 0.8708940744400024\n",
            "Epoch 4, Batch 13, test Loss: 0.795011043548584\n",
            "Epoch 4, Batch 14, test Loss: 0.8225362300872803\n",
            "Epoch 4, Batch 15, test Loss: 0.7006358504295349\n",
            "Epoch 4, Batch 16, test Loss: 0.6982042789459229\n",
            "Epoch 4, Batch 17, test Loss: 1.0102887153625488\n",
            "Epoch 4, Batch 18, test Loss: 0.7897506952285767\n",
            "Epoch 4, Batch 19, test Loss: 0.8906145095825195\n",
            "Epoch 4, Batch 20, test Loss: 0.7127529382705688\n",
            "Epoch 4, Batch 21, test Loss: 0.697711169719696\n",
            "Epoch 4, Batch 22, test Loss: 0.6905136108398438\n",
            "Epoch 4, Batch 23, test Loss: 0.6329274773597717\n",
            "Epoch 4, Batch 24, test Loss: 0.7790672779083252\n",
            "Epoch 4, Batch 25, test Loss: 0.7339114546775818\n",
            "Epoch 4, Batch 26, test Loss: 0.8077461123466492\n",
            "Epoch 4, Batch 27, test Loss: 0.7381621599197388\n",
            "Epoch 4, Batch 28, test Loss: 0.6706604957580566\n",
            "Epoch 4, Batch 29, test Loss: 0.6472867727279663\n",
            "Epoch 4, Batch 30, test Loss: 0.9015011787414551\n",
            "Epoch 4, Batch 31, test Loss: 0.5496523976325989\n",
            "Epoch 4, Batch 32, test Loss: 0.947235643863678\n",
            "Epoch 4, Batch 33, test Loss: 0.9417556524276733\n",
            "Epoch 4, Batch 34, test Loss: 0.7341692447662354\n",
            "Epoch 4, Batch 35, test Loss: 0.7646766304969788\n",
            "Epoch 4, Batch 36, test Loss: 0.8191471695899963\n",
            "Epoch 4, Batch 37, test Loss: 0.6075607538223267\n",
            "Epoch 4, Batch 38, test Loss: 0.5943191647529602\n",
            "Epoch 4, Batch 39, test Loss: 0.8640696406364441\n",
            "Epoch 4, Batch 40, test Loss: 0.8964290618896484\n",
            "Epoch 4, Batch 41, test Loss: 0.6259584426879883\n",
            "Epoch 4, Batch 42, test Loss: 0.6952701210975647\n",
            "Epoch 4, Batch 43, test Loss: 0.7523019313812256\n",
            "Epoch 4, Batch 44, test Loss: 0.9485042095184326\n",
            "Epoch 4, Batch 45, test Loss: 0.871756374835968\n",
            "Epoch 4, Batch 46, test Loss: 0.6361767649650574\n",
            "Epoch 4, Batch 47, test Loss: 0.9430148005485535\n",
            "Epoch 4, Batch 48, test Loss: 0.7824164032936096\n",
            "Epoch 4, Batch 49, test Loss: 0.7427523136138916\n",
            "Epoch 4, Batch 50, test Loss: 0.799487829208374\n",
            "Epoch 4, Batch 51, test Loss: 0.710128664970398\n",
            "Epoch 4, Batch 52, test Loss: 0.7614046931266785\n",
            "Epoch 4, Batch 53, test Loss: 0.5432551503181458\n",
            "Epoch 4, Batch 54, test Loss: 0.7917298078536987\n",
            "Epoch 4, Batch 55, test Loss: 0.9528365731239319\n",
            "Epoch 4, Batch 56, test Loss: 0.8065169453620911\n",
            "Epoch 4, Batch 57, test Loss: 0.8725964426994324\n",
            "Epoch 4, Batch 58, test Loss: 0.8243595957756042\n",
            "Epoch 4, Batch 59, test Loss: 1.0388370752334595\n",
            "Epoch 4, Batch 60, test Loss: 0.8658123016357422\n",
            "Epoch 4, Batch 61, test Loss: 0.7922605872154236\n",
            "Epoch 4, Batch 62, test Loss: 0.7794386744499207\n",
            "Epoch 4, Batch 63, test Loss: 0.8247580528259277\n",
            "Epoch 4, Batch 64, test Loss: 0.6599907875061035\n",
            "Epoch 4, Batch 65, test Loss: 0.825565755367279\n",
            "Epoch 4, Batch 66, test Loss: 0.969460666179657\n",
            "Epoch 4, Batch 67, test Loss: 1.156732439994812\n",
            "Epoch 4, Batch 68, test Loss: 0.8447442650794983\n",
            "Epoch 4, Batch 69, test Loss: 0.700846254825592\n",
            "Epoch 4, Batch 70, test Loss: 0.7176817059516907\n",
            "Epoch 4, Batch 71, test Loss: 0.8152182698249817\n",
            "Epoch 4, Batch 72, test Loss: 0.7861391305923462\n",
            "Epoch 4, Batch 73, test Loss: 0.7309107780456543\n",
            "Epoch 4, Batch 74, test Loss: 0.780164361000061\n",
            "Epoch 4, Batch 75, test Loss: 0.7487764358520508\n",
            "Epoch 4, Batch 76, test Loss: 0.7466499209403992\n",
            "Epoch 4, Batch 77, test Loss: 0.8786166906356812\n",
            "Epoch 4, Batch 78, test Loss: 0.6804325580596924\n",
            "Epoch 4, Batch 79, test Loss: 0.8912124037742615\n",
            "Epoch 4, Batch 80, test Loss: 0.727484941482544\n",
            "Epoch 4, Batch 81, test Loss: 0.8048708438873291\n",
            "Epoch 4, Batch 82, test Loss: 0.6846513748168945\n",
            "Epoch 4, Batch 83, test Loss: 0.8454364538192749\n",
            "Epoch 4, Batch 84, test Loss: 0.9054063558578491\n",
            "Epoch 4, Batch 85, test Loss: 0.6966864466667175\n",
            "Epoch 4, Batch 86, test Loss: 0.9129754900932312\n",
            "Epoch 4, Batch 87, test Loss: 0.7465035319328308\n",
            "Epoch 4, Batch 88, test Loss: 0.7554741501808167\n",
            "Epoch 4, Batch 89, test Loss: 0.8937257528305054\n",
            "Epoch 4, Batch 90, test Loss: 0.6737419962882996\n",
            "Epoch 4, Batch 91, test Loss: 0.6833096742630005\n",
            "Epoch 4, Batch 92, test Loss: 0.8110318779945374\n",
            "Epoch 4, Batch 93, test Loss: 0.6411044001579285\n",
            "Epoch 4, Batch 94, test Loss: 1.0015357732772827\n",
            "Epoch 4, Batch 95, test Loss: 0.6437716484069824\n",
            "Epoch 4, Batch 96, test Loss: 0.817417562007904\n",
            "Epoch 4, Batch 97, test Loss: 0.7589499950408936\n",
            "Epoch 4, Batch 98, test Loss: 0.6230639219284058\n",
            "Epoch 4, Batch 99, test Loss: 0.5470896363258362\n",
            "Epoch 4, Batch 100, test Loss: 0.8547501564025879\n",
            "Epoch 4, Batch 101, test Loss: 0.8696030378341675\n",
            "Epoch 4, Batch 102, test Loss: 0.8390911221504211\n",
            "Epoch 4, Batch 103, test Loss: 0.6445716619491577\n",
            "Epoch 4, Batch 104, test Loss: 0.8784918189048767\n",
            "Epoch 4, Batch 105, test Loss: 0.552259624004364\n",
            "Epoch 4, Batch 106, test Loss: 0.6545247435569763\n",
            "Epoch 4, Batch 107, test Loss: 0.7197223901748657\n",
            "Epoch 4, Batch 108, test Loss: 0.9229840040206909\n",
            "Epoch 4, Batch 109, test Loss: 0.8171855211257935\n",
            "Epoch 4, Batch 110, test Loss: 0.76109379529953\n",
            "Epoch 4, Batch 111, test Loss: 0.7643176913261414\n",
            "Epoch 4, Batch 112, test Loss: 0.7827441692352295\n",
            "Epoch 4, Batch 113, test Loss: 0.8964455723762512\n",
            "Epoch 4, Batch 114, test Loss: 0.9714306592941284\n",
            "Epoch 4, Batch 115, test Loss: 0.5296786427497864\n",
            "Epoch 4, Batch 116, test Loss: 0.7753676772117615\n",
            "Epoch 4, Batch 117, test Loss: 0.8246605396270752\n",
            "Epoch 4, Batch 118, test Loss: 0.9255863428115845\n",
            "Epoch 4, Batch 119, test Loss: 0.7803569436073303\n",
            "Epoch 4, Batch 120, test Loss: 0.7717732191085815\n",
            "Epoch 4, Batch 121, test Loss: 0.5743646621704102\n",
            "Epoch 4, Batch 122, test Loss: 0.6476153135299683\n",
            "Epoch 4, Batch 123, test Loss: 0.673378586769104\n",
            "Epoch 4, Batch 124, test Loss: 0.8557081818580627\n",
            "Epoch 4, Batch 125, test Loss: 0.8552583456039429\n",
            "Epoch 4, Batch 126, test Loss: 0.9864330291748047\n",
            "Epoch 4, Batch 127, test Loss: 0.7086596488952637\n",
            "Epoch 4, Batch 128, test Loss: 0.7274669408798218\n",
            "Epoch 4, Batch 129, test Loss: 0.5765959620475769\n",
            "Epoch 4, Batch 130, test Loss: 0.8288385272026062\n",
            "Epoch 4, Batch 131, test Loss: 0.7838398814201355\n",
            "Epoch 4, Batch 132, test Loss: 0.811025857925415\n",
            "Epoch 4, Batch 133, test Loss: 0.688484787940979\n",
            "Epoch 4, Batch 134, test Loss: 0.86280357837677\n",
            "Epoch 4, Batch 135, test Loss: 0.9558943510055542\n",
            "Epoch 4, Batch 136, test Loss: 0.967838704586029\n",
            "Epoch 4, Batch 137, test Loss: 0.7691177725791931\n",
            "Epoch 4, Batch 138, test Loss: 1.066031575202942\n",
            "Epoch 4, Batch 139, test Loss: 0.7861371040344238\n",
            "Epoch 4, Batch 140, test Loss: 0.8703906536102295\n",
            "Epoch 4, Batch 141, test Loss: 0.68292236328125\n",
            "Epoch 4, Batch 142, test Loss: 0.6731523275375366\n",
            "Epoch 4, Batch 143, test Loss: 0.8221535682678223\n",
            "Epoch 4, Batch 144, test Loss: 0.7808829545974731\n",
            "Epoch 4, Batch 145, test Loss: 0.7772237658500671\n",
            "Epoch 4, Batch 146, test Loss: 0.6986035108566284\n",
            "Epoch 4, Batch 147, test Loss: 0.7848339080810547\n",
            "Epoch 4, Batch 148, test Loss: 0.8170915842056274\n",
            "Epoch 4, Batch 149, test Loss: 0.5774520635604858\n",
            "Epoch 4, Batch 150, test Loss: 0.9341732859611511\n",
            "Epoch 4, Batch 151, test Loss: 0.745597779750824\n",
            "Epoch 4, Batch 152, test Loss: 0.8014610409736633\n",
            "Epoch 4, Batch 153, test Loss: 0.9387790560722351\n",
            "Epoch 4, Batch 154, test Loss: 0.7937648296356201\n",
            "Epoch 4, Batch 155, test Loss: 0.7159289717674255\n",
            "Epoch 4, Batch 156, test Loss: 1.0060006380081177\n",
            "Epoch 4, Accuracy of test set: 0.7242\n",
            "Epoch 5/25:\n",
            "Train Loss: 0.0125, Train Accuracy: 0.71\n",
            "Test Loss: 0.0123, Test Accuracy: 0.72\n",
            "Accuracy of train set: 0.7407333333333334\n",
            "Epoch 5, Batch 0, test Loss: 1.0881812572479248\n",
            "Epoch 5, Batch 1, test Loss: 0.6905148029327393\n",
            "Epoch 5, Batch 2, test Loss: 0.6084960699081421\n",
            "Epoch 5, Batch 3, test Loss: 0.6513265371322632\n",
            "Epoch 5, Batch 4, test Loss: 0.7063597440719604\n",
            "Epoch 5, Batch 5, test Loss: 0.6722013354301453\n",
            "Epoch 5, Batch 6, test Loss: 0.6229246854782104\n",
            "Epoch 5, Batch 7, test Loss: 0.8279594779014587\n",
            "Epoch 5, Batch 8, test Loss: 0.6410505771636963\n",
            "Epoch 5, Batch 9, test Loss: 0.5679050087928772\n",
            "Epoch 5, Batch 10, test Loss: 0.7576485276222229\n",
            "Epoch 5, Batch 11, test Loss: 0.7019774317741394\n",
            "Epoch 5, Batch 12, test Loss: 0.6251493692398071\n",
            "Epoch 5, Batch 13, test Loss: 0.6137633919715881\n",
            "Epoch 5, Batch 14, test Loss: 0.8445150852203369\n",
            "Epoch 5, Batch 15, test Loss: 0.8192905187606812\n",
            "Epoch 5, Batch 16, test Loss: 0.6039203405380249\n",
            "Epoch 5, Batch 17, test Loss: 0.6901444792747498\n",
            "Epoch 5, Batch 18, test Loss: 0.5710223913192749\n",
            "Epoch 5, Batch 19, test Loss: 0.6740770936012268\n",
            "Epoch 5, Batch 20, test Loss: 0.5969165563583374\n",
            "Epoch 5, Batch 21, test Loss: 0.5786994695663452\n",
            "Epoch 5, Batch 22, test Loss: 0.8569197058677673\n",
            "Epoch 5, Batch 23, test Loss: 1.0212888717651367\n",
            "Epoch 5, Batch 24, test Loss: 0.6545981168746948\n",
            "Epoch 5, Batch 25, test Loss: 0.8164778351783752\n",
            "Epoch 5, Batch 26, test Loss: 0.7383065819740295\n",
            "Epoch 5, Batch 27, test Loss: 0.44780784845352173\n",
            "Epoch 5, Batch 28, test Loss: 0.5527046918869019\n",
            "Epoch 5, Batch 29, test Loss: 0.6473290920257568\n",
            "Epoch 5, Batch 30, test Loss: 0.4515117406845093\n",
            "Epoch 5, Batch 31, test Loss: 0.6613913774490356\n",
            "Epoch 5, Batch 32, test Loss: 0.5499361753463745\n",
            "Epoch 5, Batch 33, test Loss: 0.7572100758552551\n",
            "Epoch 5, Batch 34, test Loss: 0.6804789900779724\n",
            "Epoch 5, Batch 35, test Loss: 0.9215326905250549\n",
            "Epoch 5, Batch 36, test Loss: 0.6007832884788513\n",
            "Epoch 5, Batch 37, test Loss: 0.9740006923675537\n",
            "Epoch 5, Batch 38, test Loss: 0.5808750987052917\n",
            "Epoch 5, Batch 39, test Loss: 0.5720745325088501\n",
            "Epoch 5, Batch 40, test Loss: 0.7585051655769348\n",
            "Epoch 5, Batch 41, test Loss: 0.6630706787109375\n",
            "Epoch 5, Batch 42, test Loss: 0.6491519808769226\n",
            "Epoch 5, Batch 43, test Loss: 0.7011556029319763\n",
            "Epoch 5, Batch 44, test Loss: 0.7053055763244629\n",
            "Epoch 5, Batch 45, test Loss: 0.7523808479309082\n",
            "Epoch 5, Batch 46, test Loss: 0.641636312007904\n",
            "Epoch 5, Batch 47, test Loss: 0.870665431022644\n",
            "Epoch 5, Batch 48, test Loss: 0.7219988107681274\n",
            "Epoch 5, Batch 49, test Loss: 0.6606960296630859\n",
            "Epoch 5, Batch 50, test Loss: 0.6908839344978333\n",
            "Epoch 5, Batch 51, test Loss: 0.6091965436935425\n",
            "Epoch 5, Batch 52, test Loss: 0.5556080341339111\n",
            "Epoch 5, Batch 53, test Loss: 0.8018473386764526\n",
            "Epoch 5, Batch 54, test Loss: 0.7528563737869263\n",
            "Epoch 5, Batch 55, test Loss: 0.6947837471961975\n",
            "Epoch 5, Batch 56, test Loss: 0.8874902129173279\n",
            "Epoch 5, Batch 57, test Loss: 0.6494505405426025\n",
            "Epoch 5, Batch 58, test Loss: 0.6721596121788025\n",
            "Epoch 5, Batch 59, test Loss: 0.750489354133606\n",
            "Epoch 5, Batch 60, test Loss: 0.6985152959823608\n",
            "Epoch 5, Batch 61, test Loss: 0.554159939289093\n",
            "Epoch 5, Batch 62, test Loss: 0.546988308429718\n",
            "Epoch 5, Batch 63, test Loss: 0.480558842420578\n",
            "Epoch 5, Batch 64, test Loss: 0.7081210613250732\n",
            "Epoch 5, Batch 65, test Loss: 0.5432618260383606\n",
            "Epoch 5, Batch 66, test Loss: 0.7658188939094543\n",
            "Epoch 5, Batch 67, test Loss: 0.5439274311065674\n",
            "Epoch 5, Batch 68, test Loss: 0.618453860282898\n",
            "Epoch 5, Batch 69, test Loss: 0.6050931215286255\n",
            "Epoch 5, Batch 70, test Loss: 0.8947699666023254\n",
            "Epoch 5, Batch 71, test Loss: 0.7004188299179077\n",
            "Epoch 5, Batch 72, test Loss: 0.7918614745140076\n",
            "Epoch 5, Batch 73, test Loss: 0.6873130798339844\n",
            "Epoch 5, Batch 74, test Loss: 0.6252544522285461\n",
            "Epoch 5, Batch 75, test Loss: 0.8854530453681946\n",
            "Epoch 5, Batch 76, test Loss: 0.5817136764526367\n",
            "Epoch 5, Batch 77, test Loss: 0.7428064346313477\n",
            "Epoch 5, Batch 78, test Loss: 0.843377411365509\n",
            "Epoch 5, Batch 79, test Loss: 0.5565376877784729\n",
            "Epoch 5, Batch 80, test Loss: 0.8641228079795837\n",
            "Epoch 5, Batch 81, test Loss: 0.5475499629974365\n",
            "Epoch 5, Batch 82, test Loss: 0.6997240781784058\n",
            "Epoch 5, Batch 83, test Loss: 0.8320354223251343\n",
            "Epoch 5, Batch 84, test Loss: 0.7395941615104675\n",
            "Epoch 5, Batch 85, test Loss: 0.7345353960990906\n",
            "Epoch 5, Batch 86, test Loss: 0.6490750312805176\n",
            "Epoch 5, Batch 87, test Loss: 0.694712221622467\n",
            "Epoch 5, Batch 88, test Loss: 0.6641071438789368\n",
            "Epoch 5, Batch 89, test Loss: 0.7451402544975281\n",
            "Epoch 5, Batch 90, test Loss: 0.7315355539321899\n",
            "Epoch 5, Batch 91, test Loss: 0.7859877943992615\n",
            "Epoch 5, Batch 92, test Loss: 0.5895357131958008\n",
            "Epoch 5, Batch 93, test Loss: 0.7642243504524231\n",
            "Epoch 5, Batch 94, test Loss: 0.7084640264511108\n",
            "Epoch 5, Batch 95, test Loss: 0.6990935206413269\n",
            "Epoch 5, Batch 96, test Loss: 0.6293541789054871\n",
            "Epoch 5, Batch 97, test Loss: 0.582732617855072\n",
            "Epoch 5, Batch 98, test Loss: 0.614161491394043\n",
            "Epoch 5, Batch 99, test Loss: 0.7566094994544983\n",
            "Epoch 5, Batch 100, test Loss: 0.6202757954597473\n",
            "Epoch 5, Batch 101, test Loss: 0.955163836479187\n",
            "Epoch 5, Batch 102, test Loss: 0.8255834579467773\n",
            "Epoch 5, Batch 103, test Loss: 0.5734866261482239\n",
            "Epoch 5, Batch 104, test Loss: 0.5944919586181641\n",
            "Epoch 5, Batch 105, test Loss: 0.7682833075523376\n",
            "Epoch 5, Batch 106, test Loss: 0.589476466178894\n",
            "Epoch 5, Batch 107, test Loss: 0.6456721425056458\n",
            "Epoch 5, Batch 108, test Loss: 0.6423857808113098\n",
            "Epoch 5, Batch 109, test Loss: 0.7555314302444458\n",
            "Epoch 5, Batch 110, test Loss: 1.0629022121429443\n",
            "Epoch 5, Batch 111, test Loss: 0.6221551299095154\n",
            "Epoch 5, Batch 112, test Loss: 0.744217038154602\n",
            "Epoch 5, Batch 113, test Loss: 0.7754497528076172\n",
            "Epoch 5, Batch 114, test Loss: 0.9923323392868042\n",
            "Epoch 5, Batch 115, test Loss: 0.5888193249702454\n",
            "Epoch 5, Batch 116, test Loss: 0.5303786993026733\n",
            "Epoch 5, Batch 117, test Loss: 0.7140144109725952\n",
            "Epoch 5, Batch 118, test Loss: 0.6850782036781311\n",
            "Epoch 5, Batch 119, test Loss: 0.6016253232955933\n",
            "Epoch 5, Batch 120, test Loss: 0.6199226975440979\n",
            "Epoch 5, Batch 121, test Loss: 0.6109262704849243\n",
            "Epoch 5, Batch 122, test Loss: 0.49251124262809753\n",
            "Epoch 5, Batch 123, test Loss: 0.817603349685669\n",
            "Epoch 5, Batch 124, test Loss: 0.5883748531341553\n",
            "Epoch 5, Batch 125, test Loss: 0.8677173852920532\n",
            "Epoch 5, Batch 126, test Loss: 0.6484420895576477\n",
            "Epoch 5, Batch 127, test Loss: 0.833202600479126\n",
            "Epoch 5, Batch 128, test Loss: 0.6915063261985779\n",
            "Epoch 5, Batch 129, test Loss: 0.694002628326416\n",
            "Epoch 5, Batch 130, test Loss: 0.6654254198074341\n",
            "Epoch 5, Batch 131, test Loss: 0.8034420013427734\n",
            "Epoch 5, Batch 132, test Loss: 0.7528173327445984\n",
            "Epoch 5, Batch 133, test Loss: 0.5367330312728882\n",
            "Epoch 5, Batch 134, test Loss: 0.6096372604370117\n",
            "Epoch 5, Batch 135, test Loss: 0.6672069430351257\n",
            "Epoch 5, Batch 136, test Loss: 0.8860005140304565\n",
            "Epoch 5, Batch 137, test Loss: 0.5173918008804321\n",
            "Epoch 5, Batch 138, test Loss: 0.8168981075286865\n",
            "Epoch 5, Batch 139, test Loss: 0.7267805337905884\n",
            "Epoch 5, Batch 140, test Loss: 0.6061409115791321\n",
            "Epoch 5, Batch 141, test Loss: 1.1414629220962524\n",
            "Epoch 5, Batch 142, test Loss: 0.7629398107528687\n",
            "Epoch 5, Batch 143, test Loss: 0.592633843421936\n",
            "Epoch 5, Batch 144, test Loss: 0.7326860427856445\n",
            "Epoch 5, Batch 145, test Loss: 0.5544341802597046\n",
            "Epoch 5, Batch 146, test Loss: 0.7311002016067505\n",
            "Epoch 5, Batch 147, test Loss: 0.7352701425552368\n",
            "Epoch 5, Batch 148, test Loss: 0.7252457141876221\n",
            "Epoch 5, Batch 149, test Loss: 0.5946880578994751\n",
            "Epoch 5, Batch 150, test Loss: 0.7020158171653748\n",
            "Epoch 5, Batch 151, test Loss: 0.7423004508018494\n",
            "Epoch 5, Batch 152, test Loss: 0.4715474545955658\n",
            "Epoch 5, Batch 153, test Loss: 0.7723404765129089\n",
            "Epoch 5, Batch 154, test Loss: 0.6997810006141663\n",
            "Epoch 5, Batch 155, test Loss: 0.6339400410652161\n",
            "Epoch 5, Batch 156, test Loss: 0.6833509802818298\n",
            "Epoch 5, Accuracy of test set: 0.755\n",
            "Epoch 6/25:\n",
            "Train Loss: 0.0114, Train Accuracy: 0.74\n",
            "Test Loss: 0.0109, Test Accuracy: 0.76\n",
            "Accuracy of train set: 0.7643\n",
            "Epoch 6, Batch 0, test Loss: 0.6420618891716003\n",
            "Epoch 6, Batch 1, test Loss: 0.5919588208198547\n",
            "Epoch 6, Batch 2, test Loss: 0.5345336198806763\n",
            "Epoch 6, Batch 3, test Loss: 0.4881657361984253\n",
            "Epoch 6, Batch 4, test Loss: 0.7625411152839661\n",
            "Epoch 6, Batch 5, test Loss: 0.6720791459083557\n",
            "Epoch 6, Batch 6, test Loss: 0.8652292490005493\n",
            "Epoch 6, Batch 7, test Loss: 0.5734871029853821\n",
            "Epoch 6, Batch 8, test Loss: 0.42634817957878113\n",
            "Epoch 6, Batch 9, test Loss: 0.934268593788147\n",
            "Epoch 6, Batch 10, test Loss: 0.540233850479126\n",
            "Epoch 6, Batch 11, test Loss: 0.6054947376251221\n",
            "Epoch 6, Batch 12, test Loss: 0.934310793876648\n",
            "Epoch 6, Batch 13, test Loss: 0.8554712533950806\n",
            "Epoch 6, Batch 14, test Loss: 0.7440852522850037\n",
            "Epoch 6, Batch 15, test Loss: 0.6410560011863708\n",
            "Epoch 6, Batch 16, test Loss: 0.7363999485969543\n",
            "Epoch 6, Batch 17, test Loss: 0.6549031138420105\n",
            "Epoch 6, Batch 18, test Loss: 0.7130062580108643\n",
            "Epoch 6, Batch 19, test Loss: 0.6714854836463928\n",
            "Epoch 6, Batch 20, test Loss: 0.4941798448562622\n",
            "Epoch 6, Batch 21, test Loss: 0.5091593265533447\n",
            "Epoch 6, Batch 22, test Loss: 0.6312671899795532\n",
            "Epoch 6, Batch 23, test Loss: 0.7379496693611145\n",
            "Epoch 6, Batch 24, test Loss: 0.7827872037887573\n",
            "Epoch 6, Batch 25, test Loss: 0.7944833636283875\n",
            "Epoch 6, Batch 26, test Loss: 0.6121323704719543\n",
            "Epoch 6, Batch 27, test Loss: 0.6684714555740356\n",
            "Epoch 6, Batch 28, test Loss: 0.4902034103870392\n",
            "Epoch 6, Batch 29, test Loss: 0.7861893773078918\n",
            "Epoch 6, Batch 30, test Loss: 0.7141703367233276\n",
            "Epoch 6, Batch 31, test Loss: 0.7449874877929688\n",
            "Epoch 6, Batch 32, test Loss: 0.6329612731933594\n",
            "Epoch 6, Batch 33, test Loss: 0.5461004972457886\n",
            "Epoch 6, Batch 34, test Loss: 0.7871140837669373\n",
            "Epoch 6, Batch 35, test Loss: 0.8650504350662231\n",
            "Epoch 6, Batch 36, test Loss: 0.7980208396911621\n",
            "Epoch 6, Batch 37, test Loss: 0.7998740077018738\n",
            "Epoch 6, Batch 38, test Loss: 0.7527182698249817\n",
            "Epoch 6, Batch 39, test Loss: 0.7027111053466797\n",
            "Epoch 6, Batch 40, test Loss: 0.5616713762283325\n",
            "Epoch 6, Batch 41, test Loss: 0.5729767084121704\n",
            "Epoch 6, Batch 42, test Loss: 0.5257697701454163\n",
            "Epoch 6, Batch 43, test Loss: 0.7986985445022583\n",
            "Epoch 6, Batch 44, test Loss: 0.7973765730857849\n",
            "Epoch 6, Batch 45, test Loss: 0.5526828169822693\n",
            "Epoch 6, Batch 46, test Loss: 0.5070199966430664\n",
            "Epoch 6, Batch 47, test Loss: 0.7960708141326904\n",
            "Epoch 6, Batch 48, test Loss: 0.7103389501571655\n",
            "Epoch 6, Batch 49, test Loss: 0.4852354824542999\n",
            "Epoch 6, Batch 50, test Loss: 0.547817051410675\n",
            "Epoch 6, Batch 51, test Loss: 0.4864090085029602\n",
            "Epoch 6, Batch 52, test Loss: 0.6271488666534424\n",
            "Epoch 6, Batch 53, test Loss: 0.5933615565299988\n",
            "Epoch 6, Batch 54, test Loss: 0.8153915405273438\n",
            "Epoch 6, Batch 55, test Loss: 0.7305660247802734\n",
            "Epoch 6, Batch 56, test Loss: 0.7773958444595337\n",
            "Epoch 6, Batch 57, test Loss: 0.7643324136734009\n",
            "Epoch 6, Batch 58, test Loss: 0.630596399307251\n",
            "Epoch 6, Batch 59, test Loss: 0.6287968158721924\n",
            "Epoch 6, Batch 60, test Loss: 0.43895357847213745\n",
            "Epoch 6, Batch 61, test Loss: 0.6009333729743958\n",
            "Epoch 6, Batch 62, test Loss: 0.7329328656196594\n",
            "Epoch 6, Batch 63, test Loss: 0.5554460287094116\n",
            "Epoch 6, Batch 64, test Loss: 0.7760571837425232\n",
            "Epoch 6, Batch 65, test Loss: 0.7842799425125122\n",
            "Epoch 6, Batch 66, test Loss: 0.5993176102638245\n",
            "Epoch 6, Batch 67, test Loss: 0.744917631149292\n",
            "Epoch 6, Batch 68, test Loss: 0.7413324117660522\n",
            "Epoch 6, Batch 69, test Loss: 0.5990215539932251\n",
            "Epoch 6, Batch 70, test Loss: 0.7672508955001831\n",
            "Epoch 6, Batch 71, test Loss: 0.6745834350585938\n",
            "Epoch 6, Batch 72, test Loss: 0.6925177574157715\n",
            "Epoch 6, Batch 73, test Loss: 0.8235192894935608\n",
            "Epoch 6, Batch 74, test Loss: 0.7555977702140808\n",
            "Epoch 6, Batch 75, test Loss: 0.5532225370407104\n",
            "Epoch 6, Batch 76, test Loss: 0.7364559173583984\n",
            "Epoch 6, Batch 77, test Loss: 0.6829490661621094\n",
            "Epoch 6, Batch 78, test Loss: 0.752019464969635\n",
            "Epoch 6, Batch 79, test Loss: 0.4991256594657898\n",
            "Epoch 6, Batch 80, test Loss: 0.7354812026023865\n",
            "Epoch 6, Batch 81, test Loss: 0.9357668161392212\n",
            "Epoch 6, Batch 82, test Loss: 0.5070998072624207\n",
            "Epoch 6, Batch 83, test Loss: 0.485414057970047\n",
            "Epoch 6, Batch 84, test Loss: 0.5155088901519775\n",
            "Epoch 6, Batch 85, test Loss: 0.5091301202774048\n",
            "Epoch 6, Batch 86, test Loss: 0.7446851134300232\n",
            "Epoch 6, Batch 87, test Loss: 0.6665210723876953\n",
            "Epoch 6, Batch 88, test Loss: 0.6395584344863892\n",
            "Epoch 6, Batch 89, test Loss: 0.6279181241989136\n",
            "Epoch 6, Batch 90, test Loss: 0.8596678972244263\n",
            "Epoch 6, Batch 91, test Loss: 0.6424457430839539\n",
            "Epoch 6, Batch 92, test Loss: 0.7074092626571655\n",
            "Epoch 6, Batch 93, test Loss: 0.8574206829071045\n",
            "Epoch 6, Batch 94, test Loss: 0.4976898729801178\n",
            "Epoch 6, Batch 95, test Loss: 0.7774734497070312\n",
            "Epoch 6, Batch 96, test Loss: 0.49419069290161133\n",
            "Epoch 6, Batch 97, test Loss: 0.6535320281982422\n",
            "Epoch 6, Batch 98, test Loss: 0.9434545636177063\n",
            "Epoch 6, Batch 99, test Loss: 0.6920494437217712\n",
            "Epoch 6, Batch 100, test Loss: 0.6659153699874878\n",
            "Epoch 6, Batch 101, test Loss: 0.7074752449989319\n",
            "Epoch 6, Batch 102, test Loss: 0.9289200305938721\n",
            "Epoch 6, Batch 103, test Loss: 0.6734474897384644\n",
            "Epoch 6, Batch 104, test Loss: 0.6260080337524414\n",
            "Epoch 6, Batch 105, test Loss: 0.6546391248703003\n",
            "Epoch 6, Batch 106, test Loss: 0.5664095282554626\n",
            "Epoch 6, Batch 107, test Loss: 0.5440045595169067\n",
            "Epoch 6, Batch 108, test Loss: 0.7589207291603088\n",
            "Epoch 6, Batch 109, test Loss: 0.5651691555976868\n",
            "Epoch 6, Batch 110, test Loss: 0.6832897663116455\n",
            "Epoch 6, Batch 111, test Loss: 0.6524783372879028\n",
            "Epoch 6, Batch 112, test Loss: 0.7203534245491028\n",
            "Epoch 6, Batch 113, test Loss: 0.5563265085220337\n",
            "Epoch 6, Batch 114, test Loss: 0.8977414965629578\n",
            "Epoch 6, Batch 115, test Loss: 0.668877124786377\n",
            "Epoch 6, Batch 116, test Loss: 0.41082876920700073\n",
            "Epoch 6, Batch 117, test Loss: 0.5791544914245605\n",
            "Epoch 6, Batch 118, test Loss: 0.8032016754150391\n",
            "Epoch 6, Batch 119, test Loss: 0.669427216053009\n",
            "Epoch 6, Batch 120, test Loss: 0.7035160064697266\n",
            "Epoch 6, Batch 121, test Loss: 0.5391440391540527\n",
            "Epoch 6, Batch 122, test Loss: 0.9648038744926453\n",
            "Epoch 6, Batch 123, test Loss: 0.4724733233451843\n",
            "Epoch 6, Batch 124, test Loss: 0.6620001792907715\n",
            "Epoch 6, Batch 125, test Loss: 0.3959207236766815\n",
            "Epoch 6, Batch 126, test Loss: 0.6748907566070557\n",
            "Epoch 6, Batch 127, test Loss: 0.8072822093963623\n",
            "Epoch 6, Batch 128, test Loss: 0.5820761322975159\n",
            "Epoch 6, Batch 129, test Loss: 0.7070944905281067\n",
            "Epoch 6, Batch 130, test Loss: 0.5983718037605286\n",
            "Epoch 6, Batch 131, test Loss: 0.7389973402023315\n",
            "Epoch 6, Batch 132, test Loss: 0.6552214622497559\n",
            "Epoch 6, Batch 133, test Loss: 0.6205385327339172\n",
            "Epoch 6, Batch 134, test Loss: 0.5011782646179199\n",
            "Epoch 6, Batch 135, test Loss: 0.708258330821991\n",
            "Epoch 6, Batch 136, test Loss: 0.6866206526756287\n",
            "Epoch 6, Batch 137, test Loss: 0.5906869769096375\n",
            "Epoch 6, Batch 138, test Loss: 0.6823334097862244\n",
            "Epoch 6, Batch 139, test Loss: 0.936168909072876\n",
            "Epoch 6, Batch 140, test Loss: 0.5948552489280701\n",
            "Epoch 6, Batch 141, test Loss: 0.7246166467666626\n",
            "Epoch 6, Batch 142, test Loss: 0.5313519835472107\n",
            "Epoch 6, Batch 143, test Loss: 0.5420487523078918\n",
            "Epoch 6, Batch 144, test Loss: 0.6204502582550049\n",
            "Epoch 6, Batch 145, test Loss: 0.698432981967926\n",
            "Epoch 6, Batch 146, test Loss: 0.9628186821937561\n",
            "Epoch 6, Batch 147, test Loss: 0.6409366726875305\n",
            "Epoch 6, Batch 148, test Loss: 0.6318162679672241\n",
            "Epoch 6, Batch 149, test Loss: 0.6682688593864441\n",
            "Epoch 6, Batch 150, test Loss: 0.5447053909301758\n",
            "Epoch 6, Batch 151, test Loss: 0.5646722316741943\n",
            "Epoch 6, Batch 152, test Loss: 0.5084502696990967\n",
            "Epoch 6, Batch 153, test Loss: 0.9572858214378357\n",
            "Epoch 6, Batch 154, test Loss: 0.6198879480361938\n",
            "Epoch 6, Batch 155, test Loss: 0.6506693363189697\n",
            "Epoch 6, Batch 156, test Loss: 0.6359682679176331\n",
            "Epoch 6, Accuracy of test set: 0.7649\n",
            "Epoch 7/25:\n",
            "Train Loss: 0.0103, Train Accuracy: 0.76\n",
            "Test Loss: 0.0105, Test Accuracy: 0.76\n",
            "Accuracy of train set: 0.7814166666666666\n",
            "Epoch 7, Batch 0, test Loss: 0.7234342098236084\n",
            "Epoch 7, Batch 1, test Loss: 0.517827570438385\n",
            "Epoch 7, Batch 2, test Loss: 0.5653821229934692\n",
            "Epoch 7, Batch 3, test Loss: 0.4917161464691162\n",
            "Epoch 7, Batch 4, test Loss: 0.53246009349823\n",
            "Epoch 7, Batch 5, test Loss: 0.7476099729537964\n",
            "Epoch 7, Batch 6, test Loss: 0.5329110622406006\n",
            "Epoch 7, Batch 7, test Loss: 0.6950202584266663\n",
            "Epoch 7, Batch 8, test Loss: 0.8838798999786377\n",
            "Epoch 7, Batch 9, test Loss: 0.5357633233070374\n",
            "Epoch 7, Batch 10, test Loss: 0.5521376132965088\n",
            "Epoch 7, Batch 11, test Loss: 0.6837599873542786\n",
            "Epoch 7, Batch 12, test Loss: 0.6685689687728882\n",
            "Epoch 7, Batch 13, test Loss: 0.6966357827186584\n",
            "Epoch 7, Batch 14, test Loss: 0.6369684934616089\n",
            "Epoch 7, Batch 15, test Loss: 0.6138157844543457\n",
            "Epoch 7, Batch 16, test Loss: 0.6038568615913391\n",
            "Epoch 7, Batch 17, test Loss: 0.5313587784767151\n",
            "Epoch 7, Batch 18, test Loss: 0.5628284215927124\n",
            "Epoch 7, Batch 19, test Loss: 0.6046934127807617\n",
            "Epoch 7, Batch 20, test Loss: 0.7592288255691528\n",
            "Epoch 7, Batch 21, test Loss: 0.6989331245422363\n",
            "Epoch 7, Batch 22, test Loss: 0.5108806490898132\n",
            "Epoch 7, Batch 23, test Loss: 0.7435705661773682\n",
            "Epoch 7, Batch 24, test Loss: 0.7744967937469482\n",
            "Epoch 7, Batch 25, test Loss: 0.6091071963310242\n",
            "Epoch 7, Batch 26, test Loss: 0.5223609209060669\n",
            "Epoch 7, Batch 27, test Loss: 0.596548855304718\n",
            "Epoch 7, Batch 28, test Loss: 0.7395689487457275\n",
            "Epoch 7, Batch 29, test Loss: 0.5807260870933533\n",
            "Epoch 7, Batch 30, test Loss: 0.649158239364624\n",
            "Epoch 7, Batch 31, test Loss: 0.438253790140152\n",
            "Epoch 7, Batch 32, test Loss: 0.5130850076675415\n",
            "Epoch 7, Batch 33, test Loss: 0.5289915204048157\n",
            "Epoch 7, Batch 34, test Loss: 0.5186519026756287\n",
            "Epoch 7, Batch 35, test Loss: 0.423137366771698\n",
            "Epoch 7, Batch 36, test Loss: 0.5906095504760742\n",
            "Epoch 7, Batch 37, test Loss: 0.6751126646995544\n",
            "Epoch 7, Batch 38, test Loss: 0.5893600583076477\n",
            "Epoch 7, Batch 39, test Loss: 0.764768660068512\n",
            "Epoch 7, Batch 40, test Loss: 0.49869027733802795\n",
            "Epoch 7, Batch 41, test Loss: 0.6728560924530029\n",
            "Epoch 7, Batch 42, test Loss: 0.6224107146263123\n",
            "Epoch 7, Batch 43, test Loss: 0.7973744869232178\n",
            "Epoch 7, Batch 44, test Loss: 0.7011197209358215\n",
            "Epoch 7, Batch 45, test Loss: 0.5325125455856323\n",
            "Epoch 7, Batch 46, test Loss: 0.6931629776954651\n",
            "Epoch 7, Batch 47, test Loss: 0.5761594176292419\n",
            "Epoch 7, Batch 48, test Loss: 0.5940185189247131\n",
            "Epoch 7, Batch 49, test Loss: 0.5568031668663025\n",
            "Epoch 7, Batch 50, test Loss: 0.7625054717063904\n",
            "Epoch 7, Batch 51, test Loss: 0.3633807599544525\n",
            "Epoch 7, Batch 52, test Loss: 0.6289427876472473\n",
            "Epoch 7, Batch 53, test Loss: 0.5837944746017456\n",
            "Epoch 7, Batch 54, test Loss: 0.5443419218063354\n",
            "Epoch 7, Batch 55, test Loss: 0.5236366987228394\n",
            "Epoch 7, Batch 56, test Loss: 0.45936739444732666\n",
            "Epoch 7, Batch 57, test Loss: 0.7880853414535522\n",
            "Epoch 7, Batch 58, test Loss: 0.6963526606559753\n",
            "Epoch 7, Batch 59, test Loss: 0.650432288646698\n",
            "Epoch 7, Batch 60, test Loss: 0.5163446664810181\n",
            "Epoch 7, Batch 61, test Loss: 0.6590527892112732\n",
            "Epoch 7, Batch 62, test Loss: 0.5181769132614136\n",
            "Epoch 7, Batch 63, test Loss: 0.5869432091712952\n",
            "Epoch 7, Batch 64, test Loss: 0.5181670784950256\n",
            "Epoch 7, Batch 65, test Loss: 0.6306958198547363\n",
            "Epoch 7, Batch 66, test Loss: 0.5312656164169312\n",
            "Epoch 7, Batch 67, test Loss: 0.5658011436462402\n",
            "Epoch 7, Batch 68, test Loss: 0.6266059875488281\n",
            "Epoch 7, Batch 69, test Loss: 0.5930598378181458\n",
            "Epoch 7, Batch 70, test Loss: 0.5099527835845947\n",
            "Epoch 7, Batch 71, test Loss: 0.4882151782512665\n",
            "Epoch 7, Batch 72, test Loss: 0.49895206093788147\n",
            "Epoch 7, Batch 73, test Loss: 0.4640141427516937\n",
            "Epoch 7, Batch 74, test Loss: 0.6544597744941711\n",
            "Epoch 7, Batch 75, test Loss: 0.47561731934547424\n",
            "Epoch 7, Batch 76, test Loss: 0.6449383497238159\n",
            "Epoch 7, Batch 77, test Loss: 0.6661151051521301\n",
            "Epoch 7, Batch 78, test Loss: 0.7021934390068054\n",
            "Epoch 7, Batch 79, test Loss: 0.8625876307487488\n",
            "Epoch 7, Batch 80, test Loss: 0.7016572952270508\n",
            "Epoch 7, Batch 81, test Loss: 0.6807342171669006\n",
            "Epoch 7, Batch 82, test Loss: 0.517257034778595\n",
            "Epoch 7, Batch 83, test Loss: 0.49096599221229553\n",
            "Epoch 7, Batch 84, test Loss: 0.6629140973091125\n",
            "Epoch 7, Batch 85, test Loss: 0.5889067649841309\n",
            "Epoch 7, Batch 86, test Loss: 0.3593965172767639\n",
            "Epoch 7, Batch 87, test Loss: 0.6136476993560791\n",
            "Epoch 7, Batch 88, test Loss: 0.6317435503005981\n",
            "Epoch 7, Batch 89, test Loss: 0.7059804797172546\n",
            "Epoch 7, Batch 90, test Loss: 0.6552670001983643\n",
            "Epoch 7, Batch 91, test Loss: 0.6157044172286987\n",
            "Epoch 7, Batch 92, test Loss: 0.48180848360061646\n",
            "Epoch 7, Batch 93, test Loss: 0.5816277861595154\n",
            "Epoch 7, Batch 94, test Loss: 0.658600926399231\n",
            "Epoch 7, Batch 95, test Loss: 0.59490966796875\n",
            "Epoch 7, Batch 96, test Loss: 0.5892581939697266\n",
            "Epoch 7, Batch 97, test Loss: 0.7589375972747803\n",
            "Epoch 7, Batch 98, test Loss: 0.614199161529541\n",
            "Epoch 7, Batch 99, test Loss: 0.886407732963562\n",
            "Epoch 7, Batch 100, test Loss: 0.6343688368797302\n",
            "Epoch 7, Batch 101, test Loss: 0.48019182682037354\n",
            "Epoch 7, Batch 102, test Loss: 0.7432548403739929\n",
            "Epoch 7, Batch 103, test Loss: 0.6633414030075073\n",
            "Epoch 7, Batch 104, test Loss: 0.6850781440734863\n",
            "Epoch 7, Batch 105, test Loss: 0.5154730081558228\n",
            "Epoch 7, Batch 106, test Loss: 0.5414823293685913\n",
            "Epoch 7, Batch 107, test Loss: 0.5194488763809204\n",
            "Epoch 7, Batch 108, test Loss: 0.6193051934242249\n",
            "Epoch 7, Batch 109, test Loss: 0.5842295289039612\n",
            "Epoch 7, Batch 110, test Loss: 0.5987322330474854\n",
            "Epoch 7, Batch 111, test Loss: 0.7610601186752319\n",
            "Epoch 7, Batch 112, test Loss: 0.5003347396850586\n",
            "Epoch 7, Batch 113, test Loss: 0.6656872034072876\n",
            "Epoch 7, Batch 114, test Loss: 0.38418883085250854\n",
            "Epoch 7, Batch 115, test Loss: 0.6687402129173279\n",
            "Epoch 7, Batch 116, test Loss: 0.7155738472938538\n",
            "Epoch 7, Batch 117, test Loss: 0.4688890874385834\n",
            "Epoch 7, Batch 118, test Loss: 0.5562098026275635\n",
            "Epoch 7, Batch 119, test Loss: 0.5704500675201416\n",
            "Epoch 7, Batch 120, test Loss: 0.8211196660995483\n",
            "Epoch 7, Batch 121, test Loss: 0.5463500022888184\n",
            "Epoch 7, Batch 122, test Loss: 0.5583171844482422\n",
            "Epoch 7, Batch 123, test Loss: 0.652854859828949\n",
            "Epoch 7, Batch 124, test Loss: 0.638513445854187\n",
            "Epoch 7, Batch 125, test Loss: 0.6567466855049133\n",
            "Epoch 7, Batch 126, test Loss: 0.5039036870002747\n",
            "Epoch 7, Batch 127, test Loss: 0.7779675126075745\n",
            "Epoch 7, Batch 128, test Loss: 0.7522801160812378\n",
            "Epoch 7, Batch 129, test Loss: 0.709696888923645\n",
            "Epoch 7, Batch 130, test Loss: 0.6072542071342468\n",
            "Epoch 7, Batch 131, test Loss: 0.7313345074653625\n",
            "Epoch 7, Batch 132, test Loss: 0.5164265036582947\n",
            "Epoch 7, Batch 133, test Loss: 0.4394519031047821\n",
            "Epoch 7, Batch 134, test Loss: 0.712688148021698\n",
            "Epoch 7, Batch 135, test Loss: 0.6777182817459106\n",
            "Epoch 7, Batch 136, test Loss: 0.657854437828064\n",
            "Epoch 7, Batch 137, test Loss: 0.7285750508308411\n",
            "Epoch 7, Batch 138, test Loss: 0.6485207676887512\n",
            "Epoch 7, Batch 139, test Loss: 0.8232313394546509\n",
            "Epoch 7, Batch 140, test Loss: 0.5709452033042908\n",
            "Epoch 7, Batch 141, test Loss: 0.5768115520477295\n",
            "Epoch 7, Batch 142, test Loss: 0.5427384376525879\n",
            "Epoch 7, Batch 143, test Loss: 0.8583278656005859\n",
            "Epoch 7, Batch 144, test Loss: 0.3811011016368866\n",
            "Epoch 7, Batch 145, test Loss: 0.6713871955871582\n",
            "Epoch 7, Batch 146, test Loss: 0.4484155774116516\n",
            "Epoch 7, Batch 147, test Loss: 0.6624080538749695\n",
            "Epoch 7, Batch 148, test Loss: 0.6311613917350769\n",
            "Epoch 7, Batch 149, test Loss: 0.8788384795188904\n",
            "Epoch 7, Batch 150, test Loss: 0.6228742599487305\n",
            "Epoch 7, Batch 151, test Loss: 0.6467215418815613\n",
            "Epoch 7, Batch 152, test Loss: 0.5843077898025513\n",
            "Epoch 7, Batch 153, test Loss: 0.5085861682891846\n",
            "Epoch 7, Batch 154, test Loss: 0.49546435475349426\n",
            "Epoch 7, Batch 155, test Loss: 0.6921445727348328\n",
            "Epoch 7, Batch 156, test Loss: 0.41663607954978943\n",
            "Epoch 7, Accuracy of test set: 0.7821\n",
            "Epoch 8/25:\n",
            "Train Loss: 0.0096, Train Accuracy: 0.78\n",
            "Test Loss: 0.0096, Test Accuracy: 0.78\n",
            "Accuracy of train set: 0.7949166666666667\n",
            "Epoch 8, Batch 0, test Loss: 0.7282057404518127\n",
            "Epoch 8, Batch 1, test Loss: 0.548292338848114\n",
            "Epoch 8, Batch 2, test Loss: 0.5313862562179565\n",
            "Epoch 8, Batch 3, test Loss: 0.5720071792602539\n",
            "Epoch 8, Batch 4, test Loss: 0.5036504864692688\n",
            "Epoch 8, Batch 5, test Loss: 0.8153461813926697\n",
            "Epoch 8, Batch 6, test Loss: 0.4569072127342224\n",
            "Epoch 8, Batch 7, test Loss: 0.5541257858276367\n",
            "Epoch 8, Batch 8, test Loss: 0.5440511107444763\n",
            "Epoch 8, Batch 9, test Loss: 0.7996094226837158\n",
            "Epoch 8, Batch 10, test Loss: 0.5431872010231018\n",
            "Epoch 8, Batch 11, test Loss: 0.455466628074646\n",
            "Epoch 8, Batch 12, test Loss: 0.6358541250228882\n",
            "Epoch 8, Batch 13, test Loss: 0.5739961862564087\n",
            "Epoch 8, Batch 14, test Loss: 0.6098565459251404\n",
            "Epoch 8, Batch 15, test Loss: 0.481233149766922\n",
            "Epoch 8, Batch 16, test Loss: 0.8016722202301025\n",
            "Epoch 8, Batch 17, test Loss: 0.6149630546569824\n",
            "Epoch 8, Batch 18, test Loss: 0.7732367515563965\n",
            "Epoch 8, Batch 19, test Loss: 0.742774248123169\n",
            "Epoch 8, Batch 20, test Loss: 0.5188890099525452\n",
            "Epoch 8, Batch 21, test Loss: 0.4745353162288666\n",
            "Epoch 8, Batch 22, test Loss: 0.6536372900009155\n",
            "Epoch 8, Batch 23, test Loss: 0.4658719599246979\n",
            "Epoch 8, Batch 24, test Loss: 0.5421290397644043\n",
            "Epoch 8, Batch 25, test Loss: 0.5291960835456848\n",
            "Epoch 8, Batch 26, test Loss: 0.5625367164611816\n",
            "Epoch 8, Batch 27, test Loss: 0.5898362994194031\n",
            "Epoch 8, Batch 28, test Loss: 0.5942385196685791\n",
            "Epoch 8, Batch 29, test Loss: 0.4709167182445526\n",
            "Epoch 8, Batch 30, test Loss: 0.5853996872901917\n",
            "Epoch 8, Batch 31, test Loss: 0.6974585652351379\n",
            "Epoch 8, Batch 32, test Loss: 0.4259786903858185\n",
            "Epoch 8, Batch 33, test Loss: 0.7591276168823242\n",
            "Epoch 8, Batch 34, test Loss: 0.7122505307197571\n",
            "Epoch 8, Batch 35, test Loss: 0.678611159324646\n",
            "Epoch 8, Batch 36, test Loss: 0.5804539322853088\n",
            "Epoch 8, Batch 37, test Loss: 0.705693244934082\n",
            "Epoch 8, Batch 38, test Loss: 0.6509249806404114\n",
            "Epoch 8, Batch 39, test Loss: 0.7276334762573242\n",
            "Epoch 8, Batch 40, test Loss: 0.5297919511795044\n",
            "Epoch 8, Batch 41, test Loss: 0.6282451152801514\n",
            "Epoch 8, Batch 42, test Loss: 0.6843650937080383\n",
            "Epoch 8, Batch 43, test Loss: 0.40615153312683105\n",
            "Epoch 8, Batch 44, test Loss: 0.5268118381500244\n",
            "Epoch 8, Batch 45, test Loss: 0.44568508863449097\n",
            "Epoch 8, Batch 46, test Loss: 0.6325132846832275\n",
            "Epoch 8, Batch 47, test Loss: 0.639914333820343\n",
            "Epoch 8, Batch 48, test Loss: 0.5743223428726196\n",
            "Epoch 8, Batch 49, test Loss: 0.5691355466842651\n",
            "Epoch 8, Batch 50, test Loss: 0.6581896543502808\n",
            "Epoch 8, Batch 51, test Loss: 0.4905730187892914\n",
            "Epoch 8, Batch 52, test Loss: 0.6440329551696777\n",
            "Epoch 8, Batch 53, test Loss: 0.41761377453804016\n",
            "Epoch 8, Batch 54, test Loss: 0.8354995250701904\n",
            "Epoch 8, Batch 55, test Loss: 0.4249083697795868\n",
            "Epoch 8, Batch 56, test Loss: 0.7168528437614441\n",
            "Epoch 8, Batch 57, test Loss: 0.8375788927078247\n",
            "Epoch 8, Batch 58, test Loss: 0.6735557317733765\n",
            "Epoch 8, Batch 59, test Loss: 0.6129654049873352\n",
            "Epoch 8, Batch 60, test Loss: 0.6240799427032471\n",
            "Epoch 8, Batch 61, test Loss: 0.7083896994590759\n",
            "Epoch 8, Batch 62, test Loss: 0.5825475454330444\n",
            "Epoch 8, Batch 63, test Loss: 0.600023090839386\n",
            "Epoch 8, Batch 64, test Loss: 0.9691319465637207\n",
            "Epoch 8, Batch 65, test Loss: 0.5173536539077759\n",
            "Epoch 8, Batch 66, test Loss: 0.7149859070777893\n",
            "Epoch 8, Batch 67, test Loss: 0.5267536044120789\n",
            "Epoch 8, Batch 68, test Loss: 0.5349603891372681\n",
            "Epoch 8, Batch 69, test Loss: 0.6608613729476929\n",
            "Epoch 8, Batch 70, test Loss: 0.5167282819747925\n",
            "Epoch 8, Batch 71, test Loss: 0.5482137799263\n",
            "Epoch 8, Batch 72, test Loss: 0.6222057342529297\n",
            "Epoch 8, Batch 73, test Loss: 0.4921853840351105\n",
            "Epoch 8, Batch 74, test Loss: 0.6296225190162659\n",
            "Epoch 8, Batch 75, test Loss: 0.6027857661247253\n",
            "Epoch 8, Batch 76, test Loss: 0.46305492520332336\n",
            "Epoch 8, Batch 77, test Loss: 0.5997326970100403\n",
            "Epoch 8, Batch 78, test Loss: 0.5616915822029114\n",
            "Epoch 8, Batch 79, test Loss: 0.4660397171974182\n",
            "Epoch 8, Batch 80, test Loss: 0.47979822754859924\n",
            "Epoch 8, Batch 81, test Loss: 0.639595627784729\n",
            "Epoch 8, Batch 82, test Loss: 0.4449336528778076\n",
            "Epoch 8, Batch 83, test Loss: 0.6298535466194153\n",
            "Epoch 8, Batch 84, test Loss: 0.5703610777854919\n",
            "Epoch 8, Batch 85, test Loss: 0.5443915724754333\n",
            "Epoch 8, Batch 86, test Loss: 0.5056647658348083\n",
            "Epoch 8, Batch 87, test Loss: 0.6811010837554932\n",
            "Epoch 8, Batch 88, test Loss: 0.3792182207107544\n",
            "Epoch 8, Batch 89, test Loss: 0.5936304926872253\n",
            "Epoch 8, Batch 90, test Loss: 0.5557344555854797\n",
            "Epoch 8, Batch 91, test Loss: 0.41571319103240967\n",
            "Epoch 8, Batch 92, test Loss: 0.8732664585113525\n",
            "Epoch 8, Batch 93, test Loss: 0.4678463935852051\n",
            "Epoch 8, Batch 94, test Loss: 0.6098307371139526\n",
            "Epoch 8, Batch 95, test Loss: 0.42329344153404236\n",
            "Epoch 8, Batch 96, test Loss: 0.529639720916748\n",
            "Epoch 8, Batch 97, test Loss: 0.7567405700683594\n",
            "Epoch 8, Batch 98, test Loss: 0.8686802387237549\n",
            "Epoch 8, Batch 99, test Loss: 0.7373183965682983\n",
            "Epoch 8, Batch 100, test Loss: 0.6098337769508362\n",
            "Epoch 8, Batch 101, test Loss: 0.8457885980606079\n",
            "Epoch 8, Batch 102, test Loss: 0.5784374475479126\n",
            "Epoch 8, Batch 103, test Loss: 0.8676209449768066\n",
            "Epoch 8, Batch 104, test Loss: 0.7322866320610046\n",
            "Epoch 8, Batch 105, test Loss: 0.41741305589675903\n",
            "Epoch 8, Batch 106, test Loss: 0.6678149700164795\n",
            "Epoch 8, Batch 107, test Loss: 0.8569658994674683\n",
            "Epoch 8, Batch 108, test Loss: 0.45374900102615356\n",
            "Epoch 8, Batch 109, test Loss: 0.6297130584716797\n",
            "Epoch 8, Batch 110, test Loss: 0.6483033895492554\n",
            "Epoch 8, Batch 111, test Loss: 0.8325557112693787\n",
            "Epoch 8, Batch 112, test Loss: 0.7342096567153931\n",
            "Epoch 8, Batch 113, test Loss: 0.5435761213302612\n",
            "Epoch 8, Batch 114, test Loss: 0.6958022713661194\n",
            "Epoch 8, Batch 115, test Loss: 0.6384389996528625\n",
            "Epoch 8, Batch 116, test Loss: 0.5312683582305908\n",
            "Epoch 8, Batch 117, test Loss: 0.8765337467193604\n",
            "Epoch 8, Batch 118, test Loss: 0.790698230266571\n",
            "Epoch 8, Batch 119, test Loss: 0.4445318579673767\n",
            "Epoch 8, Batch 120, test Loss: 0.6264450550079346\n",
            "Epoch 8, Batch 121, test Loss: 0.5060791969299316\n",
            "Epoch 8, Batch 122, test Loss: 0.5340684652328491\n",
            "Epoch 8, Batch 123, test Loss: 0.6568379998207092\n",
            "Epoch 8, Batch 124, test Loss: 0.7326069474220276\n",
            "Epoch 8, Batch 125, test Loss: 0.9712232947349548\n",
            "Epoch 8, Batch 126, test Loss: 0.6024727821350098\n",
            "Epoch 8, Batch 127, test Loss: 0.6413770914077759\n",
            "Epoch 8, Batch 128, test Loss: 0.8364377617835999\n",
            "Epoch 8, Batch 129, test Loss: 0.7090727686882019\n",
            "Epoch 8, Batch 130, test Loss: 0.7529953122138977\n",
            "Epoch 8, Batch 131, test Loss: 0.48941564559936523\n",
            "Epoch 8, Batch 132, test Loss: 0.5892722010612488\n",
            "Epoch 8, Batch 133, test Loss: 0.7603119611740112\n",
            "Epoch 8, Batch 134, test Loss: 0.49393564462661743\n",
            "Epoch 8, Batch 135, test Loss: 0.6258100867271423\n",
            "Epoch 8, Batch 136, test Loss: 0.605817973613739\n",
            "Epoch 8, Batch 137, test Loss: 0.6193362474441528\n",
            "Epoch 8, Batch 138, test Loss: 0.7990500330924988\n",
            "Epoch 8, Batch 139, test Loss: 0.5737255811691284\n",
            "Epoch 8, Batch 140, test Loss: 0.4579137861728668\n",
            "Epoch 8, Batch 141, test Loss: 0.4784226417541504\n",
            "Epoch 8, Batch 142, test Loss: 0.4515463709831238\n",
            "Epoch 8, Batch 143, test Loss: 0.5527790188789368\n",
            "Epoch 8, Batch 144, test Loss: 0.5430163145065308\n",
            "Epoch 8, Batch 145, test Loss: 0.32959017157554626\n",
            "Epoch 8, Batch 146, test Loss: 0.5761951208114624\n",
            "Epoch 8, Batch 147, test Loss: 0.4569423198699951\n",
            "Epoch 8, Batch 148, test Loss: 0.46756604313850403\n",
            "Epoch 8, Batch 149, test Loss: 0.7649386525154114\n",
            "Epoch 8, Batch 150, test Loss: 0.639380693435669\n",
            "Epoch 8, Batch 151, test Loss: 0.7662240266799927\n",
            "Epoch 8, Batch 152, test Loss: 0.8696629405021667\n",
            "Epoch 8, Batch 153, test Loss: 0.6807668805122375\n",
            "Epoch 8, Batch 154, test Loss: 0.6176677942276001\n",
            "Epoch 8, Batch 155, test Loss: 0.4533776342868805\n",
            "Epoch 8, Batch 156, test Loss: 0.6088459491729736\n",
            "Epoch 8, Accuracy of test set: 0.7806\n",
            "Epoch 9/25:\n",
            "Train Loss: 0.0091, Train Accuracy: 0.79\n",
            "Test Loss: 0.0096, Test Accuracy: 0.78\n",
            "Accuracy of train set: 0.8050333333333334\n",
            "Epoch 9, Batch 0, test Loss: 0.5306469202041626\n",
            "Epoch 9, Batch 1, test Loss: 0.5607331991195679\n",
            "Epoch 9, Batch 2, test Loss: 0.41549065709114075\n",
            "Epoch 9, Batch 3, test Loss: 0.6398225426673889\n",
            "Epoch 9, Batch 4, test Loss: 0.7606651186943054\n",
            "Epoch 9, Batch 5, test Loss: 0.6864470839500427\n",
            "Epoch 9, Batch 6, test Loss: 0.9854940176010132\n",
            "Epoch 9, Batch 7, test Loss: 0.500924289226532\n",
            "Epoch 9, Batch 8, test Loss: 0.6792569160461426\n",
            "Epoch 9, Batch 9, test Loss: 0.4872710108757019\n",
            "Epoch 9, Batch 10, test Loss: 0.7746602296829224\n",
            "Epoch 9, Batch 11, test Loss: 0.6530879139900208\n",
            "Epoch 9, Batch 12, test Loss: 0.3771078288555145\n",
            "Epoch 9, Batch 13, test Loss: 0.6633754968643188\n",
            "Epoch 9, Batch 14, test Loss: 0.4491480886936188\n",
            "Epoch 9, Batch 15, test Loss: 0.5865194201469421\n",
            "Epoch 9, Batch 16, test Loss: 0.49568456411361694\n",
            "Epoch 9, Batch 17, test Loss: 0.6564006805419922\n",
            "Epoch 9, Batch 18, test Loss: 0.5958600044250488\n",
            "Epoch 9, Batch 19, test Loss: 0.7670305967330933\n",
            "Epoch 9, Batch 20, test Loss: 0.6775408983230591\n",
            "Epoch 9, Batch 21, test Loss: 0.47634631395339966\n",
            "Epoch 9, Batch 22, test Loss: 0.5977048873901367\n",
            "Epoch 9, Batch 23, test Loss: 0.7319672107696533\n",
            "Epoch 9, Batch 24, test Loss: 0.5408281087875366\n",
            "Epoch 9, Batch 25, test Loss: 0.3953932523727417\n",
            "Epoch 9, Batch 26, test Loss: 0.5161029100418091\n",
            "Epoch 9, Batch 27, test Loss: 0.64695805311203\n",
            "Epoch 9, Batch 28, test Loss: 0.4627029299736023\n",
            "Epoch 9, Batch 29, test Loss: 0.6379933953285217\n",
            "Epoch 9, Batch 30, test Loss: 0.6828644275665283\n",
            "Epoch 9, Batch 31, test Loss: 0.45696496963500977\n",
            "Epoch 9, Batch 32, test Loss: 0.4676491916179657\n",
            "Epoch 9, Batch 33, test Loss: 0.5720711350440979\n",
            "Epoch 9, Batch 34, test Loss: 0.44142651557922363\n",
            "Epoch 9, Batch 35, test Loss: 0.6090458631515503\n",
            "Epoch 9, Batch 36, test Loss: 0.6336647272109985\n",
            "Epoch 9, Batch 37, test Loss: 0.43827977776527405\n",
            "Epoch 9, Batch 38, test Loss: 0.42770904302597046\n",
            "Epoch 9, Batch 39, test Loss: 0.3775289058685303\n",
            "Epoch 9, Batch 40, test Loss: 0.5464499592781067\n",
            "Epoch 9, Batch 41, test Loss: 0.5413463711738586\n",
            "Epoch 9, Batch 42, test Loss: 0.37685418128967285\n",
            "Epoch 9, Batch 43, test Loss: 0.6743705868721008\n",
            "Epoch 9, Batch 44, test Loss: 0.5258207321166992\n",
            "Epoch 9, Batch 45, test Loss: 0.8000780940055847\n",
            "Epoch 9, Batch 46, test Loss: 0.48898059129714966\n",
            "Epoch 9, Batch 47, test Loss: 0.8642469644546509\n",
            "Epoch 9, Batch 48, test Loss: 0.5634090304374695\n",
            "Epoch 9, Batch 49, test Loss: 0.4986910820007324\n",
            "Epoch 9, Batch 50, test Loss: 0.5719843506813049\n",
            "Epoch 9, Batch 51, test Loss: 0.49124112725257874\n",
            "Epoch 9, Batch 52, test Loss: 0.629313051700592\n",
            "Epoch 9, Batch 53, test Loss: 0.6791173219680786\n",
            "Epoch 9, Batch 54, test Loss: 0.5261382460594177\n",
            "Epoch 9, Batch 55, test Loss: 0.5578067302703857\n",
            "Epoch 9, Batch 56, test Loss: 0.5353638529777527\n",
            "Epoch 9, Batch 57, test Loss: 0.3159513473510742\n",
            "Epoch 9, Batch 58, test Loss: 0.6235888004302979\n",
            "Epoch 9, Batch 59, test Loss: 0.5233526825904846\n",
            "Epoch 9, Batch 60, test Loss: 0.6654133200645447\n",
            "Epoch 9, Batch 61, test Loss: 0.5060470104217529\n",
            "Epoch 9, Batch 62, test Loss: 0.673146665096283\n",
            "Epoch 9, Batch 63, test Loss: 0.627672016620636\n",
            "Epoch 9, Batch 64, test Loss: 0.580797553062439\n",
            "Epoch 9, Batch 65, test Loss: 0.5177558064460754\n",
            "Epoch 9, Batch 66, test Loss: 0.47957682609558105\n",
            "Epoch 9, Batch 67, test Loss: 0.6314120292663574\n",
            "Epoch 9, Batch 68, test Loss: 0.5250586271286011\n",
            "Epoch 9, Batch 69, test Loss: 0.4943387508392334\n",
            "Epoch 9, Batch 70, test Loss: 0.656873881816864\n",
            "Epoch 9, Batch 71, test Loss: 0.5305325984954834\n",
            "Epoch 9, Batch 72, test Loss: 0.6756548285484314\n",
            "Epoch 9, Batch 73, test Loss: 0.45896056294441223\n",
            "Epoch 9, Batch 74, test Loss: 0.8033888339996338\n",
            "Epoch 9, Batch 75, test Loss: 0.28763166069984436\n",
            "Epoch 9, Batch 76, test Loss: 0.5658467411994934\n",
            "Epoch 9, Batch 77, test Loss: 0.7183166146278381\n",
            "Epoch 9, Batch 78, test Loss: 0.6700721383094788\n",
            "Epoch 9, Batch 79, test Loss: 0.46149033308029175\n",
            "Epoch 9, Batch 80, test Loss: 0.4314551055431366\n",
            "Epoch 9, Batch 81, test Loss: 0.46451061964035034\n",
            "Epoch 9, Batch 82, test Loss: 0.5478174090385437\n",
            "Epoch 9, Batch 83, test Loss: 0.8127268552780151\n",
            "Epoch 9, Batch 84, test Loss: 0.3703688383102417\n",
            "Epoch 9, Batch 85, test Loss: 0.5800707936286926\n",
            "Epoch 9, Batch 86, test Loss: 0.5520641207695007\n",
            "Epoch 9, Batch 87, test Loss: 0.6306153535842896\n",
            "Epoch 9, Batch 88, test Loss: 0.6492704749107361\n",
            "Epoch 9, Batch 89, test Loss: 0.5303034782409668\n",
            "Epoch 9, Batch 90, test Loss: 0.5996645092964172\n",
            "Epoch 9, Batch 91, test Loss: 0.6444017887115479\n",
            "Epoch 9, Batch 92, test Loss: 0.5133933424949646\n",
            "Epoch 9, Batch 93, test Loss: 0.7840449810028076\n",
            "Epoch 9, Batch 94, test Loss: 0.6581264138221741\n",
            "Epoch 9, Batch 95, test Loss: 0.5245739221572876\n",
            "Epoch 9, Batch 96, test Loss: 0.6275739669799805\n",
            "Epoch 9, Batch 97, test Loss: 0.7314333319664001\n",
            "Epoch 9, Batch 98, test Loss: 0.4285067915916443\n",
            "Epoch 9, Batch 99, test Loss: 0.2419954240322113\n",
            "Epoch 9, Batch 100, test Loss: 0.4928221106529236\n",
            "Epoch 9, Batch 101, test Loss: 0.513468861579895\n",
            "Epoch 9, Batch 102, test Loss: 0.518180787563324\n",
            "Epoch 9, Batch 103, test Loss: 0.5384743213653564\n",
            "Epoch 9, Batch 104, test Loss: 0.5948157906532288\n",
            "Epoch 9, Batch 105, test Loss: 0.3960709571838379\n",
            "Epoch 9, Batch 106, test Loss: 0.8913640379905701\n",
            "Epoch 9, Batch 107, test Loss: 0.509793758392334\n",
            "Epoch 9, Batch 108, test Loss: 0.5376344323158264\n",
            "Epoch 9, Batch 109, test Loss: 0.6750757694244385\n",
            "Epoch 9, Batch 110, test Loss: 0.44745784997940063\n",
            "Epoch 9, Batch 111, test Loss: 0.5641490817070007\n",
            "Epoch 9, Batch 112, test Loss: 0.5218967795372009\n",
            "Epoch 9, Batch 113, test Loss: 0.55536949634552\n",
            "Epoch 9, Batch 114, test Loss: 0.5575256943702698\n",
            "Epoch 9, Batch 115, test Loss: 0.9700546264648438\n",
            "Epoch 9, Batch 116, test Loss: 0.7582002878189087\n",
            "Epoch 9, Batch 117, test Loss: 0.5987861156463623\n",
            "Epoch 9, Batch 118, test Loss: 0.43132179975509644\n",
            "Epoch 9, Batch 119, test Loss: 0.3985808789730072\n",
            "Epoch 9, Batch 120, test Loss: 0.5182319283485413\n",
            "Epoch 9, Batch 121, test Loss: 0.5953501462936401\n",
            "Epoch 9, Batch 122, test Loss: 0.6853907704353333\n",
            "Epoch 9, Batch 123, test Loss: 0.6083780527114868\n",
            "Epoch 9, Batch 124, test Loss: 0.47190791368484497\n",
            "Epoch 9, Batch 125, test Loss: 0.45728421211242676\n",
            "Epoch 9, Batch 126, test Loss: 0.5479130744934082\n",
            "Epoch 9, Batch 127, test Loss: 0.7417885065078735\n",
            "Epoch 9, Batch 128, test Loss: 0.71273273229599\n",
            "Epoch 9, Batch 129, test Loss: 0.5174388289451599\n",
            "Epoch 9, Batch 130, test Loss: 0.734672486782074\n",
            "Epoch 9, Batch 131, test Loss: 0.622139036655426\n",
            "Epoch 9, Batch 132, test Loss: 0.9456169605255127\n",
            "Epoch 9, Batch 133, test Loss: 0.5123320817947388\n",
            "Epoch 9, Batch 134, test Loss: 0.6171157360076904\n",
            "Epoch 9, Batch 135, test Loss: 0.44415372610092163\n",
            "Epoch 9, Batch 136, test Loss: 0.6058300137519836\n",
            "Epoch 9, Batch 137, test Loss: 0.5598068833351135\n",
            "Epoch 9, Batch 138, test Loss: 0.6395072340965271\n",
            "Epoch 9, Batch 139, test Loss: 0.4696730971336365\n",
            "Epoch 9, Batch 140, test Loss: 0.5759373903274536\n",
            "Epoch 9, Batch 141, test Loss: 0.623681902885437\n",
            "Epoch 9, Batch 142, test Loss: 0.5112712383270264\n",
            "Epoch 9, Batch 143, test Loss: 0.6685900688171387\n",
            "Epoch 9, Batch 144, test Loss: 0.49037814140319824\n",
            "Epoch 9, Batch 145, test Loss: 0.6455550193786621\n",
            "Epoch 9, Batch 146, test Loss: 0.5811042189598083\n",
            "Epoch 9, Batch 147, test Loss: 0.3986217677593231\n",
            "Epoch 9, Batch 148, test Loss: 0.6267892122268677\n",
            "Epoch 9, Batch 149, test Loss: 0.4314935505390167\n",
            "Epoch 9, Batch 150, test Loss: 0.5823304653167725\n",
            "Epoch 9, Batch 151, test Loss: 0.4450785517692566\n",
            "Epoch 9, Batch 152, test Loss: 0.511165201663971\n",
            "Epoch 9, Batch 153, test Loss: 0.5505740642547607\n",
            "Epoch 9, Batch 154, test Loss: 0.5644316077232361\n",
            "Epoch 9, Batch 155, test Loss: 0.48389947414398193\n",
            "Epoch 9, Batch 156, test Loss: 0.45599299669265747\n",
            "Epoch 9, Accuracy of test set: 0.7981\n",
            "Epoch 10/25:\n",
            "Train Loss: 0.0087, Train Accuracy: 0.81\n",
            "Test Loss: 0.0090, Test Accuracy: 0.80\n",
            "Accuracy of train set: 0.8126833333333333\n",
            "Epoch 10, Batch 0, test Loss: 0.6657684445381165\n",
            "Epoch 10, Batch 1, test Loss: 0.5682874917984009\n",
            "Epoch 10, Batch 2, test Loss: 0.5550426244735718\n",
            "Epoch 10, Batch 3, test Loss: 0.5846022367477417\n",
            "Epoch 10, Batch 4, test Loss: 0.47741082310676575\n",
            "Epoch 10, Batch 5, test Loss: 0.5482727289199829\n",
            "Epoch 10, Batch 6, test Loss: 0.3645191490650177\n",
            "Epoch 10, Batch 7, test Loss: 0.5437194108963013\n",
            "Epoch 10, Batch 8, test Loss: 0.34360435605049133\n",
            "Epoch 10, Batch 9, test Loss: 0.6202610731124878\n",
            "Epoch 10, Batch 10, test Loss: 0.46361321210861206\n",
            "Epoch 10, Batch 11, test Loss: 0.6188122034072876\n",
            "Epoch 10, Batch 12, test Loss: 0.5608469247817993\n",
            "Epoch 10, Batch 13, test Loss: 0.5721010565757751\n",
            "Epoch 10, Batch 14, test Loss: 0.6413344144821167\n",
            "Epoch 10, Batch 15, test Loss: 0.4359329342842102\n",
            "Epoch 10, Batch 16, test Loss: 0.44579997658729553\n",
            "Epoch 10, Batch 17, test Loss: 0.7794351577758789\n",
            "Epoch 10, Batch 18, test Loss: 0.5387047529220581\n",
            "Epoch 10, Batch 19, test Loss: 0.75445955991745\n",
            "Epoch 10, Batch 20, test Loss: 0.40603283047676086\n",
            "Epoch 10, Batch 21, test Loss: 0.40927332639694214\n",
            "Epoch 10, Batch 22, test Loss: 0.5689606666564941\n",
            "Epoch 10, Batch 23, test Loss: 0.5423318147659302\n",
            "Epoch 10, Batch 24, test Loss: 0.6802233457565308\n",
            "Epoch 10, Batch 25, test Loss: 0.6254070997238159\n",
            "Epoch 10, Batch 26, test Loss: 0.5467918515205383\n",
            "Epoch 10, Batch 27, test Loss: 0.5821628570556641\n",
            "Epoch 10, Batch 28, test Loss: 0.4436146914958954\n",
            "Epoch 10, Batch 29, test Loss: 0.4307582378387451\n",
            "Epoch 10, Batch 30, test Loss: 0.3455430567264557\n",
            "Epoch 10, Batch 31, test Loss: 0.604030191898346\n",
            "Epoch 10, Batch 32, test Loss: 0.6058300733566284\n",
            "Epoch 10, Batch 33, test Loss: 0.5250990986824036\n",
            "Epoch 10, Batch 34, test Loss: 0.6474968791007996\n",
            "Epoch 10, Batch 35, test Loss: 0.4022594094276428\n",
            "Epoch 10, Batch 36, test Loss: 0.506224513053894\n",
            "Epoch 10, Batch 37, test Loss: 0.367367684841156\n",
            "Epoch 10, Batch 38, test Loss: 0.674136757850647\n",
            "Epoch 10, Batch 39, test Loss: 0.5887213349342346\n",
            "Epoch 10, Batch 40, test Loss: 0.4780852198600769\n",
            "Epoch 10, Batch 41, test Loss: 0.4471425712108612\n",
            "Epoch 10, Batch 42, test Loss: 0.5458523035049438\n",
            "Epoch 10, Batch 43, test Loss: 0.6068136692047119\n",
            "Epoch 10, Batch 44, test Loss: 0.5038963556289673\n",
            "Epoch 10, Batch 45, test Loss: 0.5256786942481995\n",
            "Epoch 10, Batch 46, test Loss: 0.4953990876674652\n",
            "Epoch 10, Batch 47, test Loss: 0.5929115414619446\n",
            "Epoch 10, Batch 48, test Loss: 0.5708515048027039\n",
            "Epoch 10, Batch 49, test Loss: 0.6809282302856445\n",
            "Epoch 10, Batch 50, test Loss: 0.5215286016464233\n",
            "Epoch 10, Batch 51, test Loss: 0.6918078064918518\n",
            "Epoch 10, Batch 52, test Loss: 0.7098106741905212\n",
            "Epoch 10, Batch 53, test Loss: 0.48995327949523926\n",
            "Epoch 10, Batch 54, test Loss: 0.5512464642524719\n",
            "Epoch 10, Batch 55, test Loss: 0.8088086843490601\n",
            "Epoch 10, Batch 56, test Loss: 0.48768386244773865\n",
            "Epoch 10, Batch 57, test Loss: 0.5300668478012085\n",
            "Epoch 10, Batch 58, test Loss: 0.5194489359855652\n",
            "Epoch 10, Batch 59, test Loss: 0.41241535544395447\n",
            "Epoch 10, Batch 60, test Loss: 0.4810720682144165\n",
            "Epoch 10, Batch 61, test Loss: 0.45430681109428406\n",
            "Epoch 10, Batch 62, test Loss: 0.5140791535377502\n",
            "Epoch 10, Batch 63, test Loss: 0.5224645137786865\n",
            "Epoch 10, Batch 64, test Loss: 0.47809067368507385\n",
            "Epoch 10, Batch 65, test Loss: 0.5604360699653625\n",
            "Epoch 10, Batch 66, test Loss: 0.5709425806999207\n",
            "Epoch 10, Batch 67, test Loss: 0.5321431756019592\n",
            "Epoch 10, Batch 68, test Loss: 0.7504312992095947\n",
            "Epoch 10, Batch 69, test Loss: 0.6493961811065674\n",
            "Epoch 10, Batch 70, test Loss: 0.5784608721733093\n",
            "Epoch 10, Batch 71, test Loss: 0.49388325214385986\n",
            "Epoch 10, Batch 72, test Loss: 0.4303116798400879\n",
            "Epoch 10, Batch 73, test Loss: 0.5040000081062317\n",
            "Epoch 10, Batch 74, test Loss: 0.45368462800979614\n",
            "Epoch 10, Batch 75, test Loss: 0.5325387716293335\n",
            "Epoch 10, Batch 76, test Loss: 0.4007607102394104\n",
            "Epoch 10, Batch 77, test Loss: 0.41000014543533325\n",
            "Epoch 10, Batch 78, test Loss: 0.4454473555088043\n",
            "Epoch 10, Batch 79, test Loss: 0.45945894718170166\n",
            "Epoch 10, Batch 80, test Loss: 0.9437959790229797\n",
            "Epoch 10, Batch 81, test Loss: 0.6657453775405884\n",
            "Epoch 10, Batch 82, test Loss: 0.4510754346847534\n",
            "Epoch 10, Batch 83, test Loss: 0.5534729361534119\n",
            "Epoch 10, Batch 84, test Loss: 0.6507665514945984\n",
            "Epoch 10, Batch 85, test Loss: 0.5278632640838623\n",
            "Epoch 10, Batch 86, test Loss: 0.43987998366355896\n",
            "Epoch 10, Batch 87, test Loss: 0.4554820656776428\n",
            "Epoch 10, Batch 88, test Loss: 0.5316793918609619\n",
            "Epoch 10, Batch 89, test Loss: 0.6308777928352356\n",
            "Epoch 10, Batch 90, test Loss: 0.8427918553352356\n",
            "Epoch 10, Batch 91, test Loss: 0.4359375834465027\n",
            "Epoch 10, Batch 92, test Loss: 0.6111438870429993\n",
            "Epoch 10, Batch 93, test Loss: 0.7036653161048889\n",
            "Epoch 10, Batch 94, test Loss: 0.41356098651885986\n",
            "Epoch 10, Batch 95, test Loss: 0.3782183825969696\n",
            "Epoch 10, Batch 96, test Loss: 0.562357485294342\n",
            "Epoch 10, Batch 97, test Loss: 0.48846763372421265\n",
            "Epoch 10, Batch 98, test Loss: 0.6590437889099121\n",
            "Epoch 10, Batch 99, test Loss: 0.44829970598220825\n",
            "Epoch 10, Batch 100, test Loss: 0.4068285822868347\n",
            "Epoch 10, Batch 101, test Loss: 0.5729360580444336\n",
            "Epoch 10, Batch 102, test Loss: 0.45868438482284546\n",
            "Epoch 10, Batch 103, test Loss: 0.6217588782310486\n",
            "Epoch 10, Batch 104, test Loss: 0.5282918810844421\n",
            "Epoch 10, Batch 105, test Loss: 0.3824020028114319\n",
            "Epoch 10, Batch 106, test Loss: 0.5845187902450562\n",
            "Epoch 10, Batch 107, test Loss: 0.5724712610244751\n",
            "Epoch 10, Batch 108, test Loss: 0.46305397152900696\n",
            "Epoch 10, Batch 109, test Loss: 0.5481888651847839\n",
            "Epoch 10, Batch 110, test Loss: 0.6546304225921631\n",
            "Epoch 10, Batch 111, test Loss: 0.42249175906181335\n",
            "Epoch 10, Batch 112, test Loss: 0.6925536394119263\n",
            "Epoch 10, Batch 113, test Loss: 0.810615062713623\n",
            "Epoch 10, Batch 114, test Loss: 0.4840888977050781\n",
            "Epoch 10, Batch 115, test Loss: 0.47867006063461304\n",
            "Epoch 10, Batch 116, test Loss: 0.7521989345550537\n",
            "Epoch 10, Batch 117, test Loss: 0.3925879895687103\n",
            "Epoch 10, Batch 118, test Loss: 0.9236088991165161\n",
            "Epoch 10, Batch 119, test Loss: 0.7314696907997131\n",
            "Epoch 10, Batch 120, test Loss: 0.6835536956787109\n",
            "Epoch 10, Batch 121, test Loss: 0.7587146759033203\n",
            "Epoch 10, Batch 122, test Loss: 0.4626549780368805\n",
            "Epoch 10, Batch 123, test Loss: 0.5672886967658997\n",
            "Epoch 10, Batch 124, test Loss: 0.5658868551254272\n",
            "Epoch 10, Batch 125, test Loss: 0.4834112524986267\n",
            "Epoch 10, Batch 126, test Loss: 0.490619957447052\n",
            "Epoch 10, Batch 127, test Loss: 0.5269262790679932\n",
            "Epoch 10, Batch 128, test Loss: 0.7064776420593262\n",
            "Epoch 10, Batch 129, test Loss: 0.4123068153858185\n",
            "Epoch 10, Batch 130, test Loss: 0.695751428604126\n",
            "Epoch 10, Batch 131, test Loss: 0.5693379640579224\n",
            "Epoch 10, Batch 132, test Loss: 0.46810975670814514\n",
            "Epoch 10, Batch 133, test Loss: 0.40813735127449036\n",
            "Epoch 10, Batch 134, test Loss: 0.5168314576148987\n",
            "Epoch 10, Batch 135, test Loss: 0.43643003702163696\n",
            "Epoch 10, Batch 136, test Loss: 0.6213657855987549\n",
            "Epoch 10, Batch 137, test Loss: 0.6804987788200378\n",
            "Epoch 10, Batch 138, test Loss: 0.512711226940155\n",
            "Epoch 10, Batch 139, test Loss: 0.5201020836830139\n",
            "Epoch 10, Batch 140, test Loss: 0.44626396894454956\n",
            "Epoch 10, Batch 141, test Loss: 0.40280261635780334\n",
            "Epoch 10, Batch 142, test Loss: 0.40049561858177185\n",
            "Epoch 10, Batch 143, test Loss: 0.4678049683570862\n",
            "Epoch 10, Batch 144, test Loss: 0.5529617071151733\n",
            "Epoch 10, Batch 145, test Loss: 0.4498777985572815\n",
            "Epoch 10, Batch 146, test Loss: 0.5308955311775208\n",
            "Epoch 10, Batch 147, test Loss: 0.5667175650596619\n",
            "Epoch 10, Batch 148, test Loss: 0.3658837080001831\n",
            "Epoch 10, Batch 149, test Loss: 0.5532745718955994\n",
            "Epoch 10, Batch 150, test Loss: 0.4241987466812134\n",
            "Epoch 10, Batch 151, test Loss: 0.5063127279281616\n",
            "Epoch 10, Batch 152, test Loss: 0.5204452276229858\n",
            "Epoch 10, Batch 153, test Loss: 0.6455771923065186\n",
            "Epoch 10, Batch 154, test Loss: 0.5363271832466125\n",
            "Epoch 10, Batch 155, test Loss: 0.36491408944129944\n",
            "Epoch 10, Batch 156, test Loss: 0.7076414227485657\n",
            "Epoch 10, Accuracy of test set: 0.8097\n",
            "Epoch 11/25:\n",
            "Train Loss: 0.0084, Train Accuracy: 0.81\n",
            "Test Loss: 0.0085, Test Accuracy: 0.81\n",
            "Accuracy of train set: 0.8176833333333333\n",
            "Epoch 11, Batch 0, test Loss: 0.5323476195335388\n",
            "Epoch 11, Batch 1, test Loss: 0.39695093035697937\n",
            "Epoch 11, Batch 2, test Loss: 0.5385764241218567\n",
            "Epoch 11, Batch 3, test Loss: 0.5975045561790466\n",
            "Epoch 11, Batch 4, test Loss: 0.4775887727737427\n",
            "Epoch 11, Batch 5, test Loss: 0.4178546369075775\n",
            "Epoch 11, Batch 6, test Loss: 0.4527653753757477\n",
            "Epoch 11, Batch 7, test Loss: 0.7561576962471008\n",
            "Epoch 11, Batch 8, test Loss: 0.3394295573234558\n",
            "Epoch 11, Batch 9, test Loss: 0.5984821915626526\n",
            "Epoch 11, Batch 10, test Loss: 0.5117831230163574\n",
            "Epoch 11, Batch 11, test Loss: 0.4895733892917633\n",
            "Epoch 11, Batch 12, test Loss: 0.747576117515564\n",
            "Epoch 11, Batch 13, test Loss: 0.6305237412452698\n",
            "Epoch 11, Batch 14, test Loss: 0.6939923763275146\n",
            "Epoch 11, Batch 15, test Loss: 0.4058545231819153\n",
            "Epoch 11, Batch 16, test Loss: 0.5377154350280762\n",
            "Epoch 11, Batch 17, test Loss: 0.35646694898605347\n",
            "Epoch 11, Batch 18, test Loss: 0.7119957804679871\n",
            "Epoch 11, Batch 19, test Loss: 0.48786672949790955\n",
            "Epoch 11, Batch 20, test Loss: 0.5569676160812378\n",
            "Epoch 11, Batch 21, test Loss: 0.603054404258728\n",
            "Epoch 11, Batch 22, test Loss: 0.6232365965843201\n",
            "Epoch 11, Batch 23, test Loss: 0.6979527473449707\n",
            "Epoch 11, Batch 24, test Loss: 0.6155523657798767\n",
            "Epoch 11, Batch 25, test Loss: 0.7117583751678467\n",
            "Epoch 11, Batch 26, test Loss: 0.6118263006210327\n",
            "Epoch 11, Batch 27, test Loss: 0.7891554832458496\n",
            "Epoch 11, Batch 28, test Loss: 0.6350207328796387\n",
            "Epoch 11, Batch 29, test Loss: 0.911760151386261\n",
            "Epoch 11, Batch 30, test Loss: 0.5438728332519531\n",
            "Epoch 11, Batch 31, test Loss: 0.6106733679771423\n",
            "Epoch 11, Batch 32, test Loss: 0.519218385219574\n",
            "Epoch 11, Batch 33, test Loss: 0.401192843914032\n",
            "Epoch 11, Batch 34, test Loss: 0.5571191906929016\n",
            "Epoch 11, Batch 35, test Loss: 0.5305340886116028\n",
            "Epoch 11, Batch 36, test Loss: 0.6879842281341553\n",
            "Epoch 11, Batch 37, test Loss: 0.6228075623512268\n",
            "Epoch 11, Batch 38, test Loss: 0.555367112159729\n",
            "Epoch 11, Batch 39, test Loss: 0.21094226837158203\n",
            "Epoch 11, Batch 40, test Loss: 0.6173895597457886\n",
            "Epoch 11, Batch 41, test Loss: 0.4718565046787262\n",
            "Epoch 11, Batch 42, test Loss: 0.5875033140182495\n",
            "Epoch 11, Batch 43, test Loss: 0.9757813811302185\n",
            "Epoch 11, Batch 44, test Loss: 0.6264604330062866\n",
            "Epoch 11, Batch 45, test Loss: 0.5725796222686768\n",
            "Epoch 11, Batch 46, test Loss: 0.44913434982299805\n",
            "Epoch 11, Batch 47, test Loss: 0.6236956119537354\n",
            "Epoch 11, Batch 48, test Loss: 0.5724341869354248\n",
            "Epoch 11, Batch 49, test Loss: 0.442959725856781\n",
            "Epoch 11, Batch 50, test Loss: 0.38119709491729736\n",
            "Epoch 11, Batch 51, test Loss: 0.6641340255737305\n",
            "Epoch 11, Batch 52, test Loss: 0.42086559534072876\n",
            "Epoch 11, Batch 53, test Loss: 0.32625845074653625\n",
            "Epoch 11, Batch 54, test Loss: 0.6536451578140259\n",
            "Epoch 11, Batch 55, test Loss: 0.684158205986023\n",
            "Epoch 11, Batch 56, test Loss: 0.6680053472518921\n",
            "Epoch 11, Batch 57, test Loss: 0.6476348638534546\n",
            "Epoch 11, Batch 58, test Loss: 0.5457728505134583\n",
            "Epoch 11, Batch 59, test Loss: 0.5368288159370422\n",
            "Epoch 11, Batch 60, test Loss: 0.3446965515613556\n",
            "Epoch 11, Batch 61, test Loss: 0.5674763917922974\n",
            "Epoch 11, Batch 62, test Loss: 0.6974365711212158\n",
            "Epoch 11, Batch 63, test Loss: 0.7084519267082214\n",
            "Epoch 11, Batch 64, test Loss: 0.6207102537155151\n",
            "Epoch 11, Batch 65, test Loss: 0.5876230001449585\n",
            "Epoch 11, Batch 66, test Loss: 0.6086527109146118\n",
            "Epoch 11, Batch 67, test Loss: 0.6477189064025879\n",
            "Epoch 11, Batch 68, test Loss: 0.4186127781867981\n",
            "Epoch 11, Batch 69, test Loss: 0.44396787881851196\n",
            "Epoch 11, Batch 70, test Loss: 0.47864654660224915\n",
            "Epoch 11, Batch 71, test Loss: 0.40638160705566406\n",
            "Epoch 11, Batch 72, test Loss: 0.6010153293609619\n",
            "Epoch 11, Batch 73, test Loss: 0.511121928691864\n",
            "Epoch 11, Batch 74, test Loss: 0.7498283386230469\n",
            "Epoch 11, Batch 75, test Loss: 0.5496979355812073\n",
            "Epoch 11, Batch 76, test Loss: 0.6391940116882324\n",
            "Epoch 11, Batch 77, test Loss: 0.4202827215194702\n",
            "Epoch 11, Batch 78, test Loss: 0.6019112467765808\n",
            "Epoch 11, Batch 79, test Loss: 0.5787180066108704\n",
            "Epoch 11, Batch 80, test Loss: 0.3852902948856354\n",
            "Epoch 11, Batch 81, test Loss: 0.4462735950946808\n",
            "Epoch 11, Batch 82, test Loss: 0.8145910501480103\n",
            "Epoch 11, Batch 83, test Loss: 0.5147272348403931\n",
            "Epoch 11, Batch 84, test Loss: 0.5079169273376465\n",
            "Epoch 11, Batch 85, test Loss: 0.6571030616760254\n",
            "Epoch 11, Batch 86, test Loss: 0.5126485824584961\n",
            "Epoch 11, Batch 87, test Loss: 0.5161324739456177\n",
            "Epoch 11, Batch 88, test Loss: 0.3895300328731537\n",
            "Epoch 11, Batch 89, test Loss: 0.4668007791042328\n",
            "Epoch 11, Batch 90, test Loss: 0.4564369022846222\n",
            "Epoch 11, Batch 91, test Loss: 0.45092660188674927\n",
            "Epoch 11, Batch 92, test Loss: 0.4508425295352936\n",
            "Epoch 11, Batch 93, test Loss: 0.41293030977249146\n",
            "Epoch 11, Batch 94, test Loss: 0.630129873752594\n",
            "Epoch 11, Batch 95, test Loss: 0.42242559790611267\n",
            "Epoch 11, Batch 96, test Loss: 0.3598775565624237\n",
            "Epoch 11, Batch 97, test Loss: 0.5281413197517395\n",
            "Epoch 11, Batch 98, test Loss: 0.5585148334503174\n",
            "Epoch 11, Batch 99, test Loss: 0.3740001916885376\n",
            "Epoch 11, Batch 100, test Loss: 0.5975975394248962\n",
            "Epoch 11, Batch 101, test Loss: 0.7076506614685059\n",
            "Epoch 11, Batch 102, test Loss: 0.6483521461486816\n",
            "Epoch 11, Batch 103, test Loss: 0.43236589431762695\n",
            "Epoch 11, Batch 104, test Loss: 0.48130685091018677\n",
            "Epoch 11, Batch 105, test Loss: 0.4321748614311218\n",
            "Epoch 11, Batch 106, test Loss: 0.5743833184242249\n",
            "Epoch 11, Batch 107, test Loss: 0.5011166930198669\n",
            "Epoch 11, Batch 108, test Loss: 0.4822630286216736\n",
            "Epoch 11, Batch 109, test Loss: 0.9332555532455444\n",
            "Epoch 11, Batch 110, test Loss: 0.5184318423271179\n",
            "Epoch 11, Batch 111, test Loss: 0.7088959813117981\n",
            "Epoch 11, Batch 112, test Loss: 0.5874927639961243\n",
            "Epoch 11, Batch 113, test Loss: 0.551738977432251\n",
            "Epoch 11, Batch 114, test Loss: 0.5232434868812561\n",
            "Epoch 11, Batch 115, test Loss: 0.6371551752090454\n",
            "Epoch 11, Batch 116, test Loss: 0.40604156255722046\n",
            "Epoch 11, Batch 117, test Loss: 0.5772056579589844\n",
            "Epoch 11, Batch 118, test Loss: 0.46314898133277893\n",
            "Epoch 11, Batch 119, test Loss: 1.1358212232589722\n",
            "Epoch 11, Batch 120, test Loss: 0.5445809960365295\n",
            "Epoch 11, Batch 121, test Loss: 0.39895910024642944\n",
            "Epoch 11, Batch 122, test Loss: 0.5237629413604736\n",
            "Epoch 11, Batch 123, test Loss: 0.53397536277771\n",
            "Epoch 11, Batch 124, test Loss: 0.7559353113174438\n",
            "Epoch 11, Batch 125, test Loss: 0.508947491645813\n",
            "Epoch 11, Batch 126, test Loss: 0.5082993507385254\n",
            "Epoch 11, Batch 127, test Loss: 0.5471200346946716\n",
            "Epoch 11, Batch 128, test Loss: 0.6563048362731934\n",
            "Epoch 11, Batch 129, test Loss: 0.5014874935150146\n",
            "Epoch 11, Batch 130, test Loss: 0.41345977783203125\n",
            "Epoch 11, Batch 131, test Loss: 0.6282524466514587\n",
            "Epoch 11, Batch 132, test Loss: 0.6827685832977295\n",
            "Epoch 11, Batch 133, test Loss: 0.6118224859237671\n",
            "Epoch 11, Batch 134, test Loss: 0.5526335835456848\n",
            "Epoch 11, Batch 135, test Loss: 0.6513428092002869\n",
            "Epoch 11, Batch 136, test Loss: 0.49340158700942993\n",
            "Epoch 11, Batch 137, test Loss: 0.4397587776184082\n",
            "Epoch 11, Batch 138, test Loss: 0.4494408369064331\n",
            "Epoch 11, Batch 139, test Loss: 0.8351899981498718\n",
            "Epoch 11, Batch 140, test Loss: 0.4002465307712555\n",
            "Epoch 11, Batch 141, test Loss: 0.4175427556037903\n",
            "Epoch 11, Batch 142, test Loss: 0.50030517578125\n",
            "Epoch 11, Batch 143, test Loss: 0.5099706649780273\n",
            "Epoch 11, Batch 144, test Loss: 0.46564754843711853\n",
            "Epoch 11, Batch 145, test Loss: 0.302630752325058\n",
            "Epoch 11, Batch 146, test Loss: 0.5303322076797485\n",
            "Epoch 11, Batch 147, test Loss: 0.40330255031585693\n",
            "Epoch 11, Batch 148, test Loss: 0.6323528289794922\n",
            "Epoch 11, Batch 149, test Loss: 0.5891103148460388\n",
            "Epoch 11, Batch 150, test Loss: 0.678812563419342\n",
            "Epoch 11, Batch 151, test Loss: 0.4488667845726013\n",
            "Epoch 11, Batch 152, test Loss: 0.5154798030853271\n",
            "Epoch 11, Batch 153, test Loss: 0.6649889945983887\n",
            "Epoch 11, Batch 154, test Loss: 0.6325457096099854\n",
            "Epoch 11, Batch 155, test Loss: 0.5605859160423279\n",
            "Epoch 11, Batch 156, test Loss: 0.3471464514732361\n",
            "Epoch 11, Accuracy of test set: 0.8028\n",
            "Epoch 12/25:\n",
            "Train Loss: 0.0081, Train Accuracy: 0.82\n",
            "Test Loss: 0.0087, Test Accuracy: 0.80\n",
            "Accuracy of train set: 0.8226333333333333\n",
            "Epoch 12, Batch 0, test Loss: 0.5573425889015198\n",
            "Epoch 12, Batch 1, test Loss: 0.6071261763572693\n",
            "Epoch 12, Batch 2, test Loss: 0.619402289390564\n",
            "Epoch 12, Batch 3, test Loss: 0.432975172996521\n",
            "Epoch 12, Batch 4, test Loss: 0.47906672954559326\n",
            "Epoch 12, Batch 5, test Loss: 0.4622200131416321\n",
            "Epoch 12, Batch 6, test Loss: 0.5130050778388977\n",
            "Epoch 12, Batch 7, test Loss: 0.6914055943489075\n",
            "Epoch 12, Batch 8, test Loss: 0.4275711476802826\n",
            "Epoch 12, Batch 9, test Loss: 0.6062818765640259\n",
            "Epoch 12, Batch 10, test Loss: 0.40506434440612793\n",
            "Epoch 12, Batch 11, test Loss: 0.7930598258972168\n",
            "Epoch 12, Batch 12, test Loss: 0.4543854892253876\n",
            "Epoch 12, Batch 13, test Loss: 0.6951762437820435\n",
            "Epoch 12, Batch 14, test Loss: 0.39076468348503113\n",
            "Epoch 12, Batch 15, test Loss: 0.46711045503616333\n",
            "Epoch 12, Batch 16, test Loss: 0.523054301738739\n",
            "Epoch 12, Batch 17, test Loss: 0.49943745136260986\n",
            "Epoch 12, Batch 18, test Loss: 0.4720284938812256\n",
            "Epoch 12, Batch 19, test Loss: 0.35988980531692505\n",
            "Epoch 12, Batch 20, test Loss: 0.5227329730987549\n",
            "Epoch 12, Batch 21, test Loss: 0.5433921217918396\n",
            "Epoch 12, Batch 22, test Loss: 0.4859037399291992\n",
            "Epoch 12, Batch 23, test Loss: 0.6419471502304077\n",
            "Epoch 12, Batch 24, test Loss: 0.47912994027137756\n",
            "Epoch 12, Batch 25, test Loss: 0.6499186754226685\n",
            "Epoch 12, Batch 26, test Loss: 0.4877377152442932\n",
            "Epoch 12, Batch 27, test Loss: 0.5619155168533325\n",
            "Epoch 12, Batch 28, test Loss: 0.6021474599838257\n",
            "Epoch 12, Batch 29, test Loss: 0.5507150292396545\n",
            "Epoch 12, Batch 30, test Loss: 0.49781957268714905\n",
            "Epoch 12, Batch 31, test Loss: 0.3621057868003845\n",
            "Epoch 12, Batch 32, test Loss: 0.5058945417404175\n",
            "Epoch 12, Batch 33, test Loss: 0.6760011911392212\n",
            "Epoch 12, Batch 34, test Loss: 0.3751910328865051\n",
            "Epoch 12, Batch 35, test Loss: 0.4805810749530792\n",
            "Epoch 12, Batch 36, test Loss: 0.8702253699302673\n",
            "Epoch 12, Batch 37, test Loss: 0.4587613344192505\n",
            "Epoch 12, Batch 38, test Loss: 0.4273113012313843\n",
            "Epoch 12, Batch 39, test Loss: 0.4542746841907501\n",
            "Epoch 12, Batch 40, test Loss: 0.64503413438797\n",
            "Epoch 12, Batch 41, test Loss: 0.4226536452770233\n",
            "Epoch 12, Batch 42, test Loss: 0.6905160546302795\n",
            "Epoch 12, Batch 43, test Loss: 0.5405978560447693\n",
            "Epoch 12, Batch 44, test Loss: 0.612337052822113\n",
            "Epoch 12, Batch 45, test Loss: 0.6132556200027466\n",
            "Epoch 12, Batch 46, test Loss: 0.638877272605896\n",
            "Epoch 12, Batch 47, test Loss: 0.3592250645160675\n",
            "Epoch 12, Batch 48, test Loss: 0.41881614923477173\n",
            "Epoch 12, Batch 49, test Loss: 0.331357479095459\n",
            "Epoch 12, Batch 50, test Loss: 0.5361830592155457\n",
            "Epoch 12, Batch 51, test Loss: 0.7963943481445312\n",
            "Epoch 12, Batch 52, test Loss: 0.536864161491394\n",
            "Epoch 12, Batch 53, test Loss: 0.44606614112854004\n",
            "Epoch 12, Batch 54, test Loss: 0.45841822028160095\n",
            "Epoch 12, Batch 55, test Loss: 0.5255915522575378\n",
            "Epoch 12, Batch 56, test Loss: 0.4909304976463318\n",
            "Epoch 12, Batch 57, test Loss: 0.5824461579322815\n",
            "Epoch 12, Batch 58, test Loss: 0.42191648483276367\n",
            "Epoch 12, Batch 59, test Loss: 0.3941434621810913\n",
            "Epoch 12, Batch 60, test Loss: 0.6238487958908081\n",
            "Epoch 12, Batch 61, test Loss: 0.616538941860199\n",
            "Epoch 12, Batch 62, test Loss: 0.4820818305015564\n",
            "Epoch 12, Batch 63, test Loss: 0.42635148763656616\n",
            "Epoch 12, Batch 64, test Loss: 0.48478034138679504\n",
            "Epoch 12, Batch 65, test Loss: 0.4767097234725952\n",
            "Epoch 12, Batch 66, test Loss: 0.437869131565094\n",
            "Epoch 12, Batch 67, test Loss: 0.7099913358688354\n",
            "Epoch 12, Batch 68, test Loss: 0.43392103910446167\n",
            "Epoch 12, Batch 69, test Loss: 0.6138823628425598\n",
            "Epoch 12, Batch 70, test Loss: 0.5322741270065308\n",
            "Epoch 12, Batch 71, test Loss: 0.6391456127166748\n",
            "Epoch 12, Batch 72, test Loss: 0.368854820728302\n",
            "Epoch 12, Batch 73, test Loss: 0.3112848401069641\n",
            "Epoch 12, Batch 74, test Loss: 0.5986035466194153\n",
            "Epoch 12, Batch 75, test Loss: 0.45645275712013245\n",
            "Epoch 12, Batch 76, test Loss: 0.6766574382781982\n",
            "Epoch 12, Batch 77, test Loss: 0.5110195279121399\n",
            "Epoch 12, Batch 78, test Loss: 0.43754905462265015\n",
            "Epoch 12, Batch 79, test Loss: 0.6136643290519714\n",
            "Epoch 12, Batch 80, test Loss: 0.477336049079895\n",
            "Epoch 12, Batch 81, test Loss: 0.6628540754318237\n",
            "Epoch 12, Batch 82, test Loss: 0.45256972312927246\n",
            "Epoch 12, Batch 83, test Loss: 0.553787350654602\n",
            "Epoch 12, Batch 84, test Loss: 0.5919764637947083\n",
            "Epoch 12, Batch 85, test Loss: 0.5843710899353027\n",
            "Epoch 12, Batch 86, test Loss: 0.5252724885940552\n",
            "Epoch 12, Batch 87, test Loss: 0.4114523231983185\n",
            "Epoch 12, Batch 88, test Loss: 0.6082715392112732\n",
            "Epoch 12, Batch 89, test Loss: 0.5350653529167175\n",
            "Epoch 12, Batch 90, test Loss: 0.5044335126876831\n",
            "Epoch 12, Batch 91, test Loss: 0.5311272740364075\n",
            "Epoch 12, Batch 92, test Loss: 0.5345515608787537\n",
            "Epoch 12, Batch 93, test Loss: 0.5017430782318115\n",
            "Epoch 12, Batch 94, test Loss: 0.6426929235458374\n",
            "Epoch 12, Batch 95, test Loss: 0.7224858999252319\n",
            "Epoch 12, Batch 96, test Loss: 0.4970516264438629\n",
            "Epoch 12, Batch 97, test Loss: 0.6583328247070312\n",
            "Epoch 12, Batch 98, test Loss: 0.375047892332077\n",
            "Epoch 12, Batch 99, test Loss: 0.5423111915588379\n",
            "Epoch 12, Batch 100, test Loss: 0.34109002351760864\n",
            "Epoch 12, Batch 101, test Loss: 0.7270650863647461\n",
            "Epoch 12, Batch 102, test Loss: 0.3264160752296448\n",
            "Epoch 12, Batch 103, test Loss: 0.6054636240005493\n",
            "Epoch 12, Batch 104, test Loss: 0.7958177328109741\n",
            "Epoch 12, Batch 105, test Loss: 0.5804916620254517\n",
            "Epoch 12, Batch 106, test Loss: 0.5036980509757996\n",
            "Epoch 12, Batch 107, test Loss: 0.4157218933105469\n",
            "Epoch 12, Batch 108, test Loss: 0.286467969417572\n",
            "Epoch 12, Batch 109, test Loss: 0.6199357509613037\n",
            "Epoch 12, Batch 110, test Loss: 0.5917983055114746\n",
            "Epoch 12, Batch 111, test Loss: 0.3609803318977356\n",
            "Epoch 12, Batch 112, test Loss: 0.6086050271987915\n",
            "Epoch 12, Batch 113, test Loss: 0.5253891348838806\n",
            "Epoch 12, Batch 114, test Loss: 0.44494277238845825\n",
            "Epoch 12, Batch 115, test Loss: 0.6373620629310608\n",
            "Epoch 12, Batch 116, test Loss: 0.4421754777431488\n",
            "Epoch 12, Batch 117, test Loss: 0.5627882480621338\n",
            "Epoch 12, Batch 118, test Loss: 0.38302409648895264\n",
            "Epoch 12, Batch 119, test Loss: 0.4395180940628052\n",
            "Epoch 12, Batch 120, test Loss: 0.4589359760284424\n",
            "Epoch 12, Batch 121, test Loss: 0.6524083018302917\n",
            "Epoch 12, Batch 122, test Loss: 0.6232062578201294\n",
            "Epoch 12, Batch 123, test Loss: 0.6117404699325562\n",
            "Epoch 12, Batch 124, test Loss: 0.5735236406326294\n",
            "Epoch 12, Batch 125, test Loss: 0.7727218270301819\n",
            "Epoch 12, Batch 126, test Loss: 0.4805861711502075\n",
            "Epoch 12, Batch 127, test Loss: 0.49642413854599\n",
            "Epoch 12, Batch 128, test Loss: 0.6221821308135986\n",
            "Epoch 12, Batch 129, test Loss: 0.5066118240356445\n",
            "Epoch 12, Batch 130, test Loss: 0.7066727876663208\n",
            "Epoch 12, Batch 131, test Loss: 0.3706881105899811\n",
            "Epoch 12, Batch 132, test Loss: 0.6457622051239014\n",
            "Epoch 12, Batch 133, test Loss: 0.35498926043510437\n",
            "Epoch 12, Batch 134, test Loss: 0.6116021871566772\n",
            "Epoch 12, Batch 135, test Loss: 0.5651688575744629\n",
            "Epoch 12, Batch 136, test Loss: 0.47285863757133484\n",
            "Epoch 12, Batch 137, test Loss: 0.4544323682785034\n",
            "Epoch 12, Batch 138, test Loss: 0.5307691693305969\n",
            "Epoch 12, Batch 139, test Loss: 0.5225083827972412\n",
            "Epoch 12, Batch 140, test Loss: 0.4353167414665222\n",
            "Epoch 12, Batch 141, test Loss: 0.4394492208957672\n",
            "Epoch 12, Batch 142, test Loss: 0.4894351065158844\n",
            "Epoch 12, Batch 143, test Loss: 0.6887733936309814\n",
            "Epoch 12, Batch 144, test Loss: 0.5802682638168335\n",
            "Epoch 12, Batch 145, test Loss: 0.47344261407852173\n",
            "Epoch 12, Batch 146, test Loss: 0.3970741927623749\n",
            "Epoch 12, Batch 147, test Loss: 0.501208484172821\n",
            "Epoch 12, Batch 148, test Loss: 0.439307302236557\n",
            "Epoch 12, Batch 149, test Loss: 0.3681314289569855\n",
            "Epoch 12, Batch 150, test Loss: 0.6229804158210754\n",
            "Epoch 12, Batch 151, test Loss: 0.45563623309135437\n",
            "Epoch 12, Batch 152, test Loss: 0.4778499901294708\n",
            "Epoch 12, Batch 153, test Loss: 0.5711231827735901\n",
            "Epoch 12, Batch 154, test Loss: 0.7275023460388184\n",
            "Epoch 12, Batch 155, test Loss: 0.5091396570205688\n",
            "Epoch 12, Batch 156, test Loss: 0.7316783666610718\n",
            "Epoch 12, Accuracy of test set: 0.8168\n",
            "Epoch 13/25:\n",
            "Train Loss: 0.0079, Train Accuracy: 0.82\n",
            "Test Loss: 0.0083, Test Accuracy: 0.82\n",
            "Accuracy of train set: 0.8256833333333333\n",
            "Epoch 13, Batch 0, test Loss: 0.4465767741203308\n",
            "Epoch 13, Batch 1, test Loss: 0.3848957419395447\n",
            "Epoch 13, Batch 2, test Loss: 0.5130765438079834\n",
            "Epoch 13, Batch 3, test Loss: 0.48296356201171875\n",
            "Epoch 13, Batch 4, test Loss: 0.5955830812454224\n",
            "Epoch 13, Batch 5, test Loss: 0.7278599739074707\n",
            "Epoch 13, Batch 6, test Loss: 0.573280930519104\n",
            "Epoch 13, Batch 7, test Loss: 0.6967430710792542\n",
            "Epoch 13, Batch 8, test Loss: 0.3403722941875458\n",
            "Epoch 13, Batch 9, test Loss: 0.40125882625579834\n",
            "Epoch 13, Batch 10, test Loss: 0.44250819087028503\n",
            "Epoch 13, Batch 11, test Loss: 0.5896748304367065\n",
            "Epoch 13, Batch 12, test Loss: 0.5441151261329651\n",
            "Epoch 13, Batch 13, test Loss: 0.48940473794937134\n",
            "Epoch 13, Batch 14, test Loss: 0.7278354167938232\n",
            "Epoch 13, Batch 15, test Loss: 0.7052432894706726\n",
            "Epoch 13, Batch 16, test Loss: 0.6284865736961365\n",
            "Epoch 13, Batch 17, test Loss: 0.5220431089401245\n",
            "Epoch 13, Batch 18, test Loss: 0.6154420971870422\n",
            "Epoch 13, Batch 19, test Loss: 0.5783663392066956\n",
            "Epoch 13, Batch 20, test Loss: 0.38588783144950867\n",
            "Epoch 13, Batch 21, test Loss: 0.4198942482471466\n",
            "Epoch 13, Batch 22, test Loss: 0.5220634341239929\n",
            "Epoch 13, Batch 23, test Loss: 0.39288774132728577\n",
            "Epoch 13, Batch 24, test Loss: 0.6802108883857727\n",
            "Epoch 13, Batch 25, test Loss: 0.6219797134399414\n",
            "Epoch 13, Batch 26, test Loss: 0.5992973446846008\n",
            "Epoch 13, Batch 27, test Loss: 0.31325066089630127\n",
            "Epoch 13, Batch 28, test Loss: 0.6603953242301941\n",
            "Epoch 13, Batch 29, test Loss: 0.4818900525569916\n",
            "Epoch 13, Batch 30, test Loss: 0.43668249249458313\n",
            "Epoch 13, Batch 31, test Loss: 0.5685288310050964\n",
            "Epoch 13, Batch 32, test Loss: 0.4766733646392822\n",
            "Epoch 13, Batch 33, test Loss: 0.4842436909675598\n",
            "Epoch 13, Batch 34, test Loss: 0.5226319432258606\n",
            "Epoch 13, Batch 35, test Loss: 0.5484101176261902\n",
            "Epoch 13, Batch 36, test Loss: 0.7715909481048584\n",
            "Epoch 13, Batch 37, test Loss: 0.3241770267486572\n",
            "Epoch 13, Batch 38, test Loss: 0.46552497148513794\n",
            "Epoch 13, Batch 39, test Loss: 0.514945387840271\n",
            "Epoch 13, Batch 40, test Loss: 0.4325437843799591\n",
            "Epoch 13, Batch 41, test Loss: 0.412715882062912\n",
            "Epoch 13, Batch 42, test Loss: 0.5495450496673584\n",
            "Epoch 13, Batch 43, test Loss: 0.4484493136405945\n",
            "Epoch 13, Batch 44, test Loss: 0.6067941784858704\n",
            "Epoch 13, Batch 45, test Loss: 0.4207708239555359\n",
            "Epoch 13, Batch 46, test Loss: 0.45035380125045776\n",
            "Epoch 13, Batch 47, test Loss: 0.7729212045669556\n",
            "Epoch 13, Batch 48, test Loss: 0.5687914490699768\n",
            "Epoch 13, Batch 49, test Loss: 0.441972553730011\n",
            "Epoch 13, Batch 50, test Loss: 0.47039228677749634\n",
            "Epoch 13, Batch 51, test Loss: 0.5005600452423096\n",
            "Epoch 13, Batch 52, test Loss: 0.4675755202770233\n",
            "Epoch 13, Batch 53, test Loss: 0.43267714977264404\n",
            "Epoch 13, Batch 54, test Loss: 0.40332189202308655\n",
            "Epoch 13, Batch 55, test Loss: 0.8273128271102905\n",
            "Epoch 13, Batch 56, test Loss: 0.7080515027046204\n",
            "Epoch 13, Batch 57, test Loss: 0.37060657143592834\n",
            "Epoch 13, Batch 58, test Loss: 0.5584170818328857\n",
            "Epoch 13, Batch 59, test Loss: 0.25514304637908936\n",
            "Epoch 13, Batch 60, test Loss: 0.6820477843284607\n",
            "Epoch 13, Batch 61, test Loss: 0.45798155665397644\n",
            "Epoch 13, Batch 62, test Loss: 0.4808133542537689\n",
            "Epoch 13, Batch 63, test Loss: 0.49912282824516296\n",
            "Epoch 13, Batch 64, test Loss: 0.3662351369857788\n",
            "Epoch 13, Batch 65, test Loss: 0.5785416960716248\n",
            "Epoch 13, Batch 66, test Loss: 0.39896494150161743\n",
            "Epoch 13, Batch 67, test Loss: 0.6779975295066833\n",
            "Epoch 13, Batch 68, test Loss: 0.5945084691047668\n",
            "Epoch 13, Batch 69, test Loss: 0.6039586663246155\n",
            "Epoch 13, Batch 70, test Loss: 0.743445634841919\n",
            "Epoch 13, Batch 71, test Loss: 0.5325859785079956\n",
            "Epoch 13, Batch 72, test Loss: 0.456806480884552\n",
            "Epoch 13, Batch 73, test Loss: 0.5687311291694641\n",
            "Epoch 13, Batch 74, test Loss: 0.5190485119819641\n",
            "Epoch 13, Batch 75, test Loss: 0.5432443022727966\n",
            "Epoch 13, Batch 76, test Loss: 0.550460696220398\n",
            "Epoch 13, Batch 77, test Loss: 0.4916275143623352\n",
            "Epoch 13, Batch 78, test Loss: 0.7441600561141968\n",
            "Epoch 13, Batch 79, test Loss: 0.6303502917289734\n",
            "Epoch 13, Batch 80, test Loss: 0.4262641370296478\n",
            "Epoch 13, Batch 81, test Loss: 0.34818536043167114\n",
            "Epoch 13, Batch 82, test Loss: 0.6167687773704529\n",
            "Epoch 13, Batch 83, test Loss: 0.5522150993347168\n",
            "Epoch 13, Batch 84, test Loss: 0.5230091214179993\n",
            "Epoch 13, Batch 85, test Loss: 0.5508780479431152\n",
            "Epoch 13, Batch 86, test Loss: 0.5728656053543091\n",
            "Epoch 13, Batch 87, test Loss: 0.37396353483200073\n",
            "Epoch 13, Batch 88, test Loss: 0.5025390982627869\n",
            "Epoch 13, Batch 89, test Loss: 0.36482658982276917\n",
            "Epoch 13, Batch 90, test Loss: 0.46190083026885986\n",
            "Epoch 13, Batch 91, test Loss: 0.5416516661643982\n",
            "Epoch 13, Batch 92, test Loss: 0.7183043360710144\n",
            "Epoch 13, Batch 93, test Loss: 0.6806434988975525\n",
            "Epoch 13, Batch 94, test Loss: 0.5063552856445312\n",
            "Epoch 13, Batch 95, test Loss: 0.6353338360786438\n",
            "Epoch 13, Batch 96, test Loss: 0.4881090819835663\n",
            "Epoch 13, Batch 97, test Loss: 0.5160780549049377\n",
            "Epoch 13, Batch 98, test Loss: 0.31320732831954956\n",
            "Epoch 13, Batch 99, test Loss: 0.7192052602767944\n",
            "Epoch 13, Batch 100, test Loss: 0.6562711596488953\n",
            "Epoch 13, Batch 101, test Loss: 0.5131380558013916\n",
            "Epoch 13, Batch 102, test Loss: 0.6069954633712769\n",
            "Epoch 13, Batch 103, test Loss: 0.5448247194290161\n",
            "Epoch 13, Batch 104, test Loss: 0.429442822933197\n",
            "Epoch 13, Batch 105, test Loss: 0.6527199745178223\n",
            "Epoch 13, Batch 106, test Loss: 0.5315214991569519\n",
            "Epoch 13, Batch 107, test Loss: 0.3264067769050598\n",
            "Epoch 13, Batch 108, test Loss: 0.5415823459625244\n",
            "Epoch 13, Batch 109, test Loss: 0.672113835811615\n",
            "Epoch 13, Batch 110, test Loss: 0.6193806529045105\n",
            "Epoch 13, Batch 111, test Loss: 0.5230994820594788\n",
            "Epoch 13, Batch 112, test Loss: 0.6707084774971008\n",
            "Epoch 13, Batch 113, test Loss: 0.5002768039703369\n",
            "Epoch 13, Batch 114, test Loss: 0.3271549940109253\n",
            "Epoch 13, Batch 115, test Loss: 0.7705444097518921\n",
            "Epoch 13, Batch 116, test Loss: 0.5085384249687195\n",
            "Epoch 13, Batch 117, test Loss: 0.8321515917778015\n",
            "Epoch 13, Batch 118, test Loss: 0.410508930683136\n",
            "Epoch 13, Batch 119, test Loss: 0.6881558299064636\n",
            "Epoch 13, Batch 120, test Loss: 0.4536011815071106\n",
            "Epoch 13, Batch 121, test Loss: 0.38078299164772034\n",
            "Epoch 13, Batch 122, test Loss: 0.3398623466491699\n",
            "Epoch 13, Batch 123, test Loss: 0.2432948350906372\n",
            "Epoch 13, Batch 124, test Loss: 0.3812454342842102\n",
            "Epoch 13, Batch 125, test Loss: 0.5373435020446777\n",
            "Epoch 13, Batch 126, test Loss: 0.4128578305244446\n",
            "Epoch 13, Batch 127, test Loss: 0.3285686671733856\n",
            "Epoch 13, Batch 128, test Loss: 0.22977590560913086\n",
            "Epoch 13, Batch 129, test Loss: 0.6119662523269653\n",
            "Epoch 13, Batch 130, test Loss: 0.6542031168937683\n",
            "Epoch 13, Batch 131, test Loss: 0.42528924345970154\n",
            "Epoch 13, Batch 132, test Loss: 0.47250473499298096\n",
            "Epoch 13, Batch 133, test Loss: 0.5313857793807983\n",
            "Epoch 13, Batch 134, test Loss: 0.5993939638137817\n",
            "Epoch 13, Batch 135, test Loss: 0.47023144364356995\n",
            "Epoch 13, Batch 136, test Loss: 0.5710166692733765\n",
            "Epoch 13, Batch 137, test Loss: 0.38408318161964417\n",
            "Epoch 13, Batch 138, test Loss: 0.6228910088539124\n",
            "Epoch 13, Batch 139, test Loss: 0.4485316276550293\n",
            "Epoch 13, Batch 140, test Loss: 0.706981897354126\n",
            "Epoch 13, Batch 141, test Loss: 0.5496829152107239\n",
            "Epoch 13, Batch 142, test Loss: 0.5052473545074463\n",
            "Epoch 13, Batch 143, test Loss: 0.36690810322761536\n",
            "Epoch 13, Batch 144, test Loss: 0.5437371730804443\n",
            "Epoch 13, Batch 145, test Loss: 0.6103508472442627\n",
            "Epoch 13, Batch 146, test Loss: 0.3089982867240906\n",
            "Epoch 13, Batch 147, test Loss: 0.549502968788147\n",
            "Epoch 13, Batch 148, test Loss: 0.5001657009124756\n",
            "Epoch 13, Batch 149, test Loss: 0.5612513422966003\n",
            "Epoch 13, Batch 150, test Loss: 0.653915524482727\n",
            "Epoch 13, Batch 151, test Loss: 0.37454643845558167\n",
            "Epoch 13, Batch 152, test Loss: 0.3088719844818115\n",
            "Epoch 13, Batch 153, test Loss: 0.2458886355161667\n",
            "Epoch 13, Batch 154, test Loss: 0.5195176601409912\n",
            "Epoch 13, Batch 155, test Loss: 0.41992172598838806\n",
            "Epoch 13, Batch 156, test Loss: 0.6594757437705994\n",
            "Epoch 13, Accuracy of test set: 0.8168\n",
            "Epoch 14/25:\n",
            "Train Loss: 0.0076, Train Accuracy: 0.83\n",
            "Test Loss: 0.0082, Test Accuracy: 0.82\n",
            "Accuracy of train set: 0.8318166666666666\n",
            "Epoch 14, Batch 0, test Loss: 0.4646818935871124\n",
            "Epoch 14, Batch 1, test Loss: 0.5062203407287598\n",
            "Epoch 14, Batch 2, test Loss: 0.37432000041007996\n",
            "Epoch 14, Batch 3, test Loss: 0.6830809712409973\n",
            "Epoch 14, Batch 4, test Loss: 0.49371203780174255\n",
            "Epoch 14, Batch 5, test Loss: 0.5493745803833008\n",
            "Epoch 14, Batch 6, test Loss: 0.46015727519989014\n",
            "Epoch 14, Batch 7, test Loss: 0.5876836776733398\n",
            "Epoch 14, Batch 8, test Loss: 0.44875046610832214\n",
            "Epoch 14, Batch 9, test Loss: 0.5198020339012146\n",
            "Epoch 14, Batch 10, test Loss: 0.29007989168167114\n",
            "Epoch 14, Batch 11, test Loss: 0.42415851354599\n",
            "Epoch 14, Batch 12, test Loss: 0.39565983414649963\n",
            "Epoch 14, Batch 13, test Loss: 0.5083500146865845\n",
            "Epoch 14, Batch 14, test Loss: 0.600004255771637\n",
            "Epoch 14, Batch 15, test Loss: 0.5464746952056885\n",
            "Epoch 14, Batch 16, test Loss: 0.6039434671401978\n",
            "Epoch 14, Batch 17, test Loss: 0.4427970349788666\n",
            "Epoch 14, Batch 18, test Loss: 0.46038538217544556\n",
            "Epoch 14, Batch 19, test Loss: 0.5657832622528076\n",
            "Epoch 14, Batch 20, test Loss: 0.3401859402656555\n",
            "Epoch 14, Batch 21, test Loss: 0.5955241918563843\n",
            "Epoch 14, Batch 22, test Loss: 0.6851795315742493\n",
            "Epoch 14, Batch 23, test Loss: 0.6634047031402588\n",
            "Epoch 14, Batch 24, test Loss: 0.44852060079574585\n",
            "Epoch 14, Batch 25, test Loss: 0.4766971170902252\n",
            "Epoch 14, Batch 26, test Loss: 0.5337287187576294\n",
            "Epoch 14, Batch 27, test Loss: 0.7388384938240051\n",
            "Epoch 14, Batch 28, test Loss: 0.38637176156044006\n",
            "Epoch 14, Batch 29, test Loss: 0.41181322932243347\n",
            "Epoch 14, Batch 30, test Loss: 0.5115927457809448\n",
            "Epoch 14, Batch 31, test Loss: 0.47421833872795105\n",
            "Epoch 14, Batch 32, test Loss: 0.7749233245849609\n",
            "Epoch 14, Batch 33, test Loss: 0.5482547283172607\n",
            "Epoch 14, Batch 34, test Loss: 0.396892786026001\n",
            "Epoch 14, Batch 35, test Loss: 0.5689348578453064\n",
            "Epoch 14, Batch 36, test Loss: 0.4981752336025238\n",
            "Epoch 14, Batch 37, test Loss: 0.38551831245422363\n",
            "Epoch 14, Batch 38, test Loss: 0.42828369140625\n",
            "Epoch 14, Batch 39, test Loss: 0.6090555787086487\n",
            "Epoch 14, Batch 40, test Loss: 0.5258172750473022\n",
            "Epoch 14, Batch 41, test Loss: 0.47442302107810974\n",
            "Epoch 14, Batch 42, test Loss: 0.5232127904891968\n",
            "Epoch 14, Batch 43, test Loss: 0.5253252983093262\n",
            "Epoch 14, Batch 44, test Loss: 0.6569163799285889\n",
            "Epoch 14, Batch 45, test Loss: 0.47897961735725403\n",
            "Epoch 14, Batch 46, test Loss: 0.47037002444267273\n",
            "Epoch 14, Batch 47, test Loss: 0.36359527707099915\n",
            "Epoch 14, Batch 48, test Loss: 0.5927736163139343\n",
            "Epoch 14, Batch 49, test Loss: 0.5716549158096313\n",
            "Epoch 14, Batch 50, test Loss: 0.44513940811157227\n",
            "Epoch 14, Batch 51, test Loss: 0.5263610482215881\n",
            "Epoch 14, Batch 52, test Loss: 0.5892429947853088\n",
            "Epoch 14, Batch 53, test Loss: 0.47617220878601074\n",
            "Epoch 14, Batch 54, test Loss: 0.5629248023033142\n",
            "Epoch 14, Batch 55, test Loss: 0.5532323122024536\n",
            "Epoch 14, Batch 56, test Loss: 0.39913225173950195\n",
            "Epoch 14, Batch 57, test Loss: 0.6241015791893005\n",
            "Epoch 14, Batch 58, test Loss: 0.5072681903839111\n",
            "Epoch 14, Batch 59, test Loss: 0.653507649898529\n",
            "Epoch 14, Batch 60, test Loss: 0.38531219959259033\n",
            "Epoch 14, Batch 61, test Loss: 0.3796367645263672\n",
            "Epoch 14, Batch 62, test Loss: 0.8623120188713074\n",
            "Epoch 14, Batch 63, test Loss: 0.46688151359558105\n",
            "Epoch 14, Batch 64, test Loss: 0.4544662833213806\n",
            "Epoch 14, Batch 65, test Loss: 0.614576518535614\n",
            "Epoch 14, Batch 66, test Loss: 0.6129390001296997\n",
            "Epoch 14, Batch 67, test Loss: 0.42007705569267273\n",
            "Epoch 14, Batch 68, test Loss: 0.6507047414779663\n",
            "Epoch 14, Batch 69, test Loss: 0.543936014175415\n",
            "Epoch 14, Batch 70, test Loss: 0.37813183665275574\n",
            "Epoch 14, Batch 71, test Loss: 0.7206555604934692\n",
            "Epoch 14, Batch 72, test Loss: 0.9949734807014465\n",
            "Epoch 14, Batch 73, test Loss: 0.4402633607387543\n",
            "Epoch 14, Batch 74, test Loss: 0.5715463161468506\n",
            "Epoch 14, Batch 75, test Loss: 0.4431827664375305\n",
            "Epoch 14, Batch 76, test Loss: 0.4336073696613312\n",
            "Epoch 14, Batch 77, test Loss: 0.4842025935649872\n",
            "Epoch 14, Batch 78, test Loss: 0.47801679372787476\n",
            "Epoch 14, Batch 79, test Loss: 0.3585352599620819\n",
            "Epoch 14, Batch 80, test Loss: 0.4464564621448517\n",
            "Epoch 14, Batch 81, test Loss: 0.4550034999847412\n",
            "Epoch 14, Batch 82, test Loss: 0.5025759935379028\n",
            "Epoch 14, Batch 83, test Loss: 0.8286231756210327\n",
            "Epoch 14, Batch 84, test Loss: 0.5685855746269226\n",
            "Epoch 14, Batch 85, test Loss: 0.6342158317565918\n",
            "Epoch 14, Batch 86, test Loss: 0.48681285977363586\n",
            "Epoch 14, Batch 87, test Loss: 0.5705986022949219\n",
            "Epoch 14, Batch 88, test Loss: 0.5237961411476135\n",
            "Epoch 14, Batch 89, test Loss: 0.4213463366031647\n",
            "Epoch 14, Batch 90, test Loss: 0.5456066727638245\n",
            "Epoch 14, Batch 91, test Loss: 0.6677268147468567\n",
            "Epoch 14, Batch 92, test Loss: 0.4098614752292633\n",
            "Epoch 14, Batch 93, test Loss: 0.48619750142097473\n",
            "Epoch 14, Batch 94, test Loss: 0.6470904350280762\n",
            "Epoch 14, Batch 95, test Loss: 0.4686509370803833\n",
            "Epoch 14, Batch 96, test Loss: 0.5180463194847107\n",
            "Epoch 14, Batch 97, test Loss: 0.45549091696739197\n",
            "Epoch 14, Batch 98, test Loss: 0.5020009875297546\n",
            "Epoch 14, Batch 99, test Loss: 0.5801257491111755\n",
            "Epoch 14, Batch 100, test Loss: 0.677837610244751\n",
            "Epoch 14, Batch 101, test Loss: 0.5025694370269775\n",
            "Epoch 14, Batch 102, test Loss: 0.48904019594192505\n",
            "Epoch 14, Batch 103, test Loss: 0.6198161840438843\n",
            "Epoch 14, Batch 104, test Loss: 0.5029342174530029\n",
            "Epoch 14, Batch 105, test Loss: 0.5986822247505188\n",
            "Epoch 14, Batch 106, test Loss: 0.5897424221038818\n",
            "Epoch 14, Batch 107, test Loss: 0.5354114770889282\n",
            "Epoch 14, Batch 108, test Loss: 0.5578354597091675\n",
            "Epoch 14, Batch 109, test Loss: 0.7610183954238892\n",
            "Epoch 14, Batch 110, test Loss: 0.5222674012184143\n",
            "Epoch 14, Batch 111, test Loss: 0.6664890646934509\n",
            "Epoch 14, Batch 112, test Loss: 0.5041375160217285\n",
            "Epoch 14, Batch 113, test Loss: 0.6199102997779846\n",
            "Epoch 14, Batch 114, test Loss: 0.4332734942436218\n",
            "Epoch 14, Batch 115, test Loss: 0.5858452320098877\n",
            "Epoch 14, Batch 116, test Loss: 0.47276678681373596\n",
            "Epoch 14, Batch 117, test Loss: 0.47614073753356934\n",
            "Epoch 14, Batch 118, test Loss: 0.49625641107559204\n",
            "Epoch 14, Batch 119, test Loss: 0.24581672251224518\n",
            "Epoch 14, Batch 120, test Loss: 0.5211493372917175\n",
            "Epoch 14, Batch 121, test Loss: 0.4621444642543793\n",
            "Epoch 14, Batch 122, test Loss: 0.4509863257408142\n",
            "Epoch 14, Batch 123, test Loss: 0.44325166940689087\n",
            "Epoch 14, Batch 124, test Loss: 0.44729092717170715\n",
            "Epoch 14, Batch 125, test Loss: 0.34309178590774536\n",
            "Epoch 14, Batch 126, test Loss: 0.4750971496105194\n",
            "Epoch 14, Batch 127, test Loss: 0.7114533185958862\n",
            "Epoch 14, Batch 128, test Loss: 0.34931522607803345\n",
            "Epoch 14, Batch 129, test Loss: 0.4151040017604828\n",
            "Epoch 14, Batch 130, test Loss: 0.4963642954826355\n",
            "Epoch 14, Batch 131, test Loss: 0.3916955590248108\n",
            "Epoch 14, Batch 132, test Loss: 0.5144901871681213\n",
            "Epoch 14, Batch 133, test Loss: 0.7978549599647522\n",
            "Epoch 14, Batch 134, test Loss: 0.38599899411201477\n",
            "Epoch 14, Batch 135, test Loss: 0.833319902420044\n",
            "Epoch 14, Batch 136, test Loss: 0.7514138221740723\n",
            "Epoch 14, Batch 137, test Loss: 0.4818965196609497\n",
            "Epoch 14, Batch 138, test Loss: 0.47849780321121216\n",
            "Epoch 14, Batch 139, test Loss: 0.392634779214859\n",
            "Epoch 14, Batch 140, test Loss: 0.5449050068855286\n",
            "Epoch 14, Batch 141, test Loss: 0.3871205151081085\n",
            "Epoch 14, Batch 142, test Loss: 0.5389590263366699\n",
            "Epoch 14, Batch 143, test Loss: 0.6620252132415771\n",
            "Epoch 14, Batch 144, test Loss: 0.5004984140396118\n",
            "Epoch 14, Batch 145, test Loss: 0.5213690996170044\n",
            "Epoch 14, Batch 146, test Loss: 0.4079253375530243\n",
            "Epoch 14, Batch 147, test Loss: 0.2683180570602417\n",
            "Epoch 14, Batch 148, test Loss: 0.5057348012924194\n",
            "Epoch 14, Batch 149, test Loss: 0.5590144991874695\n",
            "Epoch 14, Batch 150, test Loss: 0.4397984445095062\n",
            "Epoch 14, Batch 151, test Loss: 0.40437769889831543\n",
            "Epoch 14, Batch 152, test Loss: 0.4579610526561737\n",
            "Epoch 14, Batch 153, test Loss: 0.42610034346580505\n",
            "Epoch 14, Batch 154, test Loss: 0.3003307282924652\n",
            "Epoch 14, Batch 155, test Loss: 0.40775635838508606\n",
            "Epoch 14, Batch 156, test Loss: 0.49266207218170166\n",
            "Epoch 14, Accuracy of test set: 0.8152\n",
            "Epoch 15/25:\n",
            "Train Loss: 0.0074, Train Accuracy: 0.83\n",
            "Test Loss: 0.0081, Test Accuracy: 0.82\n",
            "Accuracy of train set: 0.8353166666666667\n",
            "Epoch 15, Batch 0, test Loss: 0.41850394010543823\n",
            "Epoch 15, Batch 1, test Loss: 0.7683125734329224\n",
            "Epoch 15, Batch 2, test Loss: 0.5340142250061035\n",
            "Epoch 15, Batch 3, test Loss: 0.5054095387458801\n",
            "Epoch 15, Batch 4, test Loss: 0.7035096287727356\n",
            "Epoch 15, Batch 5, test Loss: 0.4968993067741394\n",
            "Epoch 15, Batch 6, test Loss: 0.6042118668556213\n",
            "Epoch 15, Batch 7, test Loss: 0.6560632586479187\n",
            "Epoch 15, Batch 8, test Loss: 0.3744919002056122\n",
            "Epoch 15, Batch 9, test Loss: 0.6317211389541626\n",
            "Epoch 15, Batch 10, test Loss: 0.6883943676948547\n",
            "Epoch 15, Batch 11, test Loss: 0.7313932180404663\n",
            "Epoch 15, Batch 12, test Loss: 0.596854567527771\n",
            "Epoch 15, Batch 13, test Loss: 0.3182857036590576\n",
            "Epoch 15, Batch 14, test Loss: 0.3027248978614807\n",
            "Epoch 15, Batch 15, test Loss: 0.5580936074256897\n",
            "Epoch 15, Batch 16, test Loss: 0.4933076500892639\n",
            "Epoch 15, Batch 17, test Loss: 0.6496076583862305\n",
            "Epoch 15, Batch 18, test Loss: 0.44101786613464355\n",
            "Epoch 15, Batch 19, test Loss: 0.5335813164710999\n",
            "Epoch 15, Batch 20, test Loss: 0.6556391716003418\n",
            "Epoch 15, Batch 21, test Loss: 0.307847261428833\n",
            "Epoch 15, Batch 22, test Loss: 0.290410578250885\n",
            "Epoch 15, Batch 23, test Loss: 0.4492107033729553\n",
            "Epoch 15, Batch 24, test Loss: 0.6240932941436768\n",
            "Epoch 15, Batch 25, test Loss: 0.6480482816696167\n",
            "Epoch 15, Batch 26, test Loss: 0.5630803108215332\n",
            "Epoch 15, Batch 27, test Loss: 0.3574589490890503\n",
            "Epoch 15, Batch 28, test Loss: 0.42727455496788025\n",
            "Epoch 15, Batch 29, test Loss: 0.5718235373497009\n",
            "Epoch 15, Batch 30, test Loss: 0.4893217384815216\n",
            "Epoch 15, Batch 31, test Loss: 0.37886425852775574\n",
            "Epoch 15, Batch 32, test Loss: 0.49517327547073364\n",
            "Epoch 15, Batch 33, test Loss: 0.42157238721847534\n",
            "Epoch 15, Batch 34, test Loss: 0.36907655000686646\n",
            "Epoch 15, Batch 35, test Loss: 0.7422071695327759\n",
            "Epoch 15, Batch 36, test Loss: 0.3713836073875427\n",
            "Epoch 15, Batch 37, test Loss: 0.5228407382965088\n",
            "Epoch 15, Batch 38, test Loss: 0.30070582032203674\n",
            "Epoch 15, Batch 39, test Loss: 0.3697183132171631\n",
            "Epoch 15, Batch 40, test Loss: 0.5929099917411804\n",
            "Epoch 15, Batch 41, test Loss: 0.4730674624443054\n",
            "Epoch 15, Batch 42, test Loss: 0.39962831139564514\n",
            "Epoch 15, Batch 43, test Loss: 0.4591148793697357\n",
            "Epoch 15, Batch 44, test Loss: 0.283611536026001\n",
            "Epoch 15, Batch 45, test Loss: 0.2986218333244324\n",
            "Epoch 15, Batch 46, test Loss: 0.4750184416770935\n",
            "Epoch 15, Batch 47, test Loss: 0.6466485857963562\n",
            "Epoch 15, Batch 48, test Loss: 0.47425973415374756\n",
            "Epoch 15, Batch 49, test Loss: 0.6782693862915039\n",
            "Epoch 15, Batch 50, test Loss: 0.5572841167449951\n",
            "Epoch 15, Batch 51, test Loss: 0.5514972805976868\n",
            "Epoch 15, Batch 52, test Loss: 0.36478808522224426\n",
            "Epoch 15, Batch 53, test Loss: 0.37967827916145325\n",
            "Epoch 15, Batch 54, test Loss: 0.38505688309669495\n",
            "Epoch 15, Batch 55, test Loss: 0.7272780537605286\n",
            "Epoch 15, Batch 56, test Loss: 0.6285558342933655\n",
            "Epoch 15, Batch 57, test Loss: 0.39809828996658325\n",
            "Epoch 15, Batch 58, test Loss: 0.5825679302215576\n",
            "Epoch 15, Batch 59, test Loss: 0.5220797657966614\n",
            "Epoch 15, Batch 60, test Loss: 0.6393285393714905\n",
            "Epoch 15, Batch 61, test Loss: 0.727165937423706\n",
            "Epoch 15, Batch 62, test Loss: 0.36281242966651917\n",
            "Epoch 15, Batch 63, test Loss: 0.5721537470817566\n",
            "Epoch 15, Batch 64, test Loss: 0.712742269039154\n",
            "Epoch 15, Batch 65, test Loss: 0.367166668176651\n",
            "Epoch 15, Batch 66, test Loss: 0.5814982056617737\n",
            "Epoch 15, Batch 67, test Loss: 0.4909067153930664\n",
            "Epoch 15, Batch 68, test Loss: 0.5626624822616577\n",
            "Epoch 15, Batch 69, test Loss: 0.5212094187736511\n",
            "Epoch 15, Batch 70, test Loss: 0.5582598447799683\n",
            "Epoch 15, Batch 71, test Loss: 0.3658212423324585\n",
            "Epoch 15, Batch 72, test Loss: 0.401587575674057\n",
            "Epoch 15, Batch 73, test Loss: 0.5852288007736206\n",
            "Epoch 15, Batch 74, test Loss: 0.49789974093437195\n",
            "Epoch 15, Batch 75, test Loss: 0.5421164631843567\n",
            "Epoch 15, Batch 76, test Loss: 0.6316526532173157\n",
            "Epoch 15, Batch 77, test Loss: 0.42095446586608887\n",
            "Epoch 15, Batch 78, test Loss: 0.4581504166126251\n",
            "Epoch 15, Batch 79, test Loss: 0.6307759284973145\n",
            "Epoch 15, Batch 80, test Loss: 0.5378128886222839\n",
            "Epoch 15, Batch 81, test Loss: 0.5557512044906616\n",
            "Epoch 15, Batch 82, test Loss: 0.3920553922653198\n",
            "Epoch 15, Batch 83, test Loss: 0.5344279408454895\n",
            "Epoch 15, Batch 84, test Loss: 0.38501599431037903\n",
            "Epoch 15, Batch 85, test Loss: 0.35267388820648193\n",
            "Epoch 15, Batch 86, test Loss: 0.47076302766799927\n",
            "Epoch 15, Batch 87, test Loss: 0.5480787754058838\n",
            "Epoch 15, Batch 88, test Loss: 0.3856982886791229\n",
            "Epoch 15, Batch 89, test Loss: 0.3980149030685425\n",
            "Epoch 15, Batch 90, test Loss: 0.47000786662101746\n",
            "Epoch 15, Batch 91, test Loss: 0.35693836212158203\n",
            "Epoch 15, Batch 92, test Loss: 0.6765077114105225\n",
            "Epoch 15, Batch 93, test Loss: 0.7607672214508057\n",
            "Epoch 15, Batch 94, test Loss: 0.5415842533111572\n",
            "Epoch 15, Batch 95, test Loss: 0.48909980058670044\n",
            "Epoch 15, Batch 96, test Loss: 0.4568225145339966\n",
            "Epoch 15, Batch 97, test Loss: 0.35749155282974243\n",
            "Epoch 15, Batch 98, test Loss: 0.6445012092590332\n",
            "Epoch 15, Batch 99, test Loss: 0.6164900660514832\n",
            "Epoch 15, Batch 100, test Loss: 0.5500946640968323\n",
            "Epoch 15, Batch 101, test Loss: 0.395801305770874\n",
            "Epoch 15, Batch 102, test Loss: 0.5816319584846497\n",
            "Epoch 15, Batch 103, test Loss: 0.4700051546096802\n",
            "Epoch 15, Batch 104, test Loss: 0.3598793148994446\n",
            "Epoch 15, Batch 105, test Loss: 0.32660409808158875\n",
            "Epoch 15, Batch 106, test Loss: 0.6003376245498657\n",
            "Epoch 15, Batch 107, test Loss: 0.5323904156684875\n",
            "Epoch 15, Batch 108, test Loss: 0.6650242805480957\n",
            "Epoch 15, Batch 109, test Loss: 0.4545295536518097\n",
            "Epoch 15, Batch 110, test Loss: 0.4269771873950958\n",
            "Epoch 15, Batch 111, test Loss: 0.41181716322898865\n",
            "Epoch 15, Batch 112, test Loss: 0.5920910239219666\n",
            "Epoch 15, Batch 113, test Loss: 0.5734362602233887\n",
            "Epoch 15, Batch 114, test Loss: 0.4086019992828369\n",
            "Epoch 15, Batch 115, test Loss: 0.3450431823730469\n",
            "Epoch 15, Batch 116, test Loss: 0.3700377345085144\n",
            "Epoch 15, Batch 117, test Loss: 0.49455833435058594\n",
            "Epoch 15, Batch 118, test Loss: 0.5786378383636475\n",
            "Epoch 15, Batch 119, test Loss: 0.3849671185016632\n",
            "Epoch 15, Batch 120, test Loss: 0.6095717549324036\n",
            "Epoch 15, Batch 121, test Loss: 0.5997252464294434\n",
            "Epoch 15, Batch 122, test Loss: 0.4771577715873718\n",
            "Epoch 15, Batch 123, test Loss: 0.4871070981025696\n",
            "Epoch 15, Batch 124, test Loss: 0.37460190057754517\n",
            "Epoch 15, Batch 125, test Loss: 0.38387277722358704\n",
            "Epoch 15, Batch 126, test Loss: 0.40337827801704407\n",
            "Epoch 15, Batch 127, test Loss: 0.5115760564804077\n",
            "Epoch 15, Batch 128, test Loss: 0.4268397092819214\n",
            "Epoch 15, Batch 129, test Loss: 0.5210391283035278\n",
            "Epoch 15, Batch 130, test Loss: 0.5324413776397705\n",
            "Epoch 15, Batch 131, test Loss: 0.3629027009010315\n",
            "Epoch 15, Batch 132, test Loss: 0.3811069428920746\n",
            "Epoch 15, Batch 133, test Loss: 0.4566172957420349\n",
            "Epoch 15, Batch 134, test Loss: 0.4726691246032715\n",
            "Epoch 15, Batch 135, test Loss: 0.364192932844162\n",
            "Epoch 15, Batch 136, test Loss: 0.4970533847808838\n",
            "Epoch 15, Batch 137, test Loss: 0.3710346221923828\n",
            "Epoch 15, Batch 138, test Loss: 0.54709792137146\n",
            "Epoch 15, Batch 139, test Loss: 0.4727408289909363\n",
            "Epoch 15, Batch 140, test Loss: 0.5942134857177734\n",
            "Epoch 15, Batch 141, test Loss: 0.7007731199264526\n",
            "Epoch 15, Batch 142, test Loss: 0.5651260018348694\n",
            "Epoch 15, Batch 143, test Loss: 0.5493765473365784\n",
            "Epoch 15, Batch 144, test Loss: 0.5689674019813538\n",
            "Epoch 15, Batch 145, test Loss: 0.3823345899581909\n",
            "Epoch 15, Batch 146, test Loss: 0.5114391446113586\n",
            "Epoch 15, Batch 147, test Loss: 0.636239230632782\n",
            "Epoch 15, Batch 148, test Loss: 0.5108444094657898\n",
            "Epoch 15, Batch 149, test Loss: 0.4769956171512604\n",
            "Epoch 15, Batch 150, test Loss: 0.4493523836135864\n",
            "Epoch 15, Batch 151, test Loss: 0.5993034243583679\n",
            "Epoch 15, Batch 152, test Loss: 0.5865477919578552\n",
            "Epoch 15, Batch 153, test Loss: 0.2636842727661133\n",
            "Epoch 15, Batch 154, test Loss: 0.47744086384773254\n",
            "Epoch 15, Batch 155, test Loss: 0.2895459830760956\n",
            "Epoch 15, Batch 156, test Loss: 0.4429609477519989\n",
            "Epoch 15, Accuracy of test set: 0.8229\n",
            "Epoch 16/25:\n",
            "Train Loss: 0.0073, Train Accuracy: 0.84\n",
            "Test Loss: 0.0078, Test Accuracy: 0.82\n",
            "Accuracy of train set: 0.83925\n",
            "Epoch 16, Batch 0, test Loss: 0.4635162651538849\n",
            "Epoch 16, Batch 1, test Loss: 0.427338570356369\n",
            "Epoch 16, Batch 2, test Loss: 0.530207097530365\n",
            "Epoch 16, Batch 3, test Loss: 0.5181946754455566\n",
            "Epoch 16, Batch 4, test Loss: 0.46559539437294006\n",
            "Epoch 16, Batch 5, test Loss: 0.5821396112442017\n",
            "Epoch 16, Batch 6, test Loss: 0.6315953135490417\n",
            "Epoch 16, Batch 7, test Loss: 0.5604566931724548\n",
            "Epoch 16, Batch 8, test Loss: 0.3898886442184448\n",
            "Epoch 16, Batch 9, test Loss: 0.6079429388046265\n",
            "Epoch 16, Batch 10, test Loss: 0.43124154210090637\n",
            "Epoch 16, Batch 11, test Loss: 0.495577335357666\n",
            "Epoch 16, Batch 12, test Loss: 0.335183709859848\n",
            "Epoch 16, Batch 13, test Loss: 0.3795086741447449\n",
            "Epoch 16, Batch 14, test Loss: 0.6235011219978333\n",
            "Epoch 16, Batch 15, test Loss: 0.45905715227127075\n",
            "Epoch 16, Batch 16, test Loss: 0.5296893119812012\n",
            "Epoch 16, Batch 17, test Loss: 0.6939599514007568\n",
            "Epoch 16, Batch 18, test Loss: 0.49292054772377014\n",
            "Epoch 16, Batch 19, test Loss: 0.33551809191703796\n",
            "Epoch 16, Batch 20, test Loss: 0.6226109266281128\n",
            "Epoch 16, Batch 21, test Loss: 0.38284313678741455\n",
            "Epoch 16, Batch 22, test Loss: 0.5720630884170532\n",
            "Epoch 16, Batch 23, test Loss: 0.23755139112472534\n",
            "Epoch 16, Batch 24, test Loss: 0.6100313067436218\n",
            "Epoch 16, Batch 25, test Loss: 0.36813950538635254\n",
            "Epoch 16, Batch 26, test Loss: 0.5360580086708069\n",
            "Epoch 16, Batch 27, test Loss: 0.6663221716880798\n",
            "Epoch 16, Batch 28, test Loss: 0.6057878136634827\n",
            "Epoch 16, Batch 29, test Loss: 0.3979712724685669\n",
            "Epoch 16, Batch 30, test Loss: 0.5232263803482056\n",
            "Epoch 16, Batch 31, test Loss: 0.3418063819408417\n",
            "Epoch 16, Batch 32, test Loss: 0.4786534309387207\n",
            "Epoch 16, Batch 33, test Loss: 0.3518206775188446\n",
            "Epoch 16, Batch 34, test Loss: 0.3247775137424469\n",
            "Epoch 16, Batch 35, test Loss: 0.5760608911514282\n",
            "Epoch 16, Batch 36, test Loss: 0.2800480127334595\n",
            "Epoch 16, Batch 37, test Loss: 0.2392769604921341\n",
            "Epoch 16, Batch 38, test Loss: 0.6286704540252686\n",
            "Epoch 16, Batch 39, test Loss: 0.5288920402526855\n",
            "Epoch 16, Batch 40, test Loss: 0.4984232485294342\n",
            "Epoch 16, Batch 41, test Loss: 0.37509283423423767\n",
            "Epoch 16, Batch 42, test Loss: 0.4329865574836731\n",
            "Epoch 16, Batch 43, test Loss: 0.41343921422958374\n",
            "Epoch 16, Batch 44, test Loss: 0.4834102392196655\n",
            "Epoch 16, Batch 45, test Loss: 0.42422300577163696\n",
            "Epoch 16, Batch 46, test Loss: 0.43096864223480225\n",
            "Epoch 16, Batch 47, test Loss: 0.6305997967720032\n",
            "Epoch 16, Batch 48, test Loss: 0.5212464332580566\n",
            "Epoch 16, Batch 49, test Loss: 0.7678432464599609\n",
            "Epoch 16, Batch 50, test Loss: 0.3839358985424042\n",
            "Epoch 16, Batch 51, test Loss: 0.3248143792152405\n",
            "Epoch 16, Batch 52, test Loss: 0.41565796732902527\n",
            "Epoch 16, Batch 53, test Loss: 0.44283992052078247\n",
            "Epoch 16, Batch 54, test Loss: 0.4059145450592041\n",
            "Epoch 16, Batch 55, test Loss: 0.5237281322479248\n",
            "Epoch 16, Batch 56, test Loss: 0.686355710029602\n",
            "Epoch 16, Batch 57, test Loss: 0.46358269453048706\n",
            "Epoch 16, Batch 58, test Loss: 0.5510116219520569\n",
            "Epoch 16, Batch 59, test Loss: 0.5388787984848022\n",
            "Epoch 16, Batch 60, test Loss: 0.58424973487854\n",
            "Epoch 16, Batch 61, test Loss: 0.4076286554336548\n",
            "Epoch 16, Batch 62, test Loss: 0.5659655928611755\n",
            "Epoch 16, Batch 63, test Loss: 0.35403743386268616\n",
            "Epoch 16, Batch 64, test Loss: 0.5933516621589661\n",
            "Epoch 16, Batch 65, test Loss: 0.4874797463417053\n",
            "Epoch 16, Batch 66, test Loss: 0.5563651919364929\n",
            "Epoch 16, Batch 67, test Loss: 0.3660251498222351\n",
            "Epoch 16, Batch 68, test Loss: 0.473153293132782\n",
            "Epoch 16, Batch 69, test Loss: 0.5760854482650757\n",
            "Epoch 16, Batch 70, test Loss: 0.648393452167511\n",
            "Epoch 16, Batch 71, test Loss: 0.4376911222934723\n",
            "Epoch 16, Batch 72, test Loss: 0.4932742118835449\n",
            "Epoch 16, Batch 73, test Loss: 0.5310402512550354\n",
            "Epoch 16, Batch 74, test Loss: 0.3837965726852417\n",
            "Epoch 16, Batch 75, test Loss: 0.4237964153289795\n",
            "Epoch 16, Batch 76, test Loss: 0.44694674015045166\n",
            "Epoch 16, Batch 77, test Loss: 0.3969470262527466\n",
            "Epoch 16, Batch 78, test Loss: 0.3429764211177826\n",
            "Epoch 16, Batch 79, test Loss: 0.2600686848163605\n",
            "Epoch 16, Batch 80, test Loss: 0.6902898550033569\n",
            "Epoch 16, Batch 81, test Loss: 0.46472570300102234\n",
            "Epoch 16, Batch 82, test Loss: 0.5321105718612671\n",
            "Epoch 16, Batch 83, test Loss: 0.3828471004962921\n",
            "Epoch 16, Batch 84, test Loss: 0.27431875467300415\n",
            "Epoch 16, Batch 85, test Loss: 0.3836343586444855\n",
            "Epoch 16, Batch 86, test Loss: 0.5672116279602051\n",
            "Epoch 16, Batch 87, test Loss: 0.44637635350227356\n",
            "Epoch 16, Batch 88, test Loss: 0.453075647354126\n",
            "Epoch 16, Batch 89, test Loss: 0.552049458026886\n",
            "Epoch 16, Batch 90, test Loss: 0.2526191473007202\n",
            "Epoch 16, Batch 91, test Loss: 0.5460023880004883\n",
            "Epoch 16, Batch 92, test Loss: 0.4428656995296478\n",
            "Epoch 16, Batch 93, test Loss: 0.4892350137233734\n",
            "Epoch 16, Batch 94, test Loss: 0.587658166885376\n",
            "Epoch 16, Batch 95, test Loss: 0.46699100732803345\n",
            "Epoch 16, Batch 96, test Loss: 0.40991345047950745\n",
            "Epoch 16, Batch 97, test Loss: 0.5122883319854736\n",
            "Epoch 16, Batch 98, test Loss: 0.3227863907814026\n",
            "Epoch 16, Batch 99, test Loss: 0.5693385004997253\n",
            "Epoch 16, Batch 100, test Loss: 0.5020946860313416\n",
            "Epoch 16, Batch 101, test Loss: 0.43012794852256775\n",
            "Epoch 16, Batch 102, test Loss: 0.35855239629745483\n",
            "Epoch 16, Batch 103, test Loss: 0.5238471031188965\n",
            "Epoch 16, Batch 104, test Loss: 0.4628937840461731\n",
            "Epoch 16, Batch 105, test Loss: 0.37710705399513245\n",
            "Epoch 16, Batch 106, test Loss: 0.31358277797698975\n",
            "Epoch 16, Batch 107, test Loss: 0.491920530796051\n",
            "Epoch 16, Batch 108, test Loss: 0.5441320538520813\n",
            "Epoch 16, Batch 109, test Loss: 0.41571858525276184\n",
            "Epoch 16, Batch 110, test Loss: 0.629669725894928\n",
            "Epoch 16, Batch 111, test Loss: 0.3535555303096771\n",
            "Epoch 16, Batch 112, test Loss: 0.401213139295578\n",
            "Epoch 16, Batch 113, test Loss: 0.6153664588928223\n",
            "Epoch 16, Batch 114, test Loss: 0.3654576539993286\n",
            "Epoch 16, Batch 115, test Loss: 0.47761717438697815\n",
            "Epoch 16, Batch 116, test Loss: 0.5939419269561768\n",
            "Epoch 16, Batch 117, test Loss: 0.3993118107318878\n",
            "Epoch 16, Batch 118, test Loss: 0.4242686629295349\n",
            "Epoch 16, Batch 119, test Loss: 0.7028172016143799\n",
            "Epoch 16, Batch 120, test Loss: 0.5419316291809082\n",
            "Epoch 16, Batch 121, test Loss: 0.5619399547576904\n",
            "Epoch 16, Batch 122, test Loss: 0.5634041428565979\n",
            "Epoch 16, Batch 123, test Loss: 0.5078784823417664\n",
            "Epoch 16, Batch 124, test Loss: 0.4692237079143524\n",
            "Epoch 16, Batch 125, test Loss: 0.3130877614021301\n",
            "Epoch 16, Batch 126, test Loss: 0.5409337878227234\n",
            "Epoch 16, Batch 127, test Loss: 0.4510573744773865\n",
            "Epoch 16, Batch 128, test Loss: 0.7193089723587036\n",
            "Epoch 16, Batch 129, test Loss: 0.6315212249755859\n",
            "Epoch 16, Batch 130, test Loss: 0.3278769850730896\n",
            "Epoch 16, Batch 131, test Loss: 0.38875195384025574\n",
            "Epoch 16, Batch 132, test Loss: 0.37382352352142334\n",
            "Epoch 16, Batch 133, test Loss: 0.45190751552581787\n",
            "Epoch 16, Batch 134, test Loss: 0.6554325222969055\n",
            "Epoch 16, Batch 135, test Loss: 0.34725433588027954\n",
            "Epoch 16, Batch 136, test Loss: 0.5800093412399292\n",
            "Epoch 16, Batch 137, test Loss: 0.3927583694458008\n",
            "Epoch 16, Batch 138, test Loss: 0.38340404629707336\n",
            "Epoch 16, Batch 139, test Loss: 0.3577817678451538\n",
            "Epoch 16, Batch 140, test Loss: 0.8355634212493896\n",
            "Epoch 16, Batch 141, test Loss: 0.31843918561935425\n",
            "Epoch 16, Batch 142, test Loss: 0.3461484909057617\n",
            "Epoch 16, Batch 143, test Loss: 0.4339185655117035\n",
            "Epoch 16, Batch 144, test Loss: 0.5794155597686768\n",
            "Epoch 16, Batch 145, test Loss: 0.37058669328689575\n",
            "Epoch 16, Batch 146, test Loss: 0.44258278608322144\n",
            "Epoch 16, Batch 147, test Loss: 0.5222664475440979\n",
            "Epoch 16, Batch 148, test Loss: 0.5129715204238892\n",
            "Epoch 16, Batch 149, test Loss: 0.43228408694267273\n",
            "Epoch 16, Batch 150, test Loss: 0.6514872908592224\n",
            "Epoch 16, Batch 151, test Loss: 0.6149086356163025\n",
            "Epoch 16, Batch 152, test Loss: 0.5087558031082153\n",
            "Epoch 16, Batch 153, test Loss: 0.4732508957386017\n",
            "Epoch 16, Batch 154, test Loss: 0.6845617294311523\n",
            "Epoch 16, Batch 155, test Loss: 0.48724129796028137\n",
            "Epoch 16, Batch 156, test Loss: 0.3212568759918213\n",
            "Epoch 16, Accuracy of test set: 0.8309\n",
            "Epoch 17/25:\n",
            "Train Loss: 0.0071, Train Accuracy: 0.84\n",
            "Test Loss: 0.0075, Test Accuracy: 0.83\n",
            "Accuracy of train set: 0.8441666666666666\n",
            "Epoch 17, Batch 0, test Loss: 0.4012996256351471\n",
            "Epoch 17, Batch 1, test Loss: 0.5601048469543457\n",
            "Epoch 17, Batch 2, test Loss: 0.7041572332382202\n",
            "Epoch 17, Batch 3, test Loss: 0.5707974433898926\n",
            "Epoch 17, Batch 4, test Loss: 0.5802042484283447\n",
            "Epoch 17, Batch 5, test Loss: 0.48664119839668274\n",
            "Epoch 17, Batch 6, test Loss: 0.5109152793884277\n",
            "Epoch 17, Batch 7, test Loss: 0.4798066318035126\n",
            "Epoch 17, Batch 8, test Loss: 0.6849343776702881\n",
            "Epoch 17, Batch 9, test Loss: 0.5512844324111938\n",
            "Epoch 17, Batch 10, test Loss: 0.5242581367492676\n",
            "Epoch 17, Batch 11, test Loss: 0.6003548502922058\n",
            "Epoch 17, Batch 12, test Loss: 0.6125662922859192\n",
            "Epoch 17, Batch 13, test Loss: 0.478424996137619\n",
            "Epoch 17, Batch 14, test Loss: 0.5570839643478394\n",
            "Epoch 17, Batch 15, test Loss: 0.5322203636169434\n",
            "Epoch 17, Batch 16, test Loss: 0.5083978772163391\n",
            "Epoch 17, Batch 17, test Loss: 0.5871473550796509\n",
            "Epoch 17, Batch 18, test Loss: 0.6151573657989502\n",
            "Epoch 17, Batch 19, test Loss: 0.22597545385360718\n",
            "Epoch 17, Batch 20, test Loss: 0.48484617471694946\n",
            "Epoch 17, Batch 21, test Loss: 0.5407282710075378\n",
            "Epoch 17, Batch 22, test Loss: 0.48531946539878845\n",
            "Epoch 17, Batch 23, test Loss: 0.25236839056015015\n",
            "Epoch 17, Batch 24, test Loss: 0.42908862233161926\n",
            "Epoch 17, Batch 25, test Loss: 0.6225652098655701\n",
            "Epoch 17, Batch 26, test Loss: 0.44010987877845764\n",
            "Epoch 17, Batch 27, test Loss: 0.571904718875885\n",
            "Epoch 17, Batch 28, test Loss: 0.536122739315033\n",
            "Epoch 17, Batch 29, test Loss: 0.5234746932983398\n",
            "Epoch 17, Batch 30, test Loss: 0.5744547247886658\n",
            "Epoch 17, Batch 31, test Loss: 0.49952566623687744\n",
            "Epoch 17, Batch 32, test Loss: 0.4936179518699646\n",
            "Epoch 17, Batch 33, test Loss: 0.3996162414550781\n",
            "Epoch 17, Batch 34, test Loss: 0.47893404960632324\n",
            "Epoch 17, Batch 35, test Loss: 0.5452358722686768\n",
            "Epoch 17, Batch 36, test Loss: 0.30710369348526\n",
            "Epoch 17, Batch 37, test Loss: 0.6570892930030823\n",
            "Epoch 17, Batch 38, test Loss: 0.39888715744018555\n",
            "Epoch 17, Batch 39, test Loss: 0.5448361039161682\n",
            "Epoch 17, Batch 40, test Loss: 0.7266272902488708\n",
            "Epoch 17, Batch 41, test Loss: 0.5339720249176025\n",
            "Epoch 17, Batch 42, test Loss: 0.4534273147583008\n",
            "Epoch 17, Batch 43, test Loss: 0.5868806838989258\n",
            "Epoch 17, Batch 44, test Loss: 0.5887861847877502\n",
            "Epoch 17, Batch 45, test Loss: 0.4221998453140259\n",
            "Epoch 17, Batch 46, test Loss: 0.45415300130844116\n",
            "Epoch 17, Batch 47, test Loss: 0.5435110330581665\n",
            "Epoch 17, Batch 48, test Loss: 0.5428325533866882\n",
            "Epoch 17, Batch 49, test Loss: 0.6475270390510559\n",
            "Epoch 17, Batch 50, test Loss: 0.379177987575531\n",
            "Epoch 17, Batch 51, test Loss: 0.5203245282173157\n",
            "Epoch 17, Batch 52, test Loss: 0.6017254590988159\n",
            "Epoch 17, Batch 53, test Loss: 0.4289902448654175\n",
            "Epoch 17, Batch 54, test Loss: 0.34127098321914673\n",
            "Epoch 17, Batch 55, test Loss: 0.5353936553001404\n",
            "Epoch 17, Batch 56, test Loss: 0.31053465604782104\n",
            "Epoch 17, Batch 57, test Loss: 0.3661692142486572\n",
            "Epoch 17, Batch 58, test Loss: 0.369839072227478\n",
            "Epoch 17, Batch 59, test Loss: 0.38879451155662537\n",
            "Epoch 17, Batch 60, test Loss: 0.7215256690979004\n",
            "Epoch 17, Batch 61, test Loss: 0.5287458896636963\n",
            "Epoch 17, Batch 62, test Loss: 0.37127912044525146\n",
            "Epoch 17, Batch 63, test Loss: 0.4489747881889343\n",
            "Epoch 17, Batch 64, test Loss: 0.7419115304946899\n",
            "Epoch 17, Batch 65, test Loss: 0.4614076614379883\n",
            "Epoch 17, Batch 66, test Loss: 0.39365166425704956\n",
            "Epoch 17, Batch 67, test Loss: 0.5038784742355347\n",
            "Epoch 17, Batch 68, test Loss: 0.5573763251304626\n",
            "Epoch 17, Batch 69, test Loss: 0.5210385322570801\n",
            "Epoch 17, Batch 70, test Loss: 0.6648876070976257\n",
            "Epoch 17, Batch 71, test Loss: 0.32156243920326233\n",
            "Epoch 17, Batch 72, test Loss: 0.6354105472564697\n",
            "Epoch 17, Batch 73, test Loss: 0.4621102213859558\n",
            "Epoch 17, Batch 74, test Loss: 0.5629369616508484\n",
            "Epoch 17, Batch 75, test Loss: 0.5153852701187134\n",
            "Epoch 17, Batch 76, test Loss: 0.45275259017944336\n",
            "Epoch 17, Batch 77, test Loss: 0.5085798501968384\n",
            "Epoch 17, Batch 78, test Loss: 0.44391316175460815\n",
            "Epoch 17, Batch 79, test Loss: 0.40198248624801636\n",
            "Epoch 17, Batch 80, test Loss: 0.5286175012588501\n",
            "Epoch 17, Batch 81, test Loss: 0.38118091225624084\n",
            "Epoch 17, Batch 82, test Loss: 0.4681586027145386\n",
            "Epoch 17, Batch 83, test Loss: 0.5138756632804871\n",
            "Epoch 17, Batch 84, test Loss: 0.6591402292251587\n",
            "Epoch 17, Batch 85, test Loss: 0.4393054246902466\n",
            "Epoch 17, Batch 86, test Loss: 0.5235198140144348\n",
            "Epoch 17, Batch 87, test Loss: 0.284404456615448\n",
            "Epoch 17, Batch 88, test Loss: 0.44940048456192017\n",
            "Epoch 17, Batch 89, test Loss: 0.5363063216209412\n",
            "Epoch 17, Batch 90, test Loss: 0.3967008888721466\n",
            "Epoch 17, Batch 91, test Loss: 0.4142407178878784\n",
            "Epoch 17, Batch 92, test Loss: 0.3710681200027466\n",
            "Epoch 17, Batch 93, test Loss: 0.6759191155433655\n",
            "Epoch 17, Batch 94, test Loss: 0.34327176213264465\n",
            "Epoch 17, Batch 95, test Loss: 0.5567362904548645\n",
            "Epoch 17, Batch 96, test Loss: 0.5030069947242737\n",
            "Epoch 17, Batch 97, test Loss: 0.30160602927207947\n",
            "Epoch 17, Batch 98, test Loss: 0.5749470591545105\n",
            "Epoch 17, Batch 99, test Loss: 0.347442090511322\n",
            "Epoch 17, Batch 100, test Loss: 0.4153304994106293\n",
            "Epoch 17, Batch 101, test Loss: 0.4421021640300751\n",
            "Epoch 17, Batch 102, test Loss: 0.48324787616729736\n",
            "Epoch 17, Batch 103, test Loss: 0.6251941919326782\n",
            "Epoch 17, Batch 104, test Loss: 0.5279813408851624\n",
            "Epoch 17, Batch 105, test Loss: 0.4262598752975464\n",
            "Epoch 17, Batch 106, test Loss: 0.378418505191803\n",
            "Epoch 17, Batch 107, test Loss: 0.5327537655830383\n",
            "Epoch 17, Batch 108, test Loss: 0.629916787147522\n",
            "Epoch 17, Batch 109, test Loss: 0.42256420850753784\n",
            "Epoch 17, Batch 110, test Loss: 0.5326156616210938\n",
            "Epoch 17, Batch 111, test Loss: 0.4607585072517395\n",
            "Epoch 17, Batch 112, test Loss: 0.3988625109195709\n",
            "Epoch 17, Batch 113, test Loss: 0.39640167355537415\n",
            "Epoch 17, Batch 114, test Loss: 0.4337816536426544\n",
            "Epoch 17, Batch 115, test Loss: 0.44357165694236755\n",
            "Epoch 17, Batch 116, test Loss: 0.732550859451294\n",
            "Epoch 17, Batch 117, test Loss: 0.32674700021743774\n",
            "Epoch 17, Batch 118, test Loss: 0.573840320110321\n",
            "Epoch 17, Batch 119, test Loss: 0.5210524201393127\n",
            "Epoch 17, Batch 120, test Loss: 0.378621369600296\n",
            "Epoch 17, Batch 121, test Loss: 0.4242624044418335\n",
            "Epoch 17, Batch 122, test Loss: 0.6089547872543335\n",
            "Epoch 17, Batch 123, test Loss: 0.592851459980011\n",
            "Epoch 17, Batch 124, test Loss: 0.388037770986557\n",
            "Epoch 17, Batch 125, test Loss: 0.45081156492233276\n",
            "Epoch 17, Batch 126, test Loss: 0.370137482881546\n",
            "Epoch 17, Batch 127, test Loss: 0.367775559425354\n",
            "Epoch 17, Batch 128, test Loss: 0.4352376163005829\n",
            "Epoch 17, Batch 129, test Loss: 0.4704226851463318\n",
            "Epoch 17, Batch 130, test Loss: 0.3432151973247528\n",
            "Epoch 17, Batch 131, test Loss: 0.39048895239830017\n",
            "Epoch 17, Batch 132, test Loss: 0.5839407444000244\n",
            "Epoch 17, Batch 133, test Loss: 0.5761521458625793\n",
            "Epoch 17, Batch 134, test Loss: 0.4150075912475586\n",
            "Epoch 17, Batch 135, test Loss: 0.5822369456291199\n",
            "Epoch 17, Batch 136, test Loss: 0.3422476053237915\n",
            "Epoch 17, Batch 137, test Loss: 0.6051857471466064\n",
            "Epoch 17, Batch 138, test Loss: 0.6846911311149597\n",
            "Epoch 17, Batch 139, test Loss: 0.4606395959854126\n",
            "Epoch 17, Batch 140, test Loss: 0.6763054728507996\n",
            "Epoch 17, Batch 141, test Loss: 0.701429545879364\n",
            "Epoch 17, Batch 142, test Loss: 0.44928404688835144\n",
            "Epoch 17, Batch 143, test Loss: 0.6251418590545654\n",
            "Epoch 17, Batch 144, test Loss: 0.3664456307888031\n",
            "Epoch 17, Batch 145, test Loss: 0.5285847187042236\n",
            "Epoch 17, Batch 146, test Loss: 0.7426842451095581\n",
            "Epoch 17, Batch 147, test Loss: 0.6451097726821899\n",
            "Epoch 17, Batch 148, test Loss: 0.4575129449367523\n",
            "Epoch 17, Batch 149, test Loss: 0.6843410730361938\n",
            "Epoch 17, Batch 150, test Loss: 0.32266199588775635\n",
            "Epoch 17, Batch 151, test Loss: 0.5474961400032043\n",
            "Epoch 17, Batch 152, test Loss: 0.40939807891845703\n",
            "Epoch 17, Batch 153, test Loss: 0.43636542558670044\n",
            "Epoch 17, Batch 154, test Loss: 0.48532119393348694\n",
            "Epoch 17, Batch 155, test Loss: 0.3137226402759552\n",
            "Epoch 17, Batch 156, test Loss: 0.3952208459377289\n",
            "Epoch 17, Accuracy of test set: 0.8192\n",
            "Epoch 18/25:\n",
            "Train Loss: 0.0069, Train Accuracy: 0.84\n",
            "Test Loss: 0.0078, Test Accuracy: 0.82\n",
            "Accuracy of train set: 0.8469166666666667\n",
            "Epoch 18, Batch 0, test Loss: 0.3207584619522095\n",
            "Epoch 18, Batch 1, test Loss: 0.5294644236564636\n",
            "Epoch 18, Batch 2, test Loss: 0.5067140460014343\n",
            "Epoch 18, Batch 3, test Loss: 0.8064486980438232\n",
            "Epoch 18, Batch 4, test Loss: 0.602383017539978\n",
            "Epoch 18, Batch 5, test Loss: 0.7297311425209045\n",
            "Epoch 18, Batch 6, test Loss: 0.41649243235588074\n",
            "Epoch 18, Batch 7, test Loss: 0.597453236579895\n",
            "Epoch 18, Batch 8, test Loss: 0.47112908959388733\n",
            "Epoch 18, Batch 9, test Loss: 0.5872129797935486\n",
            "Epoch 18, Batch 10, test Loss: 0.4917358458042145\n",
            "Epoch 18, Batch 11, test Loss: 0.43560728430747986\n",
            "Epoch 18, Batch 12, test Loss: 0.5017420649528503\n",
            "Epoch 18, Batch 13, test Loss: 0.6848074793815613\n",
            "Epoch 18, Batch 14, test Loss: 0.5280380249023438\n",
            "Epoch 18, Batch 15, test Loss: 0.6597322225570679\n",
            "Epoch 18, Batch 16, test Loss: 0.5694231390953064\n",
            "Epoch 18, Batch 17, test Loss: 0.4668733477592468\n",
            "Epoch 18, Batch 18, test Loss: 0.5104979872703552\n",
            "Epoch 18, Batch 19, test Loss: 0.2754681706428528\n",
            "Epoch 18, Batch 20, test Loss: 0.4156836271286011\n",
            "Epoch 18, Batch 21, test Loss: 0.509876549243927\n",
            "Epoch 18, Batch 22, test Loss: 0.43304774165153503\n",
            "Epoch 18, Batch 23, test Loss: 0.958383321762085\n",
            "Epoch 18, Batch 24, test Loss: 0.5330018401145935\n",
            "Epoch 18, Batch 25, test Loss: 0.368452787399292\n",
            "Epoch 18, Batch 26, test Loss: 0.4391937255859375\n",
            "Epoch 18, Batch 27, test Loss: 0.3500475585460663\n",
            "Epoch 18, Batch 28, test Loss: 0.4843336343765259\n",
            "Epoch 18, Batch 29, test Loss: 0.4551171362400055\n",
            "Epoch 18, Batch 30, test Loss: 0.7190573811531067\n",
            "Epoch 18, Batch 31, test Loss: 0.41545915603637695\n",
            "Epoch 18, Batch 32, test Loss: 0.5746216773986816\n",
            "Epoch 18, Batch 33, test Loss: 0.5200702548027039\n",
            "Epoch 18, Batch 34, test Loss: 0.5130941867828369\n",
            "Epoch 18, Batch 35, test Loss: 0.5851552486419678\n",
            "Epoch 18, Batch 36, test Loss: 0.6306381225585938\n",
            "Epoch 18, Batch 37, test Loss: 0.3771035969257355\n",
            "Epoch 18, Batch 38, test Loss: 0.5223369598388672\n",
            "Epoch 18, Batch 39, test Loss: 0.6060750484466553\n",
            "Epoch 18, Batch 40, test Loss: 0.5704079866409302\n",
            "Epoch 18, Batch 41, test Loss: 0.7476434111595154\n",
            "Epoch 18, Batch 42, test Loss: 0.492849737405777\n",
            "Epoch 18, Batch 43, test Loss: 0.40194568037986755\n",
            "Epoch 18, Batch 44, test Loss: 0.4301433563232422\n",
            "Epoch 18, Batch 45, test Loss: 0.6221626400947571\n",
            "Epoch 18, Batch 46, test Loss: 0.39618590474128723\n",
            "Epoch 18, Batch 47, test Loss: 0.555922269821167\n",
            "Epoch 18, Batch 48, test Loss: 0.4562181532382965\n",
            "Epoch 18, Batch 49, test Loss: 0.3725263178348541\n",
            "Epoch 18, Batch 50, test Loss: 0.6844193339347839\n",
            "Epoch 18, Batch 51, test Loss: 0.4843772351741791\n",
            "Epoch 18, Batch 52, test Loss: 0.5693668127059937\n",
            "Epoch 18, Batch 53, test Loss: 0.6425746083259583\n",
            "Epoch 18, Batch 54, test Loss: 0.6701785922050476\n",
            "Epoch 18, Batch 55, test Loss: 0.49696972966194153\n",
            "Epoch 18, Batch 56, test Loss: 0.5330451726913452\n",
            "Epoch 18, Batch 57, test Loss: 0.4689154624938965\n",
            "Epoch 18, Batch 58, test Loss: 0.6504518389701843\n",
            "Epoch 18, Batch 59, test Loss: 0.5674436688423157\n",
            "Epoch 18, Batch 60, test Loss: 0.3127089738845825\n",
            "Epoch 18, Batch 61, test Loss: 0.33107030391693115\n",
            "Epoch 18, Batch 62, test Loss: 0.6116373538970947\n",
            "Epoch 18, Batch 63, test Loss: 0.5871450901031494\n",
            "Epoch 18, Batch 64, test Loss: 0.5518739223480225\n",
            "Epoch 18, Batch 65, test Loss: 0.6230925917625427\n",
            "Epoch 18, Batch 66, test Loss: 0.6631226539611816\n",
            "Epoch 18, Batch 67, test Loss: 0.43643009662628174\n",
            "Epoch 18, Batch 68, test Loss: 0.483114629983902\n",
            "Epoch 18, Batch 69, test Loss: 0.5894873142242432\n",
            "Epoch 18, Batch 70, test Loss: 0.4363180696964264\n",
            "Epoch 18, Batch 71, test Loss: 0.44401752948760986\n",
            "Epoch 18, Batch 72, test Loss: 0.5531893372535706\n",
            "Epoch 18, Batch 73, test Loss: 0.5682353973388672\n",
            "Epoch 18, Batch 74, test Loss: 0.7053170800209045\n",
            "Epoch 18, Batch 75, test Loss: 0.6262140870094299\n",
            "Epoch 18, Batch 76, test Loss: 0.7860032916069031\n",
            "Epoch 18, Batch 77, test Loss: 0.7490360140800476\n",
            "Epoch 18, Batch 78, test Loss: 0.4549179971218109\n",
            "Epoch 18, Batch 79, test Loss: 0.5715200304985046\n",
            "Epoch 18, Batch 80, test Loss: 0.519238293170929\n",
            "Epoch 18, Batch 81, test Loss: 0.5724380016326904\n",
            "Epoch 18, Batch 82, test Loss: 0.5087617635726929\n",
            "Epoch 18, Batch 83, test Loss: 0.44650325179100037\n",
            "Epoch 18, Batch 84, test Loss: 0.4335954487323761\n",
            "Epoch 18, Batch 85, test Loss: 0.6078987717628479\n",
            "Epoch 18, Batch 86, test Loss: 0.292743980884552\n",
            "Epoch 18, Batch 87, test Loss: 0.764350414276123\n",
            "Epoch 18, Batch 88, test Loss: 0.5922988057136536\n",
            "Epoch 18, Batch 89, test Loss: 0.4344598352909088\n",
            "Epoch 18, Batch 90, test Loss: 0.634211540222168\n",
            "Epoch 18, Batch 91, test Loss: 0.488239586353302\n",
            "Epoch 18, Batch 92, test Loss: 0.536357045173645\n",
            "Epoch 18, Batch 93, test Loss: 0.34683042764663696\n",
            "Epoch 18, Batch 94, test Loss: 0.7790719270706177\n",
            "Epoch 18, Batch 95, test Loss: 0.4719131290912628\n",
            "Epoch 18, Batch 96, test Loss: 0.4712958037853241\n",
            "Epoch 18, Batch 97, test Loss: 0.42346248030662537\n",
            "Epoch 18, Batch 98, test Loss: 0.7397040128707886\n",
            "Epoch 18, Batch 99, test Loss: 0.38218799233436584\n",
            "Epoch 18, Batch 100, test Loss: 0.4318242073059082\n",
            "Epoch 18, Batch 101, test Loss: 0.8696994781494141\n",
            "Epoch 18, Batch 102, test Loss: 0.480630487203598\n",
            "Epoch 18, Batch 103, test Loss: 0.5688852667808533\n",
            "Epoch 18, Batch 104, test Loss: 0.5857473015785217\n",
            "Epoch 18, Batch 105, test Loss: 0.4576866328716278\n",
            "Epoch 18, Batch 106, test Loss: 0.3190595209598541\n",
            "Epoch 18, Batch 107, test Loss: 0.5213567018508911\n",
            "Epoch 18, Batch 108, test Loss: 0.7000148296356201\n",
            "Epoch 18, Batch 109, test Loss: 0.5433531403541565\n",
            "Epoch 18, Batch 110, test Loss: 0.39927059412002563\n",
            "Epoch 18, Batch 111, test Loss: 0.4695383310317993\n",
            "Epoch 18, Batch 112, test Loss: 0.5001612901687622\n",
            "Epoch 18, Batch 113, test Loss: 0.678196132183075\n",
            "Epoch 18, Batch 114, test Loss: 0.6469413042068481\n",
            "Epoch 18, Batch 115, test Loss: 0.36738020181655884\n",
            "Epoch 18, Batch 116, test Loss: 0.5787112712860107\n",
            "Epoch 18, Batch 117, test Loss: 0.6115456819534302\n",
            "Epoch 18, Batch 118, test Loss: 0.5499666333198547\n",
            "Epoch 18, Batch 119, test Loss: 0.663436233997345\n",
            "Epoch 18, Batch 120, test Loss: 0.5786023736000061\n",
            "Epoch 18, Batch 121, test Loss: 0.6200348734855652\n",
            "Epoch 18, Batch 122, test Loss: 0.379374623298645\n",
            "Epoch 18, Batch 123, test Loss: 0.5488225817680359\n",
            "Epoch 18, Batch 124, test Loss: 0.6719430685043335\n",
            "Epoch 18, Batch 125, test Loss: 0.8007131218910217\n",
            "Epoch 18, Batch 126, test Loss: 0.6025421023368835\n",
            "Epoch 18, Batch 127, test Loss: 0.5045697689056396\n",
            "Epoch 18, Batch 128, test Loss: 0.5158018469810486\n",
            "Epoch 18, Batch 129, test Loss: 0.4771696925163269\n",
            "Epoch 18, Batch 130, test Loss: 0.5425465703010559\n",
            "Epoch 18, Batch 131, test Loss: 0.4864870011806488\n",
            "Epoch 18, Batch 132, test Loss: 0.41836079955101013\n",
            "Epoch 18, Batch 133, test Loss: 0.49897751212120056\n",
            "Epoch 18, Batch 134, test Loss: 0.4536241590976715\n",
            "Epoch 18, Batch 135, test Loss: 0.5723000168800354\n",
            "Epoch 18, Batch 136, test Loss: 0.26386794447898865\n",
            "Epoch 18, Batch 137, test Loss: 0.48262491822242737\n",
            "Epoch 18, Batch 138, test Loss: 0.4569283723831177\n",
            "Epoch 18, Batch 139, test Loss: 0.797954261302948\n",
            "Epoch 18, Batch 140, test Loss: 0.6837870478630066\n",
            "Epoch 18, Batch 141, test Loss: 0.3617171347141266\n",
            "Epoch 18, Batch 142, test Loss: 0.6500950455665588\n",
            "Epoch 18, Batch 143, test Loss: 0.36423787474632263\n",
            "Epoch 18, Batch 144, test Loss: 0.559782862663269\n",
            "Epoch 18, Batch 145, test Loss: 0.38603922724723816\n",
            "Epoch 18, Batch 146, test Loss: 0.5474823713302612\n",
            "Epoch 18, Batch 147, test Loss: 0.5946707725524902\n",
            "Epoch 18, Batch 148, test Loss: 0.41775137186050415\n",
            "Epoch 18, Batch 149, test Loss: 0.3907826542854309\n",
            "Epoch 18, Batch 150, test Loss: 0.48459237813949585\n",
            "Epoch 18, Batch 151, test Loss: 0.8270160555839539\n",
            "Epoch 18, Batch 152, test Loss: 0.48603904247283936\n",
            "Epoch 18, Batch 153, test Loss: 0.7818495035171509\n",
            "Epoch 18, Batch 154, test Loss: 0.8554517030715942\n",
            "Epoch 18, Batch 155, test Loss: 0.7328780889511108\n",
            "Epoch 18, Batch 156, test Loss: 1.2263275384902954\n",
            "Epoch 18, Accuracy of test set: 0.8089\n",
            "Epoch 19/25:\n",
            "Train Loss: 0.0068, Train Accuracy: 0.85\n",
            "Test Loss: 0.0085, Test Accuracy: 0.81\n",
            "Accuracy of train set: 0.8507\n",
            "Epoch 19, Batch 0, test Loss: 0.4343714118003845\n",
            "Epoch 19, Batch 1, test Loss: 0.5175970792770386\n",
            "Epoch 19, Batch 2, test Loss: 0.4097987711429596\n",
            "Epoch 19, Batch 3, test Loss: 0.33668479323387146\n",
            "Epoch 19, Batch 4, test Loss: 0.42489057779312134\n",
            "Epoch 19, Batch 5, test Loss: 0.4545018672943115\n",
            "Epoch 19, Batch 6, test Loss: 0.5832172632217407\n",
            "Epoch 19, Batch 7, test Loss: 0.5201632976531982\n",
            "Epoch 19, Batch 8, test Loss: 0.6899863481521606\n",
            "Epoch 19, Batch 9, test Loss: 0.5383798480033875\n",
            "Epoch 19, Batch 10, test Loss: 0.4468134641647339\n",
            "Epoch 19, Batch 11, test Loss: 0.31836771965026855\n",
            "Epoch 19, Batch 12, test Loss: 0.3033882975578308\n",
            "Epoch 19, Batch 13, test Loss: 0.5566520094871521\n",
            "Epoch 19, Batch 14, test Loss: 0.36065801978111267\n",
            "Epoch 19, Batch 15, test Loss: 0.4301857054233551\n",
            "Epoch 19, Batch 16, test Loss: 0.6359425783157349\n",
            "Epoch 19, Batch 17, test Loss: 0.3711063265800476\n",
            "Epoch 19, Batch 18, test Loss: 0.5829446315765381\n",
            "Epoch 19, Batch 19, test Loss: 0.437619686126709\n",
            "Epoch 19, Batch 20, test Loss: 0.5014654994010925\n",
            "Epoch 19, Batch 21, test Loss: 0.3485538959503174\n",
            "Epoch 19, Batch 22, test Loss: 0.5338942408561707\n",
            "Epoch 19, Batch 23, test Loss: 0.4942842423915863\n",
            "Epoch 19, Batch 24, test Loss: 0.3864648938179016\n",
            "Epoch 19, Batch 25, test Loss: 0.4178648591041565\n",
            "Epoch 19, Batch 26, test Loss: 0.4098875820636749\n",
            "Epoch 19, Batch 27, test Loss: 0.7240004539489746\n",
            "Epoch 19, Batch 28, test Loss: 0.5161566734313965\n",
            "Epoch 19, Batch 29, test Loss: 0.6508473753929138\n",
            "Epoch 19, Batch 30, test Loss: 0.45279794931411743\n",
            "Epoch 19, Batch 31, test Loss: 0.4770534336566925\n",
            "Epoch 19, Batch 32, test Loss: 0.5252113938331604\n",
            "Epoch 19, Batch 33, test Loss: 0.5778390169143677\n",
            "Epoch 19, Batch 34, test Loss: 0.6023836135864258\n",
            "Epoch 19, Batch 35, test Loss: 0.3133397698402405\n",
            "Epoch 19, Batch 36, test Loss: 0.49206608533859253\n",
            "Epoch 19, Batch 37, test Loss: 0.38870298862457275\n",
            "Epoch 19, Batch 38, test Loss: 0.40142273902893066\n",
            "Epoch 19, Batch 39, test Loss: 0.46254026889801025\n",
            "Epoch 19, Batch 40, test Loss: 0.2790416181087494\n",
            "Epoch 19, Batch 41, test Loss: 0.510208785533905\n",
            "Epoch 19, Batch 42, test Loss: 0.4202728271484375\n",
            "Epoch 19, Batch 43, test Loss: 0.48499855399131775\n",
            "Epoch 19, Batch 44, test Loss: 0.6468731760978699\n",
            "Epoch 19, Batch 45, test Loss: 0.33371055126190186\n",
            "Epoch 19, Batch 46, test Loss: 0.32031679153442383\n",
            "Epoch 19, Batch 47, test Loss: 0.6371960043907166\n",
            "Epoch 19, Batch 48, test Loss: 0.4984312355518341\n",
            "Epoch 19, Batch 49, test Loss: 0.3471214473247528\n",
            "Epoch 19, Batch 50, test Loss: 0.4805046617984772\n",
            "Epoch 19, Batch 51, test Loss: 0.489143431186676\n",
            "Epoch 19, Batch 52, test Loss: 0.5781040191650391\n",
            "Epoch 19, Batch 53, test Loss: 0.33526790142059326\n",
            "Epoch 19, Batch 54, test Loss: 0.4737044870853424\n",
            "Epoch 19, Batch 55, test Loss: 0.39923810958862305\n",
            "Epoch 19, Batch 56, test Loss: 0.428872287273407\n",
            "Epoch 19, Batch 57, test Loss: 0.3422534465789795\n",
            "Epoch 19, Batch 58, test Loss: 0.37673407793045044\n",
            "Epoch 19, Batch 59, test Loss: 0.4997914135456085\n",
            "Epoch 19, Batch 60, test Loss: 0.4964330196380615\n",
            "Epoch 19, Batch 61, test Loss: 0.4225141108036041\n",
            "Epoch 19, Batch 62, test Loss: 0.4246602952480316\n",
            "Epoch 19, Batch 63, test Loss: 0.5256646871566772\n",
            "Epoch 19, Batch 64, test Loss: 0.4194328784942627\n",
            "Epoch 19, Batch 65, test Loss: 0.5373790860176086\n",
            "Epoch 19, Batch 66, test Loss: 0.6125959157943726\n",
            "Epoch 19, Batch 67, test Loss: 0.3840087354183197\n",
            "Epoch 19, Batch 68, test Loss: 0.47519615292549133\n",
            "Epoch 19, Batch 69, test Loss: 0.4780634045600891\n",
            "Epoch 19, Batch 70, test Loss: 0.4022076725959778\n",
            "Epoch 19, Batch 71, test Loss: 0.5285083651542664\n",
            "Epoch 19, Batch 72, test Loss: 0.5579463243484497\n",
            "Epoch 19, Batch 73, test Loss: 0.4692131578922272\n",
            "Epoch 19, Batch 74, test Loss: 0.5455504655838013\n",
            "Epoch 19, Batch 75, test Loss: 0.2895266115665436\n",
            "Epoch 19, Batch 76, test Loss: 0.39342421293258667\n",
            "Epoch 19, Batch 77, test Loss: 0.39086681604385376\n",
            "Epoch 19, Batch 78, test Loss: 0.34630298614501953\n",
            "Epoch 19, Batch 79, test Loss: 0.4776180386543274\n",
            "Epoch 19, Batch 80, test Loss: 0.2954103946685791\n",
            "Epoch 19, Batch 81, test Loss: 0.3512957990169525\n",
            "Epoch 19, Batch 82, test Loss: 0.6932618021965027\n",
            "Epoch 19, Batch 83, test Loss: 0.39406701922416687\n",
            "Epoch 19, Batch 84, test Loss: 0.31943070888519287\n",
            "Epoch 19, Batch 85, test Loss: 0.3484678864479065\n",
            "Epoch 19, Batch 86, test Loss: 0.5756557583808899\n",
            "Epoch 19, Batch 87, test Loss: 0.4199090898036957\n",
            "Epoch 19, Batch 88, test Loss: 0.5669941902160645\n",
            "Epoch 19, Batch 89, test Loss: 0.5932466983795166\n",
            "Epoch 19, Batch 90, test Loss: 0.44668906927108765\n",
            "Epoch 19, Batch 91, test Loss: 0.6449209451675415\n",
            "Epoch 19, Batch 92, test Loss: 0.5146562457084656\n",
            "Epoch 19, Batch 93, test Loss: 0.30600404739379883\n",
            "Epoch 19, Batch 94, test Loss: 0.5398423075675964\n",
            "Epoch 19, Batch 95, test Loss: 0.37692490220069885\n",
            "Epoch 19, Batch 96, test Loss: 0.41758275032043457\n",
            "Epoch 19, Batch 97, test Loss: 0.5467728972434998\n",
            "Epoch 19, Batch 98, test Loss: 0.4781782925128937\n",
            "Epoch 19, Batch 99, test Loss: 0.43317529559135437\n",
            "Epoch 19, Batch 100, test Loss: 0.5243502855300903\n",
            "Epoch 19, Batch 101, test Loss: 0.5695980191230774\n",
            "Epoch 19, Batch 102, test Loss: 0.6498318910598755\n",
            "Epoch 19, Batch 103, test Loss: 0.6635675430297852\n",
            "Epoch 19, Batch 104, test Loss: 0.3071267604827881\n",
            "Epoch 19, Batch 105, test Loss: 0.5008023977279663\n",
            "Epoch 19, Batch 106, test Loss: 0.5345351696014404\n",
            "Epoch 19, Batch 107, test Loss: 0.584753155708313\n",
            "Epoch 19, Batch 108, test Loss: 0.43230804800987244\n",
            "Epoch 19, Batch 109, test Loss: 0.38119998574256897\n",
            "Epoch 19, Batch 110, test Loss: 0.34865280985832214\n",
            "Epoch 19, Batch 111, test Loss: 0.52297443151474\n",
            "Epoch 19, Batch 112, test Loss: 0.33154284954071045\n",
            "Epoch 19, Batch 113, test Loss: 0.6681975722312927\n",
            "Epoch 19, Batch 114, test Loss: 0.44527456164360046\n",
            "Epoch 19, Batch 115, test Loss: 0.35345596075057983\n",
            "Epoch 19, Batch 116, test Loss: 0.2819760739803314\n",
            "Epoch 19, Batch 117, test Loss: 0.570826530456543\n",
            "Epoch 19, Batch 118, test Loss: 0.3448925018310547\n",
            "Epoch 19, Batch 119, test Loss: 0.6426624059677124\n",
            "Epoch 19, Batch 120, test Loss: 0.4689147472381592\n",
            "Epoch 19, Batch 121, test Loss: 0.6288843154907227\n",
            "Epoch 19, Batch 122, test Loss: 0.6052573919296265\n",
            "Epoch 19, Batch 123, test Loss: 0.3089979887008667\n",
            "Epoch 19, Batch 124, test Loss: 0.3210611641407013\n",
            "Epoch 19, Batch 125, test Loss: 0.39271411299705505\n",
            "Epoch 19, Batch 126, test Loss: 0.4756897985935211\n",
            "Epoch 19, Batch 127, test Loss: 0.3884999752044678\n",
            "Epoch 19, Batch 128, test Loss: 0.38568437099456787\n",
            "Epoch 19, Batch 129, test Loss: 0.2889431416988373\n",
            "Epoch 19, Batch 130, test Loss: 0.4278556704521179\n",
            "Epoch 19, Batch 131, test Loss: 0.4524006247520447\n",
            "Epoch 19, Batch 132, test Loss: 0.3519493043422699\n",
            "Epoch 19, Batch 133, test Loss: 0.6160587072372437\n",
            "Epoch 19, Batch 134, test Loss: 0.3539881110191345\n",
            "Epoch 19, Batch 135, test Loss: 0.38709890842437744\n",
            "Epoch 19, Batch 136, test Loss: 0.4738638699054718\n",
            "Epoch 19, Batch 137, test Loss: 0.31889399886131287\n",
            "Epoch 19, Batch 138, test Loss: 0.423245370388031\n",
            "Epoch 19, Batch 139, test Loss: 0.7195898294448853\n",
            "Epoch 19, Batch 140, test Loss: 0.5456268191337585\n",
            "Epoch 19, Batch 141, test Loss: 0.25765886902809143\n",
            "Epoch 19, Batch 142, test Loss: 0.5343118906021118\n",
            "Epoch 19, Batch 143, test Loss: 0.4530153274536133\n",
            "Epoch 19, Batch 144, test Loss: 0.39786824584007263\n",
            "Epoch 19, Batch 145, test Loss: 0.6477787494659424\n",
            "Epoch 19, Batch 146, test Loss: 0.4858599305152893\n",
            "Epoch 19, Batch 147, test Loss: 0.5246365070343018\n",
            "Epoch 19, Batch 148, test Loss: 0.34887850284576416\n",
            "Epoch 19, Batch 149, test Loss: 0.44214609265327454\n",
            "Epoch 19, Batch 150, test Loss: 0.49827706813812256\n",
            "Epoch 19, Batch 151, test Loss: 0.36359190940856934\n",
            "Epoch 19, Batch 152, test Loss: 0.3560889661312103\n",
            "Epoch 19, Batch 153, test Loss: 0.6384111642837524\n",
            "Epoch 19, Batch 154, test Loss: 0.41884690523147583\n",
            "Epoch 19, Batch 155, test Loss: 0.47707030177116394\n",
            "Epoch 19, Batch 156, test Loss: 0.735497772693634\n",
            "Epoch 19, Accuracy of test set: 0.836\n",
            "Epoch 20/25:\n",
            "Train Loss: 0.0066, Train Accuracy: 0.85\n",
            "Test Loss: 0.0073, Test Accuracy: 0.84\n",
            "Accuracy of train set: 0.8541833333333333\n",
            "Epoch 20, Batch 0, test Loss: 0.3682475984096527\n",
            "Epoch 20, Batch 1, test Loss: 0.6705225110054016\n",
            "Epoch 20, Batch 2, test Loss: 0.3763994574546814\n",
            "Epoch 20, Batch 3, test Loss: 0.41238224506378174\n",
            "Epoch 20, Batch 4, test Loss: 0.5980491638183594\n",
            "Epoch 20, Batch 5, test Loss: 0.5391261577606201\n",
            "Epoch 20, Batch 6, test Loss: 0.5005277991294861\n",
            "Epoch 20, Batch 7, test Loss: 0.5113133788108826\n",
            "Epoch 20, Batch 8, test Loss: 0.42508840560913086\n",
            "Epoch 20, Batch 9, test Loss: 0.5288728475570679\n",
            "Epoch 20, Batch 10, test Loss: 0.6215558052062988\n",
            "Epoch 20, Batch 11, test Loss: 0.5457208752632141\n",
            "Epoch 20, Batch 12, test Loss: 0.3115847706794739\n",
            "Epoch 20, Batch 13, test Loss: 0.467266708612442\n",
            "Epoch 20, Batch 14, test Loss: 0.49661165475845337\n",
            "Epoch 20, Batch 15, test Loss: 0.5013575553894043\n",
            "Epoch 20, Batch 16, test Loss: 0.4505036771297455\n",
            "Epoch 20, Batch 17, test Loss: 0.6038232445716858\n",
            "Epoch 20, Batch 18, test Loss: 0.5457627773284912\n",
            "Epoch 20, Batch 19, test Loss: 0.29852938652038574\n",
            "Epoch 20, Batch 20, test Loss: 0.3717029094696045\n",
            "Epoch 20, Batch 21, test Loss: 0.4146842956542969\n",
            "Epoch 20, Batch 22, test Loss: 0.37488579750061035\n",
            "Epoch 20, Batch 23, test Loss: 0.47885408997535706\n",
            "Epoch 20, Batch 24, test Loss: 0.3987935185432434\n",
            "Epoch 20, Batch 25, test Loss: 0.4703769087791443\n",
            "Epoch 20, Batch 26, test Loss: 0.42820048332214355\n",
            "Epoch 20, Batch 27, test Loss: 0.38085904717445374\n",
            "Epoch 20, Batch 28, test Loss: 0.2591024935245514\n",
            "Epoch 20, Batch 29, test Loss: 0.6040089726448059\n",
            "Epoch 20, Batch 30, test Loss: 0.3913349211215973\n",
            "Epoch 20, Batch 31, test Loss: 0.5352811813354492\n",
            "Epoch 20, Batch 32, test Loss: 0.5221643447875977\n",
            "Epoch 20, Batch 33, test Loss: 0.41095390915870667\n",
            "Epoch 20, Batch 34, test Loss: 0.5902783870697021\n",
            "Epoch 20, Batch 35, test Loss: 0.3174525499343872\n",
            "Epoch 20, Batch 36, test Loss: 0.2933788001537323\n",
            "Epoch 20, Batch 37, test Loss: 0.39943134784698486\n",
            "Epoch 20, Batch 38, test Loss: 0.6116029620170593\n",
            "Epoch 20, Batch 39, test Loss: 0.5259020924568176\n",
            "Epoch 20, Batch 40, test Loss: 0.38112756609916687\n",
            "Epoch 20, Batch 41, test Loss: 0.6247220635414124\n",
            "Epoch 20, Batch 42, test Loss: 0.440652072429657\n",
            "Epoch 20, Batch 43, test Loss: 0.5610525012016296\n",
            "Epoch 20, Batch 44, test Loss: 0.428691565990448\n",
            "Epoch 20, Batch 45, test Loss: 0.31488022208213806\n",
            "Epoch 20, Batch 46, test Loss: 0.5657615661621094\n",
            "Epoch 20, Batch 47, test Loss: 0.3895440995693207\n",
            "Epoch 20, Batch 48, test Loss: 0.5427463054656982\n",
            "Epoch 20, Batch 49, test Loss: 0.45841556787490845\n",
            "Epoch 20, Batch 50, test Loss: 0.576707124710083\n",
            "Epoch 20, Batch 51, test Loss: 0.4845828115940094\n",
            "Epoch 20, Batch 52, test Loss: 0.4091077744960785\n",
            "Epoch 20, Batch 53, test Loss: 0.3648938536643982\n",
            "Epoch 20, Batch 54, test Loss: 0.4180002212524414\n",
            "Epoch 20, Batch 55, test Loss: 0.4430275559425354\n",
            "Epoch 20, Batch 56, test Loss: 0.3356159031391144\n",
            "Epoch 20, Batch 57, test Loss: 0.7446902990341187\n",
            "Epoch 20, Batch 58, test Loss: 0.2883850038051605\n",
            "Epoch 20, Batch 59, test Loss: 0.3559131622314453\n",
            "Epoch 20, Batch 60, test Loss: 0.3802626132965088\n",
            "Epoch 20, Batch 61, test Loss: 0.40431538224220276\n",
            "Epoch 20, Batch 62, test Loss: 0.5727353096008301\n",
            "Epoch 20, Batch 63, test Loss: 0.4676564633846283\n",
            "Epoch 20, Batch 64, test Loss: 0.4435354769229889\n",
            "Epoch 20, Batch 65, test Loss: 0.5196585655212402\n",
            "Epoch 20, Batch 66, test Loss: 0.4177830219268799\n",
            "Epoch 20, Batch 67, test Loss: 0.4075140357017517\n",
            "Epoch 20, Batch 68, test Loss: 0.47893574833869934\n",
            "Epoch 20, Batch 69, test Loss: 0.38528409600257874\n",
            "Epoch 20, Batch 70, test Loss: 0.4244791865348816\n",
            "Epoch 20, Batch 71, test Loss: 0.4419076442718506\n",
            "Epoch 20, Batch 72, test Loss: 0.45409438014030457\n",
            "Epoch 20, Batch 73, test Loss: 0.5092606544494629\n",
            "Epoch 20, Batch 74, test Loss: 0.4152643382549286\n",
            "Epoch 20, Batch 75, test Loss: 0.3600533604621887\n",
            "Epoch 20, Batch 76, test Loss: 0.3328818678855896\n",
            "Epoch 20, Batch 77, test Loss: 0.5650022625923157\n",
            "Epoch 20, Batch 78, test Loss: 0.6053081750869751\n",
            "Epoch 20, Batch 79, test Loss: 0.4774029850959778\n",
            "Epoch 20, Batch 80, test Loss: 0.6447522044181824\n",
            "Epoch 20, Batch 81, test Loss: 0.34268292784690857\n",
            "Epoch 20, Batch 82, test Loss: 0.5042443871498108\n",
            "Epoch 20, Batch 83, test Loss: 0.49497169256210327\n",
            "Epoch 20, Batch 84, test Loss: 0.47302958369255066\n",
            "Epoch 20, Batch 85, test Loss: 0.5509473085403442\n",
            "Epoch 20, Batch 86, test Loss: 0.42731085419654846\n",
            "Epoch 20, Batch 87, test Loss: 0.29178979992866516\n",
            "Epoch 20, Batch 88, test Loss: 0.49292469024658203\n",
            "Epoch 20, Batch 89, test Loss: 0.3917821943759918\n",
            "Epoch 20, Batch 90, test Loss: 0.3690752387046814\n",
            "Epoch 20, Batch 91, test Loss: 0.35252806544303894\n",
            "Epoch 20, Batch 92, test Loss: 0.39985886216163635\n",
            "Epoch 20, Batch 93, test Loss: 0.6365966200828552\n",
            "Epoch 20, Batch 94, test Loss: 0.8810168504714966\n",
            "Epoch 20, Batch 95, test Loss: 0.5497456789016724\n",
            "Epoch 20, Batch 96, test Loss: 0.6792483925819397\n",
            "Epoch 20, Batch 97, test Loss: 0.5854478478431702\n",
            "Epoch 20, Batch 98, test Loss: 0.5754796266555786\n",
            "Epoch 20, Batch 99, test Loss: 0.6569499969482422\n",
            "Epoch 20, Batch 100, test Loss: 0.46585237979888916\n",
            "Epoch 20, Batch 101, test Loss: 0.30898383259773254\n",
            "Epoch 20, Batch 102, test Loss: 0.6515673398971558\n",
            "Epoch 20, Batch 103, test Loss: 0.4049535095691681\n",
            "Epoch 20, Batch 104, test Loss: 0.46491682529449463\n",
            "Epoch 20, Batch 105, test Loss: 0.48817339539527893\n",
            "Epoch 20, Batch 106, test Loss: 0.25252383947372437\n",
            "Epoch 20, Batch 107, test Loss: 0.3814060688018799\n",
            "Epoch 20, Batch 108, test Loss: 0.553005576133728\n",
            "Epoch 20, Batch 109, test Loss: 0.3584277033805847\n",
            "Epoch 20, Batch 110, test Loss: 0.3173515200614929\n",
            "Epoch 20, Batch 111, test Loss: 0.36853113770484924\n",
            "Epoch 20, Batch 112, test Loss: 0.550399124622345\n",
            "Epoch 20, Batch 113, test Loss: 0.4290028214454651\n",
            "Epoch 20, Batch 114, test Loss: 0.5760321021080017\n",
            "Epoch 20, Batch 115, test Loss: 0.6088844537734985\n",
            "Epoch 20, Batch 116, test Loss: 0.49872928857803345\n",
            "Epoch 20, Batch 117, test Loss: 0.4237125515937805\n",
            "Epoch 20, Batch 118, test Loss: 0.2221190333366394\n",
            "Epoch 20, Batch 119, test Loss: 0.3627704083919525\n",
            "Epoch 20, Batch 120, test Loss: 0.2532457113265991\n",
            "Epoch 20, Batch 121, test Loss: 0.5172440409660339\n",
            "Epoch 20, Batch 122, test Loss: 0.46378040313720703\n",
            "Epoch 20, Batch 123, test Loss: 0.30413785576820374\n",
            "Epoch 20, Batch 124, test Loss: 0.3150807321071625\n",
            "Epoch 20, Batch 125, test Loss: 0.3961256742477417\n",
            "Epoch 20, Batch 126, test Loss: 1.017087459564209\n",
            "Epoch 20, Batch 127, test Loss: 0.2534756660461426\n",
            "Epoch 20, Batch 128, test Loss: 0.24957478046417236\n",
            "Epoch 20, Batch 129, test Loss: 0.58941251039505\n",
            "Epoch 20, Batch 130, test Loss: 0.42361995577812195\n",
            "Epoch 20, Batch 131, test Loss: 0.4529218077659607\n",
            "Epoch 20, Batch 132, test Loss: 0.5507675409317017\n",
            "Epoch 20, Batch 133, test Loss: 0.4626009166240692\n",
            "Epoch 20, Batch 134, test Loss: 0.5964478850364685\n",
            "Epoch 20, Batch 135, test Loss: 0.609830915927887\n",
            "Epoch 20, Batch 136, test Loss: 0.56626957654953\n",
            "Epoch 20, Batch 137, test Loss: 0.31931382417678833\n",
            "Epoch 20, Batch 138, test Loss: 0.443559467792511\n",
            "Epoch 20, Batch 139, test Loss: 0.5155893564224243\n",
            "Epoch 20, Batch 140, test Loss: 0.43035653233528137\n",
            "Epoch 20, Batch 141, test Loss: 0.39262068271636963\n",
            "Epoch 20, Batch 142, test Loss: 0.3402549624443054\n",
            "Epoch 20, Batch 143, test Loss: 0.33842164278030396\n",
            "Epoch 20, Batch 144, test Loss: 0.5186858773231506\n",
            "Epoch 20, Batch 145, test Loss: 0.23714673519134521\n",
            "Epoch 20, Batch 146, test Loss: 0.3117208480834961\n",
            "Epoch 20, Batch 147, test Loss: 0.45560961961746216\n",
            "Epoch 20, Batch 148, test Loss: 0.46898186206817627\n",
            "Epoch 20, Batch 149, test Loss: 0.3364790976047516\n",
            "Epoch 20, Batch 150, test Loss: 0.4548795223236084\n",
            "Epoch 20, Batch 151, test Loss: 0.3788234293460846\n",
            "Epoch 20, Batch 152, test Loss: 0.38775140047073364\n",
            "Epoch 20, Batch 153, test Loss: 0.49258726835250854\n",
            "Epoch 20, Batch 154, test Loss: 0.3574804365634918\n",
            "Epoch 20, Batch 155, test Loss: 0.4207391142845154\n",
            "Epoch 20, Batch 156, test Loss: 0.7312242984771729\n",
            "Epoch 20, Accuracy of test set: 0.8377\n",
            "Epoch 21/25:\n",
            "Train Loss: 0.0065, Train Accuracy: 0.85\n",
            "Test Loss: 0.0072, Test Accuracy: 0.84\n",
            "Accuracy of train set: 0.8568833333333333\n",
            "Epoch 21, Batch 0, test Loss: 0.36767125129699707\n",
            "Epoch 21, Batch 1, test Loss: 0.514094352722168\n",
            "Epoch 21, Batch 2, test Loss: 0.4886435568332672\n",
            "Epoch 21, Batch 3, test Loss: 0.44590845704078674\n",
            "Epoch 21, Batch 4, test Loss: 0.38820382952690125\n",
            "Epoch 21, Batch 5, test Loss: 0.5066987872123718\n",
            "Epoch 21, Batch 6, test Loss: 0.3937316834926605\n",
            "Epoch 21, Batch 7, test Loss: 0.346891313791275\n",
            "Epoch 21, Batch 8, test Loss: 0.3401496708393097\n",
            "Epoch 21, Batch 9, test Loss: 0.5871380567550659\n",
            "Epoch 21, Batch 10, test Loss: 0.4585244953632355\n",
            "Epoch 21, Batch 11, test Loss: 0.4847348630428314\n",
            "Epoch 21, Batch 12, test Loss: 0.702302873134613\n",
            "Epoch 21, Batch 13, test Loss: 0.45252370834350586\n",
            "Epoch 21, Batch 14, test Loss: 0.5146476030349731\n",
            "Epoch 21, Batch 15, test Loss: 0.40029630064964294\n",
            "Epoch 21, Batch 16, test Loss: 0.5011635422706604\n",
            "Epoch 21, Batch 17, test Loss: 0.5398159027099609\n",
            "Epoch 21, Batch 18, test Loss: 0.5451580286026001\n",
            "Epoch 21, Batch 19, test Loss: 0.5544390678405762\n",
            "Epoch 21, Batch 20, test Loss: 0.5089478492736816\n",
            "Epoch 21, Batch 21, test Loss: 0.4618287980556488\n",
            "Epoch 21, Batch 22, test Loss: 0.5044859051704407\n",
            "Epoch 21, Batch 23, test Loss: 0.7042252421379089\n",
            "Epoch 21, Batch 24, test Loss: 0.5349150896072388\n",
            "Epoch 21, Batch 25, test Loss: 0.3498770594596863\n",
            "Epoch 21, Batch 26, test Loss: 0.37063068151474\n",
            "Epoch 21, Batch 27, test Loss: 0.32980045676231384\n",
            "Epoch 21, Batch 28, test Loss: 0.4446532726287842\n",
            "Epoch 21, Batch 29, test Loss: 0.49933719635009766\n",
            "Epoch 21, Batch 30, test Loss: 0.4712890684604645\n",
            "Epoch 21, Batch 31, test Loss: 0.5491769909858704\n",
            "Epoch 21, Batch 32, test Loss: 0.45723578333854675\n",
            "Epoch 21, Batch 33, test Loss: 0.3633368909358978\n",
            "Epoch 21, Batch 34, test Loss: 0.5275527834892273\n",
            "Epoch 21, Batch 35, test Loss: 0.33886754512786865\n",
            "Epoch 21, Batch 36, test Loss: 0.48543593287467957\n",
            "Epoch 21, Batch 37, test Loss: 0.54295814037323\n",
            "Epoch 21, Batch 38, test Loss: 0.40080660581588745\n",
            "Epoch 21, Batch 39, test Loss: 0.7230153679847717\n",
            "Epoch 21, Batch 40, test Loss: 0.517061710357666\n",
            "Epoch 21, Batch 41, test Loss: 0.2170901596546173\n",
            "Epoch 21, Batch 42, test Loss: 0.46947863698005676\n",
            "Epoch 21, Batch 43, test Loss: 0.6459037065505981\n",
            "Epoch 21, Batch 44, test Loss: 0.39594483375549316\n",
            "Epoch 21, Batch 45, test Loss: 0.6709848046302795\n",
            "Epoch 21, Batch 46, test Loss: 0.4791611433029175\n",
            "Epoch 21, Batch 47, test Loss: 0.5128504037857056\n",
            "Epoch 21, Batch 48, test Loss: 0.4278787076473236\n",
            "Epoch 21, Batch 49, test Loss: 0.4590495824813843\n",
            "Epoch 21, Batch 50, test Loss: 0.37900301814079285\n",
            "Epoch 21, Batch 51, test Loss: 0.41076600551605225\n",
            "Epoch 21, Batch 52, test Loss: 0.6597882509231567\n",
            "Epoch 21, Batch 53, test Loss: 0.4235510230064392\n",
            "Epoch 21, Batch 54, test Loss: 0.3613906502723694\n",
            "Epoch 21, Batch 55, test Loss: 0.4420502781867981\n",
            "Epoch 21, Batch 56, test Loss: 0.6107869744300842\n",
            "Epoch 21, Batch 57, test Loss: 0.46401914954185486\n",
            "Epoch 21, Batch 58, test Loss: 0.44613486528396606\n",
            "Epoch 21, Batch 59, test Loss: 0.39880916476249695\n",
            "Epoch 21, Batch 60, test Loss: 0.6594811081886292\n",
            "Epoch 21, Batch 61, test Loss: 0.34545010328292847\n",
            "Epoch 21, Batch 62, test Loss: 0.4918711483478546\n",
            "Epoch 21, Batch 63, test Loss: 0.48727306723594666\n",
            "Epoch 21, Batch 64, test Loss: 0.35458093881607056\n",
            "Epoch 21, Batch 65, test Loss: 0.4414516091346741\n",
            "Epoch 21, Batch 66, test Loss: 0.3214610815048218\n",
            "Epoch 21, Batch 67, test Loss: 0.7502424716949463\n",
            "Epoch 21, Batch 68, test Loss: 0.3908752501010895\n",
            "Epoch 21, Batch 69, test Loss: 0.46892401576042175\n",
            "Epoch 21, Batch 70, test Loss: 0.4811314046382904\n",
            "Epoch 21, Batch 71, test Loss: 0.23308531939983368\n",
            "Epoch 21, Batch 72, test Loss: 0.45990025997161865\n",
            "Epoch 21, Batch 73, test Loss: 0.5706572532653809\n",
            "Epoch 21, Batch 74, test Loss: 0.46269580721855164\n",
            "Epoch 21, Batch 75, test Loss: 0.37451115250587463\n",
            "Epoch 21, Batch 76, test Loss: 0.5553327798843384\n",
            "Epoch 21, Batch 77, test Loss: 0.3583308160305023\n",
            "Epoch 21, Batch 78, test Loss: 0.6138777732849121\n",
            "Epoch 21, Batch 79, test Loss: 0.3783290386199951\n",
            "Epoch 21, Batch 80, test Loss: 0.20906974375247955\n",
            "Epoch 21, Batch 81, test Loss: 0.36414334177970886\n",
            "Epoch 21, Batch 82, test Loss: 0.3376401960849762\n",
            "Epoch 21, Batch 83, test Loss: 0.5415902733802795\n",
            "Epoch 21, Batch 84, test Loss: 0.46022412180900574\n",
            "Epoch 21, Batch 85, test Loss: 0.22104832530021667\n",
            "Epoch 21, Batch 86, test Loss: 0.5186141729354858\n",
            "Epoch 21, Batch 87, test Loss: 0.5268089771270752\n",
            "Epoch 21, Batch 88, test Loss: 0.27268487215042114\n",
            "Epoch 21, Batch 89, test Loss: 0.4722595810890198\n",
            "Epoch 21, Batch 90, test Loss: 0.32202693819999695\n",
            "Epoch 21, Batch 91, test Loss: 0.4724426865577698\n",
            "Epoch 21, Batch 92, test Loss: 0.43009474873542786\n",
            "Epoch 21, Batch 93, test Loss: 0.4862566590309143\n",
            "Epoch 21, Batch 94, test Loss: 0.9453356862068176\n",
            "Epoch 21, Batch 95, test Loss: 0.8475011587142944\n",
            "Epoch 21, Batch 96, test Loss: 0.5185564160346985\n",
            "Epoch 21, Batch 97, test Loss: 0.36003851890563965\n",
            "Epoch 21, Batch 98, test Loss: 0.45815879106521606\n",
            "Epoch 21, Batch 99, test Loss: 0.4804662764072418\n",
            "Epoch 21, Batch 100, test Loss: 0.4489326477050781\n",
            "Epoch 21, Batch 101, test Loss: 0.5777877569198608\n",
            "Epoch 21, Batch 102, test Loss: 0.47891849279403687\n",
            "Epoch 21, Batch 103, test Loss: 0.4332732558250427\n",
            "Epoch 21, Batch 104, test Loss: 0.541597306728363\n",
            "Epoch 21, Batch 105, test Loss: 0.3592655062675476\n",
            "Epoch 21, Batch 106, test Loss: 0.471246600151062\n",
            "Epoch 21, Batch 107, test Loss: 0.49047109484672546\n",
            "Epoch 21, Batch 108, test Loss: 0.49825313687324524\n",
            "Epoch 21, Batch 109, test Loss: 0.4221118092536926\n",
            "Epoch 21, Batch 110, test Loss: 0.33209139108657837\n",
            "Epoch 21, Batch 111, test Loss: 0.3412098288536072\n",
            "Epoch 21, Batch 112, test Loss: 0.5096505880355835\n",
            "Epoch 21, Batch 113, test Loss: 0.39216145873069763\n",
            "Epoch 21, Batch 114, test Loss: 0.38501596450805664\n",
            "Epoch 21, Batch 115, test Loss: 0.5392014980316162\n",
            "Epoch 21, Batch 116, test Loss: 0.4296291172504425\n",
            "Epoch 21, Batch 117, test Loss: 0.4940025210380554\n",
            "Epoch 21, Batch 118, test Loss: 0.5610700845718384\n",
            "Epoch 21, Batch 119, test Loss: 0.29537490010261536\n",
            "Epoch 21, Batch 120, test Loss: 0.4748770296573639\n",
            "Epoch 21, Batch 121, test Loss: 0.31358540058135986\n",
            "Epoch 21, Batch 122, test Loss: 0.5006488561630249\n",
            "Epoch 21, Batch 123, test Loss: 0.32695773243904114\n",
            "Epoch 21, Batch 124, test Loss: 0.6235635280609131\n",
            "Epoch 21, Batch 125, test Loss: 0.33618810772895813\n",
            "Epoch 21, Batch 126, test Loss: 0.4783629775047302\n",
            "Epoch 21, Batch 127, test Loss: 0.6067171096801758\n",
            "Epoch 21, Batch 128, test Loss: 0.2718435823917389\n",
            "Epoch 21, Batch 129, test Loss: 0.3650166988372803\n",
            "Epoch 21, Batch 130, test Loss: 0.47629231214523315\n",
            "Epoch 21, Batch 131, test Loss: 0.3759588301181793\n",
            "Epoch 21, Batch 132, test Loss: 0.4994660019874573\n",
            "Epoch 21, Batch 133, test Loss: 0.40390294790267944\n",
            "Epoch 21, Batch 134, test Loss: 0.38608407974243164\n",
            "Epoch 21, Batch 135, test Loss: 0.3837079107761383\n",
            "Epoch 21, Batch 136, test Loss: 0.4172721207141876\n",
            "Epoch 21, Batch 137, test Loss: 0.37443169951438904\n",
            "Epoch 21, Batch 138, test Loss: 0.3767620027065277\n",
            "Epoch 21, Batch 139, test Loss: 0.377496600151062\n",
            "Epoch 21, Batch 140, test Loss: 0.25720080733299255\n",
            "Epoch 21, Batch 141, test Loss: 0.4223199486732483\n",
            "Epoch 21, Batch 142, test Loss: 0.5878312587738037\n",
            "Epoch 21, Batch 143, test Loss: 0.6041940450668335\n",
            "Epoch 21, Batch 144, test Loss: 0.42340198159217834\n",
            "Epoch 21, Batch 145, test Loss: 0.6496331095695496\n",
            "Epoch 21, Batch 146, test Loss: 0.46146804094314575\n",
            "Epoch 21, Batch 147, test Loss: 0.31831857562065125\n",
            "Epoch 21, Batch 148, test Loss: 0.3677164912223816\n",
            "Epoch 21, Batch 149, test Loss: 0.35352712869644165\n",
            "Epoch 21, Batch 150, test Loss: 0.5284926891326904\n",
            "Epoch 21, Batch 151, test Loss: 0.3176574409008026\n",
            "Epoch 21, Batch 152, test Loss: 0.3315097391605377\n",
            "Epoch 21, Batch 153, test Loss: 0.4429877996444702\n",
            "Epoch 21, Batch 154, test Loss: 0.44090646505355835\n",
            "Epoch 21, Batch 155, test Loss: 0.6009657382965088\n",
            "Epoch 21, Batch 156, test Loss: 0.34034398198127747\n",
            "Epoch 21, Accuracy of test set: 0.8338\n",
            "Epoch 22/25:\n",
            "Train Loss: 0.0064, Train Accuracy: 0.86\n",
            "Test Loss: 0.0072, Test Accuracy: 0.83\n",
            "Accuracy of train set: 0.8604\n",
            "Epoch 22, Batch 0, test Loss: 0.3136396110057831\n",
            "Epoch 22, Batch 1, test Loss: 0.3312157988548279\n",
            "Epoch 22, Batch 2, test Loss: 0.4733709990978241\n",
            "Epoch 22, Batch 3, test Loss: 0.4289439916610718\n",
            "Epoch 22, Batch 4, test Loss: 0.29398709535598755\n",
            "Epoch 22, Batch 5, test Loss: 0.5176214575767517\n",
            "Epoch 22, Batch 6, test Loss: 0.37498801946640015\n",
            "Epoch 22, Batch 7, test Loss: 0.3533689081668854\n",
            "Epoch 22, Batch 8, test Loss: 0.6127688884735107\n",
            "Epoch 22, Batch 9, test Loss: 0.38501906394958496\n",
            "Epoch 22, Batch 10, test Loss: 0.418396919965744\n",
            "Epoch 22, Batch 11, test Loss: 0.3016001582145691\n",
            "Epoch 22, Batch 12, test Loss: 0.2379690259695053\n",
            "Epoch 22, Batch 13, test Loss: 0.45880749821662903\n",
            "Epoch 22, Batch 14, test Loss: 0.3562897741794586\n",
            "Epoch 22, Batch 15, test Loss: 0.24151918292045593\n",
            "Epoch 22, Batch 16, test Loss: 0.2640973925590515\n",
            "Epoch 22, Batch 17, test Loss: 0.4399089515209198\n",
            "Epoch 22, Batch 18, test Loss: 0.40261757373809814\n",
            "Epoch 22, Batch 19, test Loss: 0.5441862344741821\n",
            "Epoch 22, Batch 20, test Loss: 0.6399039030075073\n",
            "Epoch 22, Batch 21, test Loss: 0.5959159135818481\n",
            "Epoch 22, Batch 22, test Loss: 0.5094318389892578\n",
            "Epoch 22, Batch 23, test Loss: 0.4472544193267822\n",
            "Epoch 22, Batch 24, test Loss: 0.3122500479221344\n",
            "Epoch 22, Batch 25, test Loss: 0.40149474143981934\n",
            "Epoch 22, Batch 26, test Loss: 0.48623064160346985\n",
            "Epoch 22, Batch 27, test Loss: 0.5176223516464233\n",
            "Epoch 22, Batch 28, test Loss: 0.3082447350025177\n",
            "Epoch 22, Batch 29, test Loss: 0.48324140906333923\n",
            "Epoch 22, Batch 30, test Loss: 0.39188694953918457\n",
            "Epoch 22, Batch 31, test Loss: 0.5231793522834778\n",
            "Epoch 22, Batch 32, test Loss: 0.5329022407531738\n",
            "Epoch 22, Batch 33, test Loss: 0.515828013420105\n",
            "Epoch 22, Batch 34, test Loss: 0.38103675842285156\n",
            "Epoch 22, Batch 35, test Loss: 0.41755974292755127\n",
            "Epoch 22, Batch 36, test Loss: 0.5384584665298462\n",
            "Epoch 22, Batch 37, test Loss: 0.36119937896728516\n",
            "Epoch 22, Batch 38, test Loss: 0.36936673521995544\n",
            "Epoch 22, Batch 39, test Loss: 0.44197311997413635\n",
            "Epoch 22, Batch 40, test Loss: 0.3243590295314789\n",
            "Epoch 22, Batch 41, test Loss: 0.2630873918533325\n",
            "Epoch 22, Batch 42, test Loss: 0.512782871723175\n",
            "Epoch 22, Batch 43, test Loss: 0.34385624527931213\n",
            "Epoch 22, Batch 44, test Loss: 0.3509167432785034\n",
            "Epoch 22, Batch 45, test Loss: 0.45901596546173096\n",
            "Epoch 22, Batch 46, test Loss: 0.4122198224067688\n",
            "Epoch 22, Batch 47, test Loss: 0.5428714156150818\n",
            "Epoch 22, Batch 48, test Loss: 0.47039130330085754\n",
            "Epoch 22, Batch 49, test Loss: 0.41092097759246826\n",
            "Epoch 22, Batch 50, test Loss: 0.5180616974830627\n",
            "Epoch 22, Batch 51, test Loss: 0.441425621509552\n",
            "Epoch 22, Batch 52, test Loss: 0.5150538682937622\n",
            "Epoch 22, Batch 53, test Loss: 0.6332671046257019\n",
            "Epoch 22, Batch 54, test Loss: 0.39018821716308594\n",
            "Epoch 22, Batch 55, test Loss: 0.3311067223548889\n",
            "Epoch 22, Batch 56, test Loss: 0.57662433385849\n",
            "Epoch 22, Batch 57, test Loss: 0.4426022469997406\n",
            "Epoch 22, Batch 58, test Loss: 0.48895493149757385\n",
            "Epoch 22, Batch 59, test Loss: 0.3702412247657776\n",
            "Epoch 22, Batch 60, test Loss: 0.555182695388794\n",
            "Epoch 22, Batch 61, test Loss: 0.5103500485420227\n",
            "Epoch 22, Batch 62, test Loss: 0.3250395655632019\n",
            "Epoch 22, Batch 63, test Loss: 0.4005959630012512\n",
            "Epoch 22, Batch 64, test Loss: 0.3503209948539734\n",
            "Epoch 22, Batch 65, test Loss: 0.21011465787887573\n",
            "Epoch 22, Batch 66, test Loss: 0.3805108070373535\n",
            "Epoch 22, Batch 67, test Loss: 0.5751820206642151\n",
            "Epoch 22, Batch 68, test Loss: 0.40907347202301025\n",
            "Epoch 22, Batch 69, test Loss: 0.49024516344070435\n",
            "Epoch 22, Batch 70, test Loss: 0.5061737895011902\n",
            "Epoch 22, Batch 71, test Loss: 0.47399309277534485\n",
            "Epoch 22, Batch 72, test Loss: 0.40117961168289185\n",
            "Epoch 22, Batch 73, test Loss: 0.33541205525398254\n",
            "Epoch 22, Batch 74, test Loss: 0.42146560549736023\n",
            "Epoch 22, Batch 75, test Loss: 0.33985796570777893\n",
            "Epoch 22, Batch 76, test Loss: 0.34311214089393616\n",
            "Epoch 22, Batch 77, test Loss: 0.5323373079299927\n",
            "Epoch 22, Batch 78, test Loss: 0.36564382910728455\n",
            "Epoch 22, Batch 79, test Loss: 0.40668562054634094\n",
            "Epoch 22, Batch 80, test Loss: 0.24098020792007446\n",
            "Epoch 22, Batch 81, test Loss: 0.48794835805892944\n",
            "Epoch 22, Batch 82, test Loss: 0.47317999601364136\n",
            "Epoch 22, Batch 83, test Loss: 0.5082470178604126\n",
            "Epoch 22, Batch 84, test Loss: 0.3990635275840759\n",
            "Epoch 22, Batch 85, test Loss: 0.3674579858779907\n",
            "Epoch 22, Batch 86, test Loss: 0.2744610905647278\n",
            "Epoch 22, Batch 87, test Loss: 0.29951295256614685\n",
            "Epoch 22, Batch 88, test Loss: 0.5260542631149292\n",
            "Epoch 22, Batch 89, test Loss: 0.5436690449714661\n",
            "Epoch 22, Batch 90, test Loss: 0.4594736099243164\n",
            "Epoch 22, Batch 91, test Loss: 0.47762709856033325\n",
            "Epoch 22, Batch 92, test Loss: 0.6379635334014893\n",
            "Epoch 22, Batch 93, test Loss: 0.6165142059326172\n",
            "Epoch 22, Batch 94, test Loss: 0.4914350211620331\n",
            "Epoch 22, Batch 95, test Loss: 0.33893832564353943\n",
            "Epoch 22, Batch 96, test Loss: 0.491960346698761\n",
            "Epoch 22, Batch 97, test Loss: 0.3833128809928894\n",
            "Epoch 22, Batch 98, test Loss: 0.3734413981437683\n",
            "Epoch 22, Batch 99, test Loss: 0.5235406756401062\n",
            "Epoch 22, Batch 100, test Loss: 0.47110748291015625\n",
            "Epoch 22, Batch 101, test Loss: 0.4169389009475708\n",
            "Epoch 22, Batch 102, test Loss: 0.5562006831169128\n",
            "Epoch 22, Batch 103, test Loss: 0.25338461995124817\n",
            "Epoch 22, Batch 104, test Loss: 0.35240858793258667\n",
            "Epoch 22, Batch 105, test Loss: 0.3517317473888397\n",
            "Epoch 22, Batch 106, test Loss: 0.6241117715835571\n",
            "Epoch 22, Batch 107, test Loss: 0.43608230352401733\n",
            "Epoch 22, Batch 108, test Loss: 0.4635279178619385\n",
            "Epoch 22, Batch 109, test Loss: 0.4332248866558075\n",
            "Epoch 22, Batch 110, test Loss: 0.5459150075912476\n",
            "Epoch 22, Batch 111, test Loss: 0.5832541584968567\n",
            "Epoch 22, Batch 112, test Loss: 0.4886642098426819\n",
            "Epoch 22, Batch 113, test Loss: 0.6277174949645996\n",
            "Epoch 22, Batch 114, test Loss: 0.4926408529281616\n",
            "Epoch 22, Batch 115, test Loss: 0.46631473302841187\n",
            "Epoch 22, Batch 116, test Loss: 0.47717198729515076\n",
            "Epoch 22, Batch 117, test Loss: 0.3634028434753418\n",
            "Epoch 22, Batch 118, test Loss: 0.3281805217266083\n",
            "Epoch 22, Batch 119, test Loss: 0.5230765342712402\n",
            "Epoch 22, Batch 120, test Loss: 0.4036192297935486\n",
            "Epoch 22, Batch 121, test Loss: 0.3648812472820282\n",
            "Epoch 22, Batch 122, test Loss: 0.47411826252937317\n",
            "Epoch 22, Batch 123, test Loss: 0.41418325901031494\n",
            "Epoch 22, Batch 124, test Loss: 0.4082675278186798\n",
            "Epoch 22, Batch 125, test Loss: 0.5152683854103088\n",
            "Epoch 22, Batch 126, test Loss: 0.4340592622756958\n",
            "Epoch 22, Batch 127, test Loss: 0.5896045565605164\n",
            "Epoch 22, Batch 128, test Loss: 0.47690099477767944\n",
            "Epoch 22, Batch 129, test Loss: 0.583899736404419\n",
            "Epoch 22, Batch 130, test Loss: 0.47394251823425293\n",
            "Epoch 22, Batch 131, test Loss: 0.29884660243988037\n",
            "Epoch 22, Batch 132, test Loss: 0.4045754075050354\n",
            "Epoch 22, Batch 133, test Loss: 0.6685426831245422\n",
            "Epoch 22, Batch 134, test Loss: 0.40763232111930847\n",
            "Epoch 22, Batch 135, test Loss: 0.5810524225234985\n",
            "Epoch 22, Batch 136, test Loss: 0.3881485164165497\n",
            "Epoch 22, Batch 137, test Loss: 0.4182833135128021\n",
            "Epoch 22, Batch 138, test Loss: 0.4528825879096985\n",
            "Epoch 22, Batch 139, test Loss: 0.49439409375190735\n",
            "Epoch 22, Batch 140, test Loss: 0.5017312169075012\n",
            "Epoch 22, Batch 141, test Loss: 0.24498124420642853\n",
            "Epoch 22, Batch 142, test Loss: 0.4945986270904541\n",
            "Epoch 22, Batch 143, test Loss: 0.43681660294532776\n",
            "Epoch 22, Batch 144, test Loss: 0.31343039870262146\n",
            "Epoch 22, Batch 145, test Loss: 0.2819066345691681\n",
            "Epoch 22, Batch 146, test Loss: 0.4593978524208069\n",
            "Epoch 22, Batch 147, test Loss: 0.26057878136634827\n",
            "Epoch 22, Batch 148, test Loss: 0.47095662355422974\n",
            "Epoch 22, Batch 149, test Loss: 0.5551804900169373\n",
            "Epoch 22, Batch 150, test Loss: 0.3847969174385071\n",
            "Epoch 22, Batch 151, test Loss: 0.4759441316127777\n",
            "Epoch 22, Batch 152, test Loss: 0.4600640535354614\n",
            "Epoch 22, Batch 153, test Loss: 0.3056830167770386\n",
            "Epoch 22, Batch 154, test Loss: 0.28954648971557617\n",
            "Epoch 22, Batch 155, test Loss: 0.4557291269302368\n",
            "Epoch 22, Batch 156, test Loss: 0.2695087790489197\n",
            "Epoch 22, Accuracy of test set: 0.8449\n",
            "Epoch 23/25:\n",
            "Train Loss: 0.0062, Train Accuracy: 0.86\n",
            "Test Loss: 0.0068, Test Accuracy: 0.84\n",
            "Accuracy of train set: 0.8633833333333333\n",
            "Epoch 23, Batch 0, test Loss: 0.5852499604225159\n",
            "Epoch 23, Batch 1, test Loss: 0.4750148355960846\n",
            "Epoch 23, Batch 2, test Loss: 0.4374919533729553\n",
            "Epoch 23, Batch 3, test Loss: 0.40661245584487915\n",
            "Epoch 23, Batch 4, test Loss: 0.3387773633003235\n",
            "Epoch 23, Batch 5, test Loss: 0.5225934386253357\n",
            "Epoch 23, Batch 6, test Loss: 0.4317038059234619\n",
            "Epoch 23, Batch 7, test Loss: 0.30024853348731995\n",
            "Epoch 23, Batch 8, test Loss: 0.5686815977096558\n",
            "Epoch 23, Batch 9, test Loss: 0.27930545806884766\n",
            "Epoch 23, Batch 10, test Loss: 0.42118221521377563\n",
            "Epoch 23, Batch 11, test Loss: 0.37654808163642883\n",
            "Epoch 23, Batch 12, test Loss: 0.2417559027671814\n",
            "Epoch 23, Batch 13, test Loss: 0.20386828482151031\n",
            "Epoch 23, Batch 14, test Loss: 0.44186046719551086\n",
            "Epoch 23, Batch 15, test Loss: 0.42510986328125\n",
            "Epoch 23, Batch 16, test Loss: 0.4555645287036896\n",
            "Epoch 23, Batch 17, test Loss: 0.44377583265304565\n",
            "Epoch 23, Batch 18, test Loss: 0.5772135853767395\n",
            "Epoch 23, Batch 19, test Loss: 0.4352286458015442\n",
            "Epoch 23, Batch 20, test Loss: 0.4241907596588135\n",
            "Epoch 23, Batch 21, test Loss: 0.45728495717048645\n",
            "Epoch 23, Batch 22, test Loss: 0.6010209321975708\n",
            "Epoch 23, Batch 23, test Loss: 0.3625835180282593\n",
            "Epoch 23, Batch 24, test Loss: 0.34849271178245544\n",
            "Epoch 23, Batch 25, test Loss: 0.322578102350235\n",
            "Epoch 23, Batch 26, test Loss: 0.35472604632377625\n",
            "Epoch 23, Batch 27, test Loss: 0.4900875687599182\n",
            "Epoch 23, Batch 28, test Loss: 0.39846888184547424\n",
            "Epoch 23, Batch 29, test Loss: 0.5521109104156494\n",
            "Epoch 23, Batch 30, test Loss: 0.4730004072189331\n",
            "Epoch 23, Batch 31, test Loss: 0.424483984708786\n",
            "Epoch 23, Batch 32, test Loss: 0.5469887256622314\n",
            "Epoch 23, Batch 33, test Loss: 0.4449945390224457\n",
            "Epoch 23, Batch 34, test Loss: 0.37969908118247986\n",
            "Epoch 23, Batch 35, test Loss: 0.33749622106552124\n",
            "Epoch 23, Batch 36, test Loss: 0.48177245259284973\n",
            "Epoch 23, Batch 37, test Loss: 0.4704034924507141\n",
            "Epoch 23, Batch 38, test Loss: 0.44840124249458313\n",
            "Epoch 23, Batch 39, test Loss: 0.42307519912719727\n",
            "Epoch 23, Batch 40, test Loss: 0.6150044202804565\n",
            "Epoch 23, Batch 41, test Loss: 0.45579591393470764\n",
            "Epoch 23, Batch 42, test Loss: 0.41627198457717896\n",
            "Epoch 23, Batch 43, test Loss: 0.42682525515556335\n",
            "Epoch 23, Batch 44, test Loss: 0.4680078327655792\n",
            "Epoch 23, Batch 45, test Loss: 0.3193160593509674\n",
            "Epoch 23, Batch 46, test Loss: 0.6807143092155457\n",
            "Epoch 23, Batch 47, test Loss: 0.43714362382888794\n",
            "Epoch 23, Batch 48, test Loss: 0.5045976638793945\n",
            "Epoch 23, Batch 49, test Loss: 0.35723286867141724\n",
            "Epoch 23, Batch 50, test Loss: 0.48221004009246826\n",
            "Epoch 23, Batch 51, test Loss: 0.4561800956726074\n",
            "Epoch 23, Batch 52, test Loss: 0.4250887930393219\n",
            "Epoch 23, Batch 53, test Loss: 0.2630474269390106\n",
            "Epoch 23, Batch 54, test Loss: 0.4608263075351715\n",
            "Epoch 23, Batch 55, test Loss: 0.3087766766548157\n",
            "Epoch 23, Batch 56, test Loss: 0.5767041444778442\n",
            "Epoch 23, Batch 57, test Loss: 0.6277931928634644\n",
            "Epoch 23, Batch 58, test Loss: 0.3442630171775818\n",
            "Epoch 23, Batch 59, test Loss: 0.4638087749481201\n",
            "Epoch 23, Batch 60, test Loss: 0.37042784690856934\n",
            "Epoch 23, Batch 61, test Loss: 0.6105656027793884\n",
            "Epoch 23, Batch 62, test Loss: 0.3164466619491577\n",
            "Epoch 23, Batch 63, test Loss: 0.3691933751106262\n",
            "Epoch 23, Batch 64, test Loss: 0.4150318205356598\n",
            "Epoch 23, Batch 65, test Loss: 0.31073856353759766\n",
            "Epoch 23, Batch 66, test Loss: 0.6221506595611572\n",
            "Epoch 23, Batch 67, test Loss: 0.24721594154834747\n",
            "Epoch 23, Batch 68, test Loss: 0.3733707666397095\n",
            "Epoch 23, Batch 69, test Loss: 0.2703268527984619\n",
            "Epoch 23, Batch 70, test Loss: 0.4475865662097931\n",
            "Epoch 23, Batch 71, test Loss: 0.2639867961406708\n",
            "Epoch 23, Batch 72, test Loss: 0.31604063510894775\n",
            "Epoch 23, Batch 73, test Loss: 0.516598641872406\n",
            "Epoch 23, Batch 74, test Loss: 0.38086074590682983\n",
            "Epoch 23, Batch 75, test Loss: 0.5414944887161255\n",
            "Epoch 23, Batch 76, test Loss: 0.4223872423171997\n",
            "Epoch 23, Batch 77, test Loss: 0.3867056965827942\n",
            "Epoch 23, Batch 78, test Loss: 0.3177700340747833\n",
            "Epoch 23, Batch 79, test Loss: 0.5506424903869629\n",
            "Epoch 23, Batch 80, test Loss: 0.6115818619728088\n",
            "Epoch 23, Batch 81, test Loss: 0.5302817225456238\n",
            "Epoch 23, Batch 82, test Loss: 0.6481520533561707\n",
            "Epoch 23, Batch 83, test Loss: 0.3720625638961792\n",
            "Epoch 23, Batch 84, test Loss: 0.5376290678977966\n",
            "Epoch 23, Batch 85, test Loss: 0.29059743881225586\n",
            "Epoch 23, Batch 86, test Loss: 0.2800089120864868\n",
            "Epoch 23, Batch 87, test Loss: 0.5372042059898376\n",
            "Epoch 23, Batch 88, test Loss: 0.4051111042499542\n",
            "Epoch 23, Batch 89, test Loss: 0.22527693212032318\n",
            "Epoch 23, Batch 90, test Loss: 0.5312345623970032\n",
            "Epoch 23, Batch 91, test Loss: 0.4460235834121704\n",
            "Epoch 23, Batch 92, test Loss: 0.41153988242149353\n",
            "Epoch 23, Batch 93, test Loss: 0.3029301166534424\n",
            "Epoch 23, Batch 94, test Loss: 0.4147697687149048\n",
            "Epoch 23, Batch 95, test Loss: 0.47596147656440735\n",
            "Epoch 23, Batch 96, test Loss: 0.3595845401287079\n",
            "Epoch 23, Batch 97, test Loss: 0.43158718943595886\n",
            "Epoch 23, Batch 98, test Loss: 0.621610701084137\n",
            "Epoch 23, Batch 99, test Loss: 0.5491253137588501\n",
            "Epoch 23, Batch 100, test Loss: 0.6168631315231323\n",
            "Epoch 23, Batch 101, test Loss: 0.48023197054862976\n",
            "Epoch 23, Batch 102, test Loss: 0.3518195152282715\n",
            "Epoch 23, Batch 103, test Loss: 0.308767706155777\n",
            "Epoch 23, Batch 104, test Loss: 0.3785082995891571\n",
            "Epoch 23, Batch 105, test Loss: 0.431617796421051\n",
            "Epoch 23, Batch 106, test Loss: 0.5367071628570557\n",
            "Epoch 23, Batch 107, test Loss: 0.5061396956443787\n",
            "Epoch 23, Batch 108, test Loss: 0.35807427763938904\n",
            "Epoch 23, Batch 109, test Loss: 0.4489220976829529\n",
            "Epoch 23, Batch 110, test Loss: 0.4221506118774414\n",
            "Epoch 23, Batch 111, test Loss: 0.77569180727005\n",
            "Epoch 23, Batch 112, test Loss: 0.5930407643318176\n",
            "Epoch 23, Batch 113, test Loss: 0.4487195611000061\n",
            "Epoch 23, Batch 114, test Loss: 0.6906510591506958\n",
            "Epoch 23, Batch 115, test Loss: 0.43252453207969666\n",
            "Epoch 23, Batch 116, test Loss: 0.3574458658695221\n",
            "Epoch 23, Batch 117, test Loss: 0.4473602771759033\n",
            "Epoch 23, Batch 118, test Loss: 0.4748452305793762\n",
            "Epoch 23, Batch 119, test Loss: 0.3661552965641022\n",
            "Epoch 23, Batch 120, test Loss: 0.39751869440078735\n",
            "Epoch 23, Batch 121, test Loss: 0.3462386727333069\n",
            "Epoch 23, Batch 122, test Loss: 0.49171802401542664\n",
            "Epoch 23, Batch 123, test Loss: 0.4199589788913727\n",
            "Epoch 23, Batch 124, test Loss: 0.4294126033782959\n",
            "Epoch 23, Batch 125, test Loss: 0.39802977442741394\n",
            "Epoch 23, Batch 126, test Loss: 0.5587140321731567\n",
            "Epoch 23, Batch 127, test Loss: 0.39495694637298584\n",
            "Epoch 23, Batch 128, test Loss: 0.44831642508506775\n",
            "Epoch 23, Batch 129, test Loss: 0.5049450993537903\n",
            "Epoch 23, Batch 130, test Loss: 0.36122313141822815\n",
            "Epoch 23, Batch 131, test Loss: 0.3356541395187378\n",
            "Epoch 23, Batch 132, test Loss: 0.3699270486831665\n",
            "Epoch 23, Batch 133, test Loss: 0.5674061179161072\n",
            "Epoch 23, Batch 134, test Loss: 0.5334511995315552\n",
            "Epoch 23, Batch 135, test Loss: 0.400910884141922\n",
            "Epoch 23, Batch 136, test Loss: 0.45187950134277344\n",
            "Epoch 23, Batch 137, test Loss: 0.33348411321640015\n",
            "Epoch 23, Batch 138, test Loss: 0.41457000374794006\n",
            "Epoch 23, Batch 139, test Loss: 0.38958871364593506\n",
            "Epoch 23, Batch 140, test Loss: 0.6687064170837402\n",
            "Epoch 23, Batch 141, test Loss: 0.4391268789768219\n",
            "Epoch 23, Batch 142, test Loss: 0.6091857552528381\n",
            "Epoch 23, Batch 143, test Loss: 0.45293647050857544\n",
            "Epoch 23, Batch 144, test Loss: 0.23677147924900055\n",
            "Epoch 23, Batch 145, test Loss: 0.32340824604034424\n",
            "Epoch 23, Batch 146, test Loss: 0.46759238839149475\n",
            "Epoch 23, Batch 147, test Loss: 0.4315528869628906\n",
            "Epoch 23, Batch 148, test Loss: 0.39619606733322144\n",
            "Epoch 23, Batch 149, test Loss: 0.43654584884643555\n",
            "Epoch 23, Batch 150, test Loss: 0.39528271555900574\n",
            "Epoch 23, Batch 151, test Loss: 0.2690589427947998\n",
            "Epoch 23, Batch 152, test Loss: 0.5984325408935547\n",
            "Epoch 23, Batch 153, test Loss: 0.3968597650527954\n",
            "Epoch 23, Batch 154, test Loss: 0.3999972641468048\n",
            "Epoch 23, Batch 155, test Loss: 0.3911135196685791\n",
            "Epoch 23, Batch 156, test Loss: 0.5726938843727112\n",
            "Epoch 23, Accuracy of test set: 0.8446\n",
            "Epoch 24/25:\n",
            "Train Loss: 0.0061, Train Accuracy: 0.86\n",
            "Test Loss: 0.0069, Test Accuracy: 0.84\n",
            "Accuracy of train set: 0.8655166666666667\n",
            "Epoch 24, Batch 0, test Loss: 0.4626220166683197\n",
            "Epoch 24, Batch 1, test Loss: 0.3472658395767212\n",
            "Epoch 24, Batch 2, test Loss: 0.5051215887069702\n",
            "Epoch 24, Batch 3, test Loss: 0.26552656292915344\n",
            "Epoch 24, Batch 4, test Loss: 0.4346582591533661\n",
            "Epoch 24, Batch 5, test Loss: 0.5014553070068359\n",
            "Epoch 24, Batch 6, test Loss: 0.4375171363353729\n",
            "Epoch 24, Batch 7, test Loss: 0.46847689151763916\n",
            "Epoch 24, Batch 8, test Loss: 0.4496450126171112\n",
            "Epoch 24, Batch 9, test Loss: 0.5645811557769775\n",
            "Epoch 24, Batch 10, test Loss: 0.4488394260406494\n",
            "Epoch 24, Batch 11, test Loss: 0.2715165317058563\n",
            "Epoch 24, Batch 12, test Loss: 0.26768749952316284\n",
            "Epoch 24, Batch 13, test Loss: 0.49940866231918335\n",
            "Epoch 24, Batch 14, test Loss: 0.35742029547691345\n",
            "Epoch 24, Batch 15, test Loss: 0.4979228675365448\n",
            "Epoch 24, Batch 16, test Loss: 0.38993069529533386\n",
            "Epoch 24, Batch 17, test Loss: 0.5869601964950562\n",
            "Epoch 24, Batch 18, test Loss: 0.6088411211967468\n",
            "Epoch 24, Batch 19, test Loss: 0.8486125469207764\n",
            "Epoch 24, Batch 20, test Loss: 0.4117715060710907\n",
            "Epoch 24, Batch 21, test Loss: 0.4339154064655304\n",
            "Epoch 24, Batch 22, test Loss: 0.33947527408599854\n",
            "Epoch 24, Batch 23, test Loss: 0.2892391085624695\n",
            "Epoch 24, Batch 24, test Loss: 0.40832412242889404\n",
            "Epoch 24, Batch 25, test Loss: 0.39335599541664124\n",
            "Epoch 24, Batch 26, test Loss: 0.3781203031539917\n",
            "Epoch 24, Batch 27, test Loss: 0.30160874128341675\n",
            "Epoch 24, Batch 28, test Loss: 0.2634904980659485\n",
            "Epoch 24, Batch 29, test Loss: 0.5082827210426331\n",
            "Epoch 24, Batch 30, test Loss: 0.4482029676437378\n",
            "Epoch 24, Batch 31, test Loss: 0.30157387256622314\n",
            "Epoch 24, Batch 32, test Loss: 0.4039095640182495\n",
            "Epoch 24, Batch 33, test Loss: 0.40720364451408386\n",
            "Epoch 24, Batch 34, test Loss: 0.42150041460990906\n",
            "Epoch 24, Batch 35, test Loss: 0.5076729655265808\n",
            "Epoch 24, Batch 36, test Loss: 0.2841666638851166\n",
            "Epoch 24, Batch 37, test Loss: 0.4244128465652466\n",
            "Epoch 24, Batch 38, test Loss: 0.42051082849502563\n",
            "Epoch 24, Batch 39, test Loss: 0.3625416159629822\n",
            "Epoch 24, Batch 40, test Loss: 0.525122880935669\n",
            "Epoch 24, Batch 41, test Loss: 0.43975967168807983\n",
            "Epoch 24, Batch 42, test Loss: 0.46405482292175293\n",
            "Epoch 24, Batch 43, test Loss: 0.6166870594024658\n",
            "Epoch 24, Batch 44, test Loss: 0.26728135347366333\n",
            "Epoch 24, Batch 45, test Loss: 0.48985451459884644\n",
            "Epoch 24, Batch 46, test Loss: 0.5577119588851929\n",
            "Epoch 24, Batch 47, test Loss: 0.4998691976070404\n",
            "Epoch 24, Batch 48, test Loss: 0.38618770241737366\n",
            "Epoch 24, Batch 49, test Loss: 0.5226622223854065\n",
            "Epoch 24, Batch 50, test Loss: 0.6175826787948608\n",
            "Epoch 24, Batch 51, test Loss: 0.3525550365447998\n",
            "Epoch 24, Batch 52, test Loss: 0.46028900146484375\n",
            "Epoch 24, Batch 53, test Loss: 0.5505446195602417\n",
            "Epoch 24, Batch 54, test Loss: 0.4682495892047882\n",
            "Epoch 24, Batch 55, test Loss: 0.5540698766708374\n",
            "Epoch 24, Batch 56, test Loss: 0.3699718713760376\n",
            "Epoch 24, Batch 57, test Loss: 0.432618647813797\n",
            "Epoch 24, Batch 58, test Loss: 0.48107171058654785\n",
            "Epoch 24, Batch 59, test Loss: 0.38994932174682617\n",
            "Epoch 24, Batch 60, test Loss: 0.4486028552055359\n",
            "Epoch 24, Batch 61, test Loss: 0.40846073627471924\n",
            "Epoch 24, Batch 62, test Loss: 0.2769728899002075\n",
            "Epoch 24, Batch 63, test Loss: 0.4353184998035431\n",
            "Epoch 24, Batch 64, test Loss: 0.3350566327571869\n",
            "Epoch 24, Batch 65, test Loss: 0.42467647790908813\n",
            "Epoch 24, Batch 66, test Loss: 0.2602713108062744\n",
            "Epoch 24, Batch 67, test Loss: 0.3252527415752411\n",
            "Epoch 24, Batch 68, test Loss: 0.31206217408180237\n",
            "Epoch 24, Batch 69, test Loss: 0.34931549429893494\n",
            "Epoch 24, Batch 70, test Loss: 0.4395979642868042\n",
            "Epoch 24, Batch 71, test Loss: 0.6171380281448364\n",
            "Epoch 24, Batch 72, test Loss: 0.59569251537323\n",
            "Epoch 24, Batch 73, test Loss: 0.31807780265808105\n",
            "Epoch 24, Batch 74, test Loss: 0.5665256381034851\n",
            "Epoch 24, Batch 75, test Loss: 0.2643934488296509\n",
            "Epoch 24, Batch 76, test Loss: 0.3990299701690674\n",
            "Epoch 24, Batch 77, test Loss: 0.39561206102371216\n",
            "Epoch 24, Batch 78, test Loss: 0.2068304866552353\n",
            "Epoch 24, Batch 79, test Loss: 0.5078689455986023\n",
            "Epoch 24, Batch 80, test Loss: 0.3459758162498474\n",
            "Epoch 24, Batch 81, test Loss: 0.33574381470680237\n",
            "Epoch 24, Batch 82, test Loss: 0.4352078437805176\n",
            "Epoch 24, Batch 83, test Loss: 0.5386408567428589\n",
            "Epoch 24, Batch 84, test Loss: 0.4187712073326111\n",
            "Epoch 24, Batch 85, test Loss: 0.48997023701667786\n",
            "Epoch 24, Batch 86, test Loss: 0.5238294005393982\n",
            "Epoch 24, Batch 87, test Loss: 0.4904431700706482\n",
            "Epoch 24, Batch 88, test Loss: 0.36728161573410034\n",
            "Epoch 24, Batch 89, test Loss: 0.39863649010658264\n",
            "Epoch 24, Batch 90, test Loss: 0.6018010973930359\n",
            "Epoch 24, Batch 91, test Loss: 0.35649800300598145\n",
            "Epoch 24, Batch 92, test Loss: 0.3512786626815796\n",
            "Epoch 24, Batch 93, test Loss: 0.41907382011413574\n",
            "Epoch 24, Batch 94, test Loss: 0.33053508400917053\n",
            "Epoch 24, Batch 95, test Loss: 0.3255699574947357\n",
            "Epoch 24, Batch 96, test Loss: 0.4387291669845581\n",
            "Epoch 24, Batch 97, test Loss: 0.3701210618019104\n",
            "Epoch 24, Batch 98, test Loss: 0.4543552100658417\n",
            "Epoch 24, Batch 99, test Loss: 0.23588982224464417\n",
            "Epoch 24, Batch 100, test Loss: 0.4455123543739319\n",
            "Epoch 24, Batch 101, test Loss: 0.3887801170349121\n",
            "Epoch 24, Batch 102, test Loss: 0.42771345376968384\n",
            "Epoch 24, Batch 103, test Loss: 0.3388177454471588\n",
            "Epoch 24, Batch 104, test Loss: 0.6301339864730835\n",
            "Epoch 24, Batch 105, test Loss: 0.3969944715499878\n",
            "Epoch 24, Batch 106, test Loss: 0.3525168299674988\n",
            "Epoch 24, Batch 107, test Loss: 0.4379606246948242\n",
            "Epoch 24, Batch 108, test Loss: 0.6540557742118835\n",
            "Epoch 24, Batch 109, test Loss: 0.4798680543899536\n",
            "Epoch 24, Batch 110, test Loss: 0.6199150085449219\n",
            "Epoch 24, Batch 111, test Loss: 0.5209007263183594\n",
            "Epoch 24, Batch 112, test Loss: 0.3111078143119812\n",
            "Epoch 24, Batch 113, test Loss: 0.37255775928497314\n",
            "Epoch 24, Batch 114, test Loss: 0.3629453778266907\n",
            "Epoch 24, Batch 115, test Loss: 0.46278882026672363\n",
            "Epoch 24, Batch 116, test Loss: 0.5340206623077393\n",
            "Epoch 24, Batch 117, test Loss: 0.4493573307991028\n",
            "Epoch 24, Batch 118, test Loss: 0.34680771827697754\n",
            "Epoch 24, Batch 119, test Loss: 0.49075597524642944\n",
            "Epoch 24, Batch 120, test Loss: 0.4385337829589844\n",
            "Epoch 24, Batch 121, test Loss: 0.45607832074165344\n",
            "Epoch 24, Batch 122, test Loss: 0.20360320806503296\n",
            "Epoch 24, Batch 123, test Loss: 0.20838220417499542\n",
            "Epoch 24, Batch 124, test Loss: 0.5017204284667969\n",
            "Epoch 24, Batch 125, test Loss: 0.5801928639411926\n",
            "Epoch 24, Batch 126, test Loss: 0.5230515599250793\n",
            "Epoch 24, Batch 127, test Loss: 0.3878374695777893\n",
            "Epoch 24, Batch 128, test Loss: 0.2464066445827484\n",
            "Epoch 24, Batch 129, test Loss: 0.35833439230918884\n",
            "Epoch 24, Batch 130, test Loss: 0.27360856533050537\n",
            "Epoch 24, Batch 131, test Loss: 0.49368569254875183\n",
            "Epoch 24, Batch 132, test Loss: 0.443621426820755\n",
            "Epoch 24, Batch 133, test Loss: 0.41592103242874146\n",
            "Epoch 24, Batch 134, test Loss: 0.2456432580947876\n",
            "Epoch 24, Batch 135, test Loss: 0.30219727754592896\n",
            "Epoch 24, Batch 136, test Loss: 0.42439863085746765\n",
            "Epoch 24, Batch 137, test Loss: 0.28219300508499146\n",
            "Epoch 24, Batch 138, test Loss: 0.7804050445556641\n",
            "Epoch 24, Batch 139, test Loss: 0.4361986517906189\n",
            "Epoch 24, Batch 140, test Loss: 0.5658940076828003\n",
            "Epoch 24, Batch 141, test Loss: 0.35637572407722473\n",
            "Epoch 24, Batch 142, test Loss: 0.32942938804626465\n",
            "Epoch 24, Batch 143, test Loss: 0.535118043422699\n",
            "Epoch 24, Batch 144, test Loss: 0.31827512383461\n",
            "Epoch 24, Batch 145, test Loss: 0.5676671862602234\n",
            "Epoch 24, Batch 146, test Loss: 0.36913129687309265\n",
            "Epoch 24, Batch 147, test Loss: 0.43214330077171326\n",
            "Epoch 24, Batch 148, test Loss: 0.3735522925853729\n",
            "Epoch 24, Batch 149, test Loss: 0.7434157729148865\n",
            "Epoch 24, Batch 150, test Loss: 0.29621434211730957\n",
            "Epoch 24, Batch 151, test Loss: 0.42321959137916565\n",
            "Epoch 24, Batch 152, test Loss: 0.21511828899383545\n",
            "Epoch 24, Batch 153, test Loss: 0.2894513010978699\n",
            "Epoch 24, Batch 154, test Loss: 0.4209992587566376\n",
            "Epoch 24, Batch 155, test Loss: 0.37691089510917664\n",
            "Epoch 24, Batch 156, test Loss: 0.4492489993572235\n",
            "Epoch 24, Accuracy of test set: 0.8504\n",
            "Epoch 25/25:\n",
            "Train Loss: 0.0060, Train Accuracy: 0.87\n",
            "Test Loss: 0.0067, Test Accuracy: 0.85\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "train_model([train_loader, test_loader], num_epochs=25, learning_rate=0.005)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "ceb5783f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceb5783f",
        "outputId": "b8eb272a-5f2c-4d95-b58e-703d9fc878e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final test accuracy: 0.8504\n"
          ]
        }
      ],
      "source": [
        "print(f'Final test accuracy: {test_accuracies[-1]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5e128ed",
      "metadata": {
        "id": "a5e128ed"
      },
      "source": [
        "## Visualization of the labels and predictions\n",
        "\n",
        "In this section, you should visual one image from each class and show both the actual label and the predicted label for that image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "6c0b79fd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "6c0b79fd",
        "outputId": "28491fd4-629d-46e1-e412-7af30c28cec1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 3000x1000 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "## FILL HERE\n",
        "def visualize_labels_and_predictions(loader, parameters, class_names):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    images = []\n",
        "    true_labels = []\n",
        "    pred_labels = []\n",
        "    found_labels = set()\n",
        "\n",
        "    for x, y in loader:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        output = model(x, parameters)\n",
        "        predicted = output.argmax(dim=1)\n",
        "\n",
        "        for img, true, pred in zip(x, y, predicted):\n",
        "            if true.item() not in found_labels:\n",
        "                images.append(img.cpu())\n",
        "                true_labels.append(true.item())\n",
        "                pred_labels.append(pred.item())\n",
        "                found_labels.add(true.item())\n",
        "            if len(found_labels) == len(class_names):  # Stop once we have all classes\n",
        "                break\n",
        "        if len(found_labels) == len(class_names):\n",
        "            break\n",
        "\n",
        "    fig, axes = plt.subplots(1, len(class_names), figsize=(30, 10))\n",
        "    for i, (img, true, pred) in enumerate(zip(images, true_labels, pred_labels)):\n",
        "        ax = axes[i]\n",
        "        img = img.squeeze()\n",
        "        ax.imshow(img, cmap='gray')\n",
        "        ax.set_title(f\"True: {class_names[true]}\\nPred: {class_names[pred]}\")\n",
        "        ax.axis('off')\n",
        "\n",
        "    # Adjust the spacing\n",
        "    plt.subplots_adjust(wspace=0.1, hspace=0.1)  # Adjust the width and height spaces\n",
        "    plt.show()\n",
        "\n",
        "# Usage:\n",
        "visualize_labels_and_predictions(test_loader, parameters, class_names)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}